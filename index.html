<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kyler Laycock">
<meta name="author" content="Kevin B McGowan">
<meta name="dcterms.date" content="2024-05-21">
<meta name="description" content="REMOVING THE DISGUISE: THE MATCHED GUISE TECHNIQUE AND LISTENER AWARENESS">

<title>Removing the disguise: the matched guise technique and listener awareness</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/critic/critic.min.js"></script>
<link href="site_libs/quarto-contrib/critic/critic.css" rel="stylesheet">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">


<link rel="stylesheet" href="_extensions/wjschne/apaquarto/apa.css">
<meta name="citation_title" content="Removing the disguise: the matched guise technique and listener awareness">
<meta name="citation_abstract" content="Sociophonetic perception is often studied using versions of the matched guise technique. Linguists using this technique appear united in the methodological assumptions that participants believe the manipulation and that this belief influences perception below the level of introspective awareness. We report an audiovisual matched guise experiment with a novel &amp;amp;#039;unhidden' instruction condition. The basic task is a replication of the Strand effect [@strandJohnson1996; @strand1999]. Participants in the 'unhidden' condition were instructed that the man or woman in the photo did not represent the voice they were listening to. Participants in both guises exhibited the Strand effect to nearly numerically identical extents. This result suggests that participants need not believe a link exists between a voice and a purported social category for visually-cued social information to influence segmental perception. We explore the implications of this result for the MGT and for theories of social awareness and speech perception more broadly.
">
<meta name="citation_keywords" content="">
<meta name="citation_author" content="Kyler Laycock">
<meta name="citation_author" content="Kevin B McGowan">
<meta name="citation_publication_date" content="2024-05-21">
<meta name="citation_cover_date" content="2024-05-21">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-05-21">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Awareness and Control of Sociolinguistic Variation">
<meta name="citation_reference" content="citation_title=Uncovering the role of gender stereotypes in speech perception;,citation_author=Elizabeth A Strand;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=18;,citation_journal_title=Journal of language and social psychology;,citation_publisher=Sage Publications Sage CA: Thousand Oaks, CA;">
<meta name="citation_reference" content="citation_title=Gradient and visual speaker normalization in the perception of fricatives.;,citation_author=Elizabeth A Strand;,citation_author=Keith Johnson;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=KONVENS;">
<meta name="citation_reference" content="citation_title=Acoustic theory of speech production;,citation_author=G. Fant;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=The effect of geometry on source mechanisms of fricative consonants;,citation_author=Christine H Shadle;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=3-4;,citation_volume=19;,citation_journal_title=Journal of Phonetics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Subcategorical phonetic mismatches slow phonetic judgments;,citation_author=Douglas H Whalen;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_volume=35;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=The influence of actual and imputed talker gender on fricative perception, revisited (l);,citation_author=Benjamin Munson;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=5;,citation_volume=130;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Influence of vocalic context on perception of the [ʃ]-[s] distinction;,citation_author=Virginia A Mann;,citation_author=Bruno H Repp;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=3;,citation_volume=28;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=An ethological perspective on common cross-language utilization of F₀ of voice;,citation_author=John J Ohala;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=1;,citation_volume=41;,citation_journal_title=Phonetica;,citation_publisher=S. Karger AG Basel, Switzerland;">
<meta name="citation_reference" content="citation_title=On the influence of context upon perception of voiceless fricative consonants;,citation_author=Osamu Kunisaki;,citation_author=Hyroya Fujisaki;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_volume=11;,citation_journal_title=Annual Bulletin;,citation_publisher=Research Institute of Logopedics; Phoniatrics Tokyo;">
<meta name="citation_reference" content="citation_title=Effects of vocalic formant transitions and vowel quality on the english [s]–[š] boundary;,citation_author=Douglas H Whalen;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=1;,citation_volume=69;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=The time course of perception of coarticulation;,citation_author=Patrice Speeter Beddor;,citation_author=Kevin B McGowan;,citation_author=Julie E Boland;,citation_author=Andries W Coetzee;,citation_author=Anthony Brasher;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=133;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=The time course of individuals’ perception of coarticulatory information is linked to their production: Implications for sound change;,citation_author=Patrice Speeter Beddor;,citation_author=Andries W Coetzee;,citation_author=Will Styler;,citation_author=Kevin B McGowan;,citation_author=Julie E Boland;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=94;,citation_journal_title=Language;,citation_publisher=Linguistic Society of America;">
<meta name="citation_reference" content="citation_title=Hearing lips and seeing voices;,citation_author=Harry McGurk;,citation_author=John MacDonald;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_volume=264;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Perception of the english/s/–//distinction relies on fricative noises and transitions, not on brief spectral slices;,citation_author=Douglas H Whalen;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=4;,citation_volume=90;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Sociophonetics, gender, and sexuality;,citation_author=Robert J Podesva;,citation_author=Sakiko Kajino;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=The handbook of language, gender, and sexuality;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The association between/s/quality and perceived sexual orientation of men’s voices: Implicit and explicit measures;,citation_author=Sara Mack;,citation_author=Benjamin Munson;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=40;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=From “gay lisp” to “fierce queen”: The sociophonetics of sexuality’s most iconic variable;,citation_author=Jeremy Calder;,citation_editor=Kira Hall;,citation_editor=Rusty Barrett;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_inbook_title=The oxford handbook of language and sexuality;">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#coarticulatory-and-social-information-influence-ʃ-s-perception" id="toc-coarticulatory-and-social-information-influence-ʃ-s-perception" class="nav-link" data-scroll-target="#coarticulatory-and-social-information-influence-ʃ-s-perception">Coarticulatory and Social Information Influence [ʃ]-[s] perception</a></li>
  <li><a href="#phonetics-speech-perception-and-the-social-construction-of-gender" id="toc-phonetics-speech-perception-and-the-social-construction-of-gender" class="nav-link" data-scroll-target="#phonetics-speech-perception-and-the-social-construction-of-gender">Phonetics, Speech Perception, and the Social-Construction of Gender</a></li>
  <li><a href="#sec-data-methods" id="toc-sec-data-methods" class="nav-link" data-scroll-target="#sec-data-methods">Data &amp; Methods</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word (apaquarto)</a></li></ul></div><div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="notebooks/explore-earthquakes.embed-preview.html"><i class="bi bi-journal-code"></i>Explore Earthquakes</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<br>

<br>

<section id="title" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">Removing the disguise: the matched guise technique and listener awareness</h1>
<div class="Author">
<br>

<p>Kyler Laycock<sup>1</sup> and Kevin B McGowan<sup>2</sup></p>
<p><sup>1</sup>The Ohio State University</p>
<p><sup>2</sup>The University of Kentucky</p>
</div>
</section>
<section id="author-note" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Author Note</h1>
</section>
<section id="abstract" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Abstract</h1>
<p><em>Keywords</em>:</p>
</section>
<section id="firstheader" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">Removing the disguise: the matched guise technique and listener awareness</h1>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>A great deal of attention has been paid in the phonetics and sociophonetics literatures to the perception of the voiceless fricatives [ʃ] and [s] in English. To a first approximation, these fricatives differ in the distance between the point of lingual articulation and the teeth, which give them their characteristic sibilance <span class="citation" data-cites="fant1960">Shadle (<a href="#ref-shadle1991" role="doc-biblioref">1991</a>)</span>. English [s] has a short resonating chamber behind the teeth; it is typically produced by holding the tongue blade near enough to the alveolar ridge to cause turbulent airflow. English [ʃ] has a comparatively larger resonating chamber; it is typically produced with a more posterior, palato-alveolar tongue position and lip rounding both of which serve to reinforce this posteriority. But listeners do not perceive via <ins>this type of</ins><span class="critic comment">KM</span> first approximation<ins>; we are sensitive to fine phonetic details far beyond these gross, categorical, differences</ins><span class="critic comment">KM</span>. Indeed, these two fricatives have been exciting to researchers precisely because of the sensitivity listeners bring to their perception and how that perception interacts with both linguistic and social knowledge.</p>
<section id="coarticulatory-and-social-information-influence-ʃ-s-perception" class="level2">
<h2 data-anchor-id="coarticulatory-and-social-information-influence-ʃ-s-perception">Coarticulatory and Social Information Influence [ʃ]-[s] perception</h2>
<p><span class="critic comment">KL: ok, this is the specific section the editors didn’t like I think vis-a-vis “rewriting the introduction to state more strongly why this study is important to sociolinguistics, and not mainly interesting to cognitive linguists”</span> Listeners are sensitive to articulatory mismatches between the fricatives [ʃ]-[s] and neighboring sounds. <span class="citation" data-cites="whalen1984">Whalen (<a href="#ref-whalen1984" role="doc-biblioref">1984</a>)</span> conducted a series of experiments to investigate listeners’ responses to articulatory mismatches in synthetic speech. Overall, the result of these investigations was that subcategorical phonetic mismatches slow phonetic judgments. In onset position, in isolation, or in coda position, misleading coarticulatory information inhibited reaction times. Listeners, Whalen cautions in the conclusion, are sensitive to articulatory patterns that are below the level of conscious awareness and not available to direct experimenter scrutiny. While listeners will readily fill-in missing or ambiguous information, the presence of actively <em>conflicting</em> articulatory information is inhibitory.</p>
<p>A commonly used methodology involves the creation of synthetic fricative continua. These continua have endpoints in prototypical examples of [ʃ] and [s] with some number of equal-sized acoustic steps generated, synthesized, or even mixed between these. Somewhere in the middle of such a continuum will be fricative-like noise that is ambiguous as to category membership: not clearly a [ʃ] and not clearly an [s]. paired a continuum from [ʃ] (2.9 kHz) to [s] (4.4 kHz) with synthetic [æ] vowels to form CV pairs. May found that listeners perceived a higher proportion of the fricative continuum as [ʃ] when paired with vowel stimuli from a smaller vocal tract. The logic here is that smaller resonating chambers between the lingual articulation and teeth will have a higher mean frequency than larger resonating chambers. Listeners’ use of apparent vocal tract size in perception reflect their knowledge of this variation <span class="citation" data-cites="munson2011">(<a href="#ref-munson2011" role="doc-biblioref">Munson, 2011</a>)</span>.</p>
<p><span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> replicated this finding, extending it to natural productions of vowels spoken by a male or female-identified talker. Similar to May’s results with simulated vocal tract size, Mann &amp; Repp found a higher proportion of the fricative continuum was heard as [ʃ] when paired with the speech of the female talker. This early work, like others of the period <span class="citation" data-cites="ohala1984">(<a href="#ref-ohala1984" role="doc-biblioref">Ohala, 1984</a>)</span>, theorized size as being a relatively deterministic feature of talker sexual dimorphism. One consequence of this view is that gender-related variation in the speech signal is considered mechanistic, universal, and following from purely physical laws. Vocal tract size is presumably not available for individual performance and so listener knowledge of this variation can be correspondingly simple. Vocal tract size may influence perception, but it does so implicitly, automatically, and below the level of introspective awareness.</p>
<p><ins> <span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> also replicated and extended previous work <span class="citation" data-cites="kunisakifujisaki1977 whalen1981">(<a href="#ref-kunisakifujisaki1977" role="doc-biblioref">Kunisaki &amp; Fujisaki, 1977</a>; <a href="#ref-whalen1981" role="doc-biblioref">Whalen, 1981</a>)</span> demonstrating that listeners report hearing more of the synthetic fricative continuum as [s] when followed by a rounded vowel quality such as English [u] than when followed by an unrounded quality such as [i] or [a]. Listeners experience the fricative continuum differently in the presence of anticipatory coarticulation. The presence of nasal coarticulation on a vowel similarly allows listeners to make a lexical decision between words like <em>bend</em> and <em>bed</em> as soon as that information is present in the acoustic signal <span class="citation" data-cites="beddormcgowanbolandcoetzeebrasher2013 beddorcoetzeestylermcgowanboland2018">(<a href="#ref-beddormcgowanbolandcoetzeebrasher2013" role="doc-biblioref">Beddor et al., 2013</a>, <a href="#ref-beddorcoetzeestylermcgowanboland2018" role="doc-biblioref">2018</a>)</span>. Mann &amp; Repp’s participants in this study experienced auditory evidence of posteriority in the ambiguous portion of the fricative continuum as the presence of coarticulation with a following rounded vowel. As with vocal tract length, above, the behavioral result was a shift in the listeners’ fricative category boundary toward [s]. </ins><span class="critic comment">KM: clarifying and putting this back at least for now.</span></p>
<p><span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span> conducted a pair of experiments investigating the influence of purported gender of a talker on the perception of the [ʃ]-[s] boundary. In their experiment 1, listeners heard a [ʃ]-[s] continuum paired with voices previously normed as prototypical female, non-prototypical female, non-prototypical male, and prototypical male voices. The result replicates <span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> and extends it to show that the influence of a gendered voice correlates with the protypicality of that voice (exp1). They then extend this research to show that presenting listeners with prototypically-gendered videos of their purported talker can, again, shift perceptions of the [ʃ]-[s] such that listeners report hearing a higher proportion of the continuum as [ʃ] when watching a female talker and a higher proportion of [s] when watching a male talker. The AV condition of their experiment 2 is reminiscent of <span class="citation" data-cites="McGurkMacDonald1976">McGurk and MacDonald (<a href="#ref-McGurkMacDonald1976" role="doc-biblioref">1976</a>)</span> and is presented in that context. A striking feature of the McGurk Effect is its automaticity; participants can not choose to perceive the two components of a fused percept independently. It is unclear from <span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span> and subsequent work whether the perceptual influence of visually-presented social information is implicit and automatic, like vocal tract size, the McGurk effect, etc., or whether the effect disappears when listeners are aware of the guise manipulation.</p>
<p>This is an incomplete sample of the literature on the perception of these fricatives. We hope, however, that the message is clear that even when arriving at a purely linguistic percept, listeners’ judgments depend on a rich constellation of evidence and expectation. Vocal tract size, formant transitions, following vowel quality <span class="citation" data-cites="MannRepp1980">(<a href="#ref-MannRepp1980" role="doc-biblioref">Mann &amp; Repp, 1980</a>)</span>, and coarticulatory cues, along with the acoustic properties of the fricative itself, can all shape how listeners report experiencing that fricative. Rather than relying on a single, invariant, phonetic cue, listeners take the entire fricative and context into account <span class="citation" data-cites="whalen1991">Whalen (<a href="#ref-whalen1991" role="doc-biblioref">1991</a>)</span>.</p>
<p><del>One imagines</del><ins> It is conceivable that</ins> <span class="critic comment">KM</span> such exquisite sensitivity to the phonetic cues conveying linguistic category membership might restrict language users’ freedom to communicate and perceive social information via the same phonetic signal. This would be the prediction of a phonetic theory in which linguistic information and social information battle for control of the air waves –where listeners must normalize away social variation to recover linguistic information. Instead, with these fricatives, at least, we can observe the opposite. The fricatives /ʃ/ and /s/ often carry social meaning <span class="citation" data-cites="podesvakajino2014 mackMunson2012b">(<a href="#ref-mackMunson2012b" role="doc-biblioref">Mack &amp; Munson, 2012</a>; <a href="#ref-podesvakajino2014" role="doc-biblioref">Podesva &amp; Kajino, 2014</a>)</span> with /s/ being “perhaps the most iconic phonetic variable in the field” <span class="citation" data-cites="calder2018">(<a href="#ref-calder2018" role="doc-biblioref">Calder, 2018</a>)</span>. The implication is that the social and linguistic meanings of particular phonetic cues are not in competition with one another.</p>
</section>
<section id="phonetics-speech-perception-and-the-social-construction-of-gender" class="level2">
<h2 data-anchor-id="phonetics-speech-perception-and-the-social-construction-of-gender">Phonetics, Speech Perception, and the Social-Construction of Gender</h2>
<p>La Palma is one of the west most islands in the Volcanic Archipelago of the Canary Islands (<a href="#fig-map" class="quarto-xref" aria-expanded="false">Figure&nbsp;1</a>).</p>
<p><a href="#fig-spatial-plot" class="quarto-xref" aria-expanded="false">Figure&nbsp;2</a> shows the location of recent Earthquakes on La Palma.</p>
</section>
<section id="sec-data-methods" class="level2">
<h2 data-anchor-id="sec-data-methods">Data &amp; Methods</h2>
</section>
<section id="conclusion" class="level2">
<h2 data-anchor-id="conclusion">Conclusion</h2>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-beddorcoetzeestylermcgowanboland2018" class="csl-entry" role="listitem">
Beddor, P. S., Coetzee, A. W., Styler, W., McGowan, K. B., &amp; Boland, J. E. (2018). The time course of individuals’ perception of coarticulatory information is linked to their production: Implications for sound change. <em>Language</em>, <em>94</em>(4), 931–968.
</div>
<div id="ref-beddormcgowanbolandcoetzeebrasher2013" class="csl-entry" role="listitem">
Beddor, P. S., McGowan, K. B., Boland, J. E., Coetzee, A. W., &amp; Brasher, A. (2013). The time course of perception of coarticulation. <em>The Journal of the Acoustical Society of America</em>, <em>133</em>(4), 2350–2366.
</div>
<div id="ref-calder2018" class="csl-entry" role="listitem">
Calder, J. (2018). From <span>“gay lisp”</span> to <span>“fierce queen”</span>: The sociophonetics of sexuality’s most iconic variable. In K. Hall &amp; R. Barrett (Eds.), <em>The oxford handbook of language and sexuality</em> (pp. 1–23).
</div>
<div id="ref-fant1960" class="csl-entry" role="listitem">
Fant, G. (1960). <em>Acoustic theory of speech production</em>. Mouton.
</div>
<div id="ref-kunisakifujisaki1977" class="csl-entry" role="listitem">
Kunisaki, O., &amp; Fujisaki, H. (1977). On the influence of context upon perception of voiceless fricative consonants. <em>Annual Bulletin</em>, <em>11</em>, 85–91.
</div>
<div id="ref-mackMunson2012b" class="csl-entry" role="listitem">
Mack, S., &amp; Munson, B. (2012). The association between/s/quality and perceived sexual orientation of men’s voices: Implicit and explicit measures. <em>Journal of Phonetics</em>, <em>40</em>(1), 198–212.
</div>
<div id="ref-MannRepp1980" class="csl-entry" role="listitem">
Mann, V. A., &amp; Repp, B. H. (1980). Influence of vocalic context on perception of the [ʃ]-[s] distinction. <em>Perception &amp; Psychophysics</em>, <em>28</em>(3), 213–228.
</div>
<div id="ref-McGurkMacDonald1976" class="csl-entry" role="listitem">
McGurk, H., &amp; MacDonald, J. (1976). Hearing lips and seeing voices. <em>Nature</em>, <em>264</em>, 746–748.
</div>
<div id="ref-munson2011" class="csl-entry" role="listitem">
Munson, B. (2011). The influence of actual and imputed talker gender on fricative perception, revisited (l). <em>The Journal of the Acoustical Society of America</em>, <em>130</em>(5), 2631–2634.
</div>
<div id="ref-ohala1984" class="csl-entry" role="listitem">
Ohala, J. J. (1984). An ethological perspective on common cross-language utilization of F₀ of voice. <em>Phonetica</em>, <em>41</em>(1), 1–16.
</div>
<div id="ref-podesvakajino2014" class="csl-entry" role="listitem">
Podesva, R. J., &amp; Kajino, S. (2014). Sociophonetics, gender, and sexuality. <em>The Handbook of Language, Gender, and Sexuality</em>, 103–122.
</div>
<div id="ref-shadle1991" class="csl-entry" role="listitem">
Shadle, C. H. (1991). The effect of geometry on source mechanisms of fricative consonants. <em>Journal of Phonetics</em>, <em>19</em>(3-4), 409–424.
</div>
<div id="ref-strand1999" class="csl-entry" role="listitem">
Strand, E. A. (1999). Uncovering the role of gender stereotypes in speech perception. <em>Journal of Language and Social Psychology</em>, <em>18</em>(1), 86–100.
</div>
<div id="ref-strandJohnson1996" class="csl-entry" role="listitem">
Strand, E. A., &amp; Johnson, K. (1996). Gradient and visual speaker normalization in the perception of fricatives. <em>KONVENS</em>, 14–26.
</div>
<div id="ref-whalen1981" class="csl-entry" role="listitem">
Whalen, D. H. (1981). Effects of vocalic formant transitions and vowel quality on the english [s]–[<span>š</span>] boundary. <em>The Journal of the Acoustical Society of America</em>, <em>69</em>(1), 275–282.
</div>
<div id="ref-whalen1984" class="csl-entry" role="listitem">
Whalen, D. H. (1984). Subcategorical phonetic mismatches slow phonetic judgments. <em>Perception &amp; <span>Psychophysics</span></em>, <em>35</em>, 49–64.
</div>
<div id="ref-whalen1991" class="csl-entry" role="listitem">
Whalen, D. H. (1991). Perception of the english/s/–//distinction relies on fricative noises and transitions, not on brief spectral slices. <em>The Journal of the Acoustical Society of America</em>, <em>90</em>(4), 1776–1785.
</div>
</div>
<div id="fig-map" class="quarto-float quarto-figure quarto-figure-center FigureWithoutNote" data-fignum="1" prefix="" data-custom-style="FigureWithoutNote">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;1</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Map of La Palma</p>
</div>
</figcaption>
<div aria-describedby="fig-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/la-palma-map.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Map of La Palma"><img src="images/la-palma-map.png" class="img-fluid figure-img"></a>
</div>
</figure>
</div>
<div class="quarto-embed-nb-cell FigureWithoutNote" data-custom-style="FigureWithoutNote">
<div id="cell-fig-spatial-plot" class="cell">
<div class="cell-output cell-output-display">
<div id="fig-spatial-plot" class="quarto-float quarto-figure quarto-figure-center" data-fignum="2" alt="A scatterplot of earthquake locations plotting latitude against longitude." prefix="">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-spatial-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;2</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Locations of earthquakes on La Palma since 2017</p>
</div>
</figcaption>
<div aria-describedby="fig-spatial-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-explore-earthquakes-fig-spatial-plot-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Locations of earthquakes on La Palma since 2017"><img src="index_files/figure-html/notebooks-explore-earthquakes-fig-spatial-plot-output-1.png" class="img-fluid figure-img" alt="A scatterplot of earthquake locations plotting latitude against longitude."></a>
</div>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{laycock2024,
  author = {Laycock, Kyler and B McGowan, Kevin},
  title = {Removing the Disguise: The Matched Guise Technique and
    Listener Awareness},
  date = {2024-05-21},
  langid = {en},
  abstract = {Sociophonetic perception is often studied using versions
    of the matched guise technique. Linguists using this technique
    appear united in the methodological assumptions that participants
    believe the manipulation and that this belief influences perception
    below the level of introspective awareness. We report an audiovisual
    matched guise experiment with a novel “unhidden” instruction
    condition. The basic task is a replication of the Strand effect
    {[}@strandJohnson1996; @strand1999{]}. Participants in the
    “unhidden” condition were instructed that the man or woman in the
    photo did not represent the voice they were listening to.
    Participants in both guises exhibited the Strand effect to nearly
    numerically identical extents. This result suggests that
    participants need not believe a link exists between a voice and a
    purported social category for visually-cued social information to
    influence segmental perception. We explore the implications of this
    result for the MGT and for theories of social awareness and speech
    perception more broadly.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-laycock2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Laycock, K., &amp; B McGowan, K. (2024, May 21). <em>Removing the
disguise: the matched guise technique and listener awareness</em>.
Awareness and Control of Sociolinguistic Variation.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="kbmcgowan/play-manuscript" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->

<div id="criticnav">
<ul>
<li id="markup-button">Markup</li>
<li id="original-button">Original</li>
<li id="edited-button">Edited</li>
</ul>
</div>

<script type="text/javascript">
  function critic() {

      $('.content').addClass('markup');
      $('#markup-button').addClass('active');
      $('ins.break').unwrap();
      $('span.critic.comment').wrap('<span class="popoverc" /></span>');
      $('span.critic.comment').before('&#8225;');
  }

  function original() {
      $('#original-button').addClass('active');
      $('#edited-button').removeClass('active');
      $('#markup-button').removeClass('active');

      $('.content').addClass('original');
      $('.content').removeClass('edited');
      $('.content').removeClass('markup');
  }

  function edited() {
      $('#original-button').removeClass('active');
      $('#edited-button').addClass('active');
      $('#markup-button').removeClass('active');

      $('.content').removeClass('original');
      $('.content').addClass('edited');
      $('.content').removeClass('markup');
  } 

  function markup() {
      $('#original-button').removeClass('active');
      $('#edited-button').removeClass('active');
      $('#markup-button').addClass('active');

      $('.content').removeClass('original');
      $('.content').removeClass('edited');
      $('.content').addClass('markup');
  }

  var o = document.getElementById("original-button");
  var e = document.getElementById("edited-button");
  var m = document.getElementById("markup-button");

  window.onload = critic();
  o.onclick = original;
  e.onclick = edited;
  m.onclick = markup;
</script>
<script>var lightboxQuarto = GLightbox({"selector":".lightbox","openEffect":"zoom","descPosition":"bottom","loop":false,"closeEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>