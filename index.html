<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kyler Laycock">
<meta name="author" content="&nbsp;Kevin B McGowan">
<meta name="dcterms.date" content="2024-10-26">
<meta name="keywords" content="awareness, control, inverse matched guise, sociophonetic perception">

<title>Removing the disguise: the matched guise technique and listener awareness</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-3a01e2046221230fdceeea94b1ec5d67.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-429efd594779f4c57e5c14c6e080f5ea.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="Removing the disguise: the matched guise technique and listener awareness">
<meta name="citation_abstract" content="Sociophonetic perception is often studied using versions of the matched guise technique. Linguists using this technique appear united in the methodological assumptions that participants believe the manipulation and that this belief influences perception below the level of introspective awareness. We report an audiovisual matched guise experiment with a novel &amp;amp;#039;unhidden' instruction condition. The basic task is a replication of the Strand effect [@strandJohnson1996; @strand1999]. Participants in the 'unhidden' condition were instructed that the man or woman in the photo did not represent the voice they were listening to. Participants in both guises exhibited the Strand effect to nearly numerically identical extents. This result suggests that participants need not believe a link exists between a voice and a purported social category for visually-cued social information to influence segmental perception. We explore the implications of this result for the MGT and for theories of social awareness and speech perception more broadly.
">
<meta name="citation_keywords" content="awareness,control,inverse matched guise,sociophonetic perception">
<meta name="citation_author" content="Kyler Laycock">
<meta name="citation_author" content="&amp;amp;nbsp;Kevin B McGowan">
<meta name="citation_publication_date" content="2024-10-26">
<meta name="citation_cover_date" content="2024-10-26">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-10-26">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Awareness and Control of Sociolinguistic Variation">
<meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;,citation_author=R Development Core Team;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.R-project.org;">
<meta name="citation_reference" content="citation_title=Experimental investigations of sociolinguistic knowledge;,citation_author=Laura Staum Casasanto;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_dissertation_institution=Stanford University Department of Linguistics;">
<meta name="citation_reference" content="citation_title=What do listeners know about sociolinguistic variation?;,citation_author=Laura Staum Casasanto;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=15;,citation_journal_title=Penn Working Papers in Linguistics: Selected papers from NWAV 37.;">
<meta name="citation_reference" content="citation_title=How do listeners represent sociolinguistic knowledge?;,citation_author=Laura Staum Casasanto;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 31st annual meeting of the cognitive science society;">
<meta name="citation_reference" content="citation_title=Does social information influence sentence processing?;,citation_author=Laura Staum Casasanto;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=Proceedings of the 30th annual meeting of the cognitive science society;">
<meta name="citation_reference" content="citation_title=The wildcat corpus of native- and foreign-accented english: Communicative efficiency across conversational dyads with varying language alignment profiles;,citation_author=K. J. Van Engen;,citation_author=M. Baese-Berk;,citation_author=R. E. Baker;,citation_author=A. Choi;,citation_author=M. Kim;,citation_author=A. R. Bradlow;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=Language and Speech;">
<meta name="citation_reference" content="citation_title=Discriminability along the voicing continuum: Cross-language tests.;,citation_author=A. S. Abramson;,citation_author=L. Lisker;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_conference_title=Proceedings of the sixth international congress of phonetic sciences prague 1967;,citation_conference=Academia;">
<meta name="citation_reference" content="citation_title=A comparison of vowel normalization procedures for language variation research;,citation_author=Patti Adank;,citation_author=Roel Smits;,citation_author=Roeland Hout;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=5;,citation_volume=116;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=The social life of cultural value;,citation_author=Asif Agha;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3/4;,citation_volume=23;,citation_journal_title=Language and Communication;">
<meta name="citation_reference" content="citation_title=Voice, footing, enregisterment.;,citation_author=Asif Agha;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=15;,citation_journal_title=Journal of Linguistic Anthropology;">
<meta name="citation_reference" content="citation_title=Stereotypes and registers of honorific language;,citation_abstract=Honorific registers are formally discrete but functionally stratified systems, in the sense that an apparently bounded set of linguistic forms allows lan- guage users to calculate many concurrent aspects of the pragmatic context of language use. This paper argues that native stereotypes about language struc- ture and use play a critical role in formulating the pragmatic value(s) of register systems. The linguist can neither isolate the forms belonging to a register, nor explain their significance in use, independently of appeal to native stereotypes about language. The paper discusses methods for the em- pirical study and analysis of such stereotypes. Stereotypes that formulate the social identity of language users play a special role within register systems, grounding the significance of pragmatic acts in the attributes of pragmatic actors. Much of the discussion focuses on how such stereotypes are formu- lated and what their social consequences are. (Honorifics, pragmatics, meta- pragmatics, stereotypes, registers, deference, identity, Tibetan).;,citation_author=Asif Agha;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=27;,citation_journal_title=Language in Society;">
<meta name="citation_reference" content="citation_title=Tracking the time course of spoken word recognition: Evidence for continuous mapping models.;,citation_author=P. D Allopenna;,citation_author=J. S. Magnuson;,citation_author=M. K. Tanenhaus;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=38;,citation_journal_title=Journal of Memory and Language;">
<meta name="citation_reference" content="citation_title=Language, gender, and ideology in japanese professional matchmaking.;,citation_author=Erika Renée Alpert;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_dissertation_institution=University of Michigan, Department of Anthropology;">
<meta name="citation_reference" content="citation_title=Stoicism or shyness?: Japanese professional matchmakers and new masculine conversational ideals;,citation_author=Erika Renée Alpert;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=3;,citation_journal_title=Journal of Language and Sexuality;,citation_publisher=John Benjamins;">
<meta name="citation_reference" content="citation_title=The dogma of isomorphism: A case study from speech perception;,citation_abstract=In this paper I provide a metatheoretical analysis of speech perception research. I argue that the central turning point in the history of speech perception research has not been well understood. While it is widely thought to mark a decisive break with what I call &amp;amp;amp;quot;the alphabetic conception of speech,&amp;quot; I argue that it instead marks the entrenchment of this conception of speech. In addition, I argue that the alphabetic conception of speech continues to underwrite speech perception research today and moreover that it functions as a dogma which ought to be rejected.;,citation_author=Irene Appelbaum;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://www.jstor.org/stable/188775;,citation_issn=00318248;,citation_volume=66;,citation_journal_title=Philosophy of Science;,citation_publisher=The University of Chicago Press on behalf of the Philosophy of Science Association;">
<meta name="citation_reference" content="citation_title=Overhearing a language during childhood.;,citation_author=T. K. Au;,citation_author=L. M. Knightly;,citation_author=S. A. Jun;,citation_author=J. S. Oh;,citation_publication_date=2002-05;,citation_cover_date=2002-05;,citation_year=2002;,citation_issue=3;,citation_volume=13;,citation_journal_title=Psychological Science;">
<meta name="citation_reference" content="citation_title=The CELEX lexical data base on CD-ROM;,citation_author=R. H. Baayen;,citation_author=R. Piepenbrock;,citation_author=H. Van Rijn;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=Analyzing linguistic data: A practical introduction to statistics using r.;,citation_author=R. H. Baayen;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Introduction to the thematic issue;,citation_author=Anna M. Babel;,citation_author=Kathryn Campbell-Kibler;,citation_author=Kevin B. McGowan;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Accentedness ratings do not predict sensitivity to regional variation in vowel quality.;,citation_author=Kathryn Campbell-Kibler;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Why don’t all contact features act alike? Contact features as enregistered features;,citation_author=Anna M. Babel;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=4;,citation_journal_title=Journal of Language Contact;">
<meta name="citation_reference" content="citation_title=Contact and contrast in valley spanish;,citation_author=Anna M. Babel;,citation_publication_date=2010-05;,citation_cover_date=2010-05;,citation_year=2010;,citation_dissertation_institution=University of Michigan;">
<meta name="citation_reference" content="citation_title=Dizque, evidentiality, and stance in valley spanish;,citation_abstract=While information sources have largely been treated as transparent categories in the literature on evidentiality, understandings of information source can be culturally and situationally variable. This article proposes that the strictly linguistic information encoded in reportative evidentials cannot be cleanly separated from social influences. Defining an information source, especially when referring to information reported by another person, serves social purposes, such as casting doubt, framing gossip, distancing oneself, or indicating empathy. Using the concept of speaker stance, this study explores the relationship of information source to the interpersonal relationships and interactions that are encoded in this linguistic form. Data from a contact variety of Spanish spoken in central Bolivia provide evidence that diz(que), a Spanish word, has undergone influence from Quechua to become a systematic reportative evidential marker in this variety of Bolivian Spanish. Speakers use information source marking in order to shade subtleties of relationships and authority. (Evidentiality, speaker stance, Andean Spanish, Bolivian Spanish, language contact, linguistic anthropology);,citation_author=Anna M. Babel;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=04;,citation_doi=10.1017/S0047404509990236;,citation_volume=38;,citation_journal_title=Language in Society;">
<meta name="citation_reference" content="citation_title=A semiotic approach to awareness and control;,citation_author=Anna M. Babel;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Accessing psycho-acoustic perception and language-specific perception with speech sounds;,citation_author=Molly Babel;,citation_author=Keith Johnson;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=http://dx.doi.org/10.1515/LABPHON.2010.009;,citation_issue=1;,citation_doi=10.1515/LABPHON.2010.009;,citation_isbn=1868-6346;,citation_volume=1;,citation_journal_title=Laboratory Phonology;,citation_publisher=De Gruyter;">
<meta name="citation_reference" content="citation_title=Phonetic and social selectivity in speech accommodation.;,citation_author=Molly Babel;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_dissertation_institution=University of California, Berkeley;">
<meta name="citation_reference" content="citation_title=The dialogic imagination: Four essays;,citation_author=Mikhail Mikhaı̆lovich Bakhtin;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;">
<meta name="citation_reference" content="citation_title=Word durations in non-native english;,citation_abstract=In this study, we compare the effects of English lexical features on word duration for native and non-native English speakers and for non-native speakers with different L1s and a range of L2 experience. We also examine whether non-native word durations lead to judgments of a stronger foreign accent. We measured word durations in English paragraphs read by 12 American English (AE), 20 Korean, and 20 Chinese speakers. We also had AE listeners rate the [“]accentedness” of these non-native speakers. AE speech had shorter durations, greater within-speaker word duration variance, greater reduction of function words, and less between-speaker variance than non-native speech. However, both AE and non-native speakers showed sensitivity to lexical predictability by reducing second mentions and high-frequency words. Non-native speakers with more native-like word durations, greater within-speaker word duration variance, and greater function word reduction were perceived as less accented. Overall, these findings identify word duration as an important and complex feature of foreign-accented English.;,citation_author=Rachel E. Baker;,citation_author=Melissa Baese-Berk;,citation_author=Laurent Bonnasse-Gahot;,citation_author=Midam Kim;,citation_author=Kristin J. Van Engen;,citation_author=Ann R. Bradlow;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6WKT-51XNX42-1/2/a95d5f33c14374b0067473f90be70480;,citation_doi=DOI: 10.1016/j.wocn.2010.10.006;,citation_issn=0095-4470;,citation_volume=In Press, Corrected Proof;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=The english lexicon project;,citation_author=David Balota;,citation_author=Melvin Yap;,citation_author=Keith Hutchison;,citation_author=Michael Cortese;,citation_author=Brett Kessler;,citation_author=Bjorn Loftis;,citation_author=James Neely;,citation_author=Douglas Nelson;,citation_author=Greg Simpson;,citation_author=Rebecca Treiman;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=http://dx.doi.org/10.3758/BF03193014;,citation_issue=3;,citation_doi=10.3758/BF03193014;,citation_isbn=1554-351X;,citation_volume=39;,citation_journal_title=Behavior Research Methods;,citation_publisher=Springer New York;">
<meta name="citation_reference" content="citation_title=The emergence of the unmarked;,citation_author=Rusty Barrett;,citation_author=L Zimman;,citation_author=J Davis;,citation_author=J Raclaw;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=Queer excursions: Retheorizing binaries in language, gender, and sexuality;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=lme4: Linear mixed-effects models using S4 classes;,citation_author=Douglas Bates;,citation_author=Martin Maechler;,citation_author=Ben Bolker;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://CRAN.R-project.org/package=lme4;">
<meta name="citation_reference" content="citation_title=An attempt at a theory of phonetic alternations.[translation of versuch einer theorie phonetischer alternationen: Ein kapitel aus der psychophonetik.];,citation_author=Jan Baudouin de Courtenay;,citation_publication_date=1895;,citation_cover_date=1895;,citation_year=1895;,citation_publisher=1972). A Baudouin de Courtenay anthology. Bloomington: Indiana University Press;">
<meta name="citation_reference" content="citation_title=The perceptual TIme course of coarticulatory nasalization (poster);,citation_author=Patrice Speeter Beddor;,citation_author=Julie Boland;,citation_author=Andries Coetzee;,citation_author=Kevin B. McGowan;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=The time course of individuals’ perception of coarticulatory information is linked to their production: Implications for sound change;,citation_author=Patrice Speeter Beddor;,citation_author=Andries W. Coetzee;,citation_author=Will Styler;,citation_author=Kevin B. McGowan;,citation_author=Julie E. Boland;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=94;,citation_journal_title=Language;,citation_publisher=Linguistic Society of America;">
<meta name="citation_reference" content="citation_title=The time course of perception of coarticulation;,citation_author=Patrice Speeter Beddor;,citation_author=Kevin B. McGowan;,citation_author=Julie E. Boland;,citation_author=Andries W. Coetzee;,citation_author=Anthony Brasher;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=133;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=A coarticulatory path to sound change.;,citation_abstract=Although coarticulatory variation is largely systematic, and serves as useful information for listeners, such variation is nonetheless linked to sound change. This article explores the articulatory and perceptual interactions between a coarticulatory source and its effects, and how these interactions likely contribute to change. The focus is on the historical change VN (phonetically, ṼN) &amp;amp;amp;gt; Ṽ, but with more general attention to how a gesture associated with a source segment comes to be reinterpreted as distinctively, rather than coarticulatorily, associated with a nearby vowel or consonant. Two synchronic factors are hypothesized to contribute to reinterpretation: (i) articulatory covariation between the duration of the coarticulatory source (here, N) and the temporal extent of its effects (Ṽ), and (ii) perceived equivalence between source and effect. Experimental support for both hypotheses is provided. Additionally, the experimental data are linked to the historical situation by showing that the contextual conditions that trigger (i) and (ii) parallel the conditions that historically influence phonologization of vowel nasalization.;,citation_author=Patrice Speeter Beddor;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=4;,citation_volume=85;,citation_journal_title=Language;">
<meta name="citation_reference" content="citation_author=Benjamin Munson;,citation_author=Kayleigh Ryherd;,citation_author=Sara Kemper;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1515/ling-2017-0021;,citation_issue=5;,citation_doi=doi:10.1515/ling-2017-0021;,citation_volume=55;,citation_journal_title=Linguistics;">
<meta name="citation_reference" content="citation_title=The interlanguage speech intelligibility benefit;,citation_author=Tessa Bent;,citation_author=Ann R. Bradlow;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3;,citation_volume=114;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=On scepticism about unconscious perception;,citation_author=Jacob Berger;,citation_author=Myrto Mylopoulos;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=11-12;,citation_volume=26;,citation_journal_title=Journal of Consciousness Studies;,citation_publisher=Imprint Academic;">
<meta name="citation_reference" content="citation_title=The emergence of native-language phonological influences in infants: A perceptual assimilation model.;,citation_author=C. T. Best;,citation_editor=J. C. Goodman;,citation_editor=H. C. Nusbaum;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_inbook_title=The development of speech perception: The transition from speech sounds to spoken words;">
<meta name="citation_reference" content="citation_title=Discrimination of non-native consonant contrasts varying in perceptual assimilation to the listener’s native phonological system.;,citation_author=C. T. Best;,citation_author=G. W. McRoberts;,citation_author=E. Goodell;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=109;,citation_volume=109;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=A direct realist perspective on cross-language speech perception.;,citation_author=C. T. Best;,citation_editor=W. Strange;,citation_editor=J. J. Jenkins;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_inbook_title=Cross-language speech perception;">
<meta name="citation_reference" content="citation_title=Articulating the perceptual assimilation model (PAM): Perceptual assimilation in relation to articulatory organs and their constriction gestures.;,citation_author=Catherine T. Best;,citation_author=Louis Goldstein;,citation_author=Michael D. Tyler;,citation_author=Hosung Nam;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=http://link.aip.org/link/?JAS/125/2758/2;,citation_issue=4;,citation_volume=125;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Language;,citation_author=Leonard Bloomfield;,citation_publication_date=1933;,citation_cover_date=1933;,citation_year=1933;">
<meta name="citation_reference" content="citation_title=Praat;,citation_author=Paul Boersma;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_journal_title=a system for doing phonetics by computer. Glot International;">
<meta name="citation_reference" content="citation_title=Bidirectional effects of priming in speech perception: Social-to-lexical and lexical-to-social;,citation_author=Dominique A. Bouavichith;,citation_author=Ian C. Calloway;,citation_author=Justin T. Craft;,citation_author=Tamarae Hildebrandt;,citation_author=Stephen J. Tobin;,citation_author=Patrice S. Beddor;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1121/1.5101933;,citation_volume=145;,citation_journal_title=The Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Crosslinguistic perceptions of /s/ among english, french, and german listeners;,citation_author=Zac Boyd;,citation_author=Josef Fruehwald;,citation_author=Lauren Hall-Lew;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_doi=10.1017/S0954394521000089;,citation_volume=33;,citation_journal_title=Language Variation and Change;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Semantic-contextual and acoustic-phonetic enhancements for english sentence-in-noise recognition by native and non-native listeners.;,citation_author=A. R. Bradlow;,citation_author=J. A. Alexander;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=4;,citation_volume=121;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Perceptual adaptation to non-native speech;,citation_abstract=This study investigated talker-dependent and talker-independent perceptual adaptation to foreign-accent English. Experiment 1 investigated talker-dependent adaptation by comparing native English listeners’ recognition accuracy for Chinese-accented English across single and multiple talker presentation conditions. Results showed that the native listeners adapted to the foreign-accented speech over the course of the single talker presentation condition with some variation in the rate and extent of this adaptation depending on the baseline sentence intelligibility of the foreign-accented talker. Experiment 2 investigated talker-independent per- ceptual adaptation to Chinese-accented English by exposing native English listeners to Chi- nese-accented English and then testing their perception of English produced by a novel Chinese-accented talker. Results showed that, if exposed to multiple talkers of Chinese- accented English during training, native English listeners could achieve talker-independent adaptation to Chinese-accented English. Taken together, these findings provide evidence for highly flexible speech perception processes that can adapt to speech that deviates substantially from the pronunciation norms in the native talker community along multiple acoustic-pho- netic dimensions.;,citation_author=Ann R. Bradlow;,citation_author=Tessa Bent;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=106;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=The effect of listeners’ anticipations on the intelligibility of heard speech;,citation_abstract=The experiment described demonstrates the effect of prior set on the intelligibility of heard speech. Twenty subjects hear the same twelve word sentences in the presence of noise on five occasions. The sentences fall into two groups — one unprefaced by any indication of topic, the other prefaced on each occasion by a different word, which subjects are told is the topic to which the group refers. Only one of the sentences in the latter group is fully appropriate to each word given. Wherever this conjunction occurs in the order of testing, the sentence involved reaches its highest level of intelligibility. When inappropriately prefaced, sentences are misinterpreted to a considerable extent or resist interpretation.;,citation_author=D. J. Bruce;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_issue=2;,citation_volume=1;,citation_journal_title=Language and Speech;">
<meta name="citation_reference" content="citation_title=Locating identity in language;,citation_author=Mary Bucholtz;,citation_author=Kira Hall;,citation_editor=Carmen Llamas;,citation_editor=Dominic Watt;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_inbook_title=Language and identities;">
<meta name="citation_reference" content="citation_title=Embodied sociolinguistics;,citation_author=Mary Bucholtz;,citation_author=Kira Hall;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=1;,citation_journal_title=Sociolinguistics: theoretical debates;,citation_publisher=Cambridge University Press Cambridge;">
<meta name="citation_reference" content="citation_title=From “sex differences” to gender variation in sociolinguistics;,citation_author=Mary Bucholtz;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=3;,citation_volume=8;,citation_journal_title=University of Pennsylvania Working Papers in Linguistics;">
<meta name="citation_reference" content="citation_title=From “gay lisp” to “fierce queen”: The sociophonetics of sexuality’s most iconic variable;,citation_author=J Calder;,citation_editor=Kira Hall;,citation_editor=Rusty Barrett;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_inbook_title=The oxford handbook of language and sexuality;">
<meta name="citation_reference" content="citation_title=From “gay lisp” to “fierce queen”: The sociophonetics of sexuality’s most iconic variable;,citation_author=Jeremy Calder;,citation_editor=Kira Hall;,citation_editor=Rusty Barrett;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_inbook_title=The oxford handbook of language and sexuality;">
<meta name="citation_reference" content="citation_title=Deliberative control in audiovisual sociolinguistic perception;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_volume=25;,citation_journal_title=Journal of Sociolinguistics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Intersecting variables and perceived sexual orientation in men;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=86;,citation_journal_title=American Speech;,citation_publisher=Duke University Press;">
<meta name="citation_reference" content="citation_title=Listener perceptions of sociolinguistic variables: The case of (ING);,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=Accent,(ING), and the social logic of listener perceptions;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=82;,citation_journal_title=American speech;,citation_publisher=Duke University Press;">
<meta name="citation_reference" content="citation_title=Toward a cognitively realistic model of meaningful sociolinguistic variation;,citation_author=Kathryn Campbell-Kibler;,citation_editor=Anna M. Babel;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_inbook_title=Awareness and control in sociolinguistic research;">
<meta name="citation_reference" content="citation_title=Sounding chinese and listening chinese: Awareness and knowledge in the laboratory;,citation_author=Kevin B. McGowan;,citation_editor=Anna M. Babel;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_inbook_title=Awareness and control in sociolinguistic research;">
<meta name="citation_reference" content="citation_title=Listener perceptions of sociolinguistic variables: The case of (ING);,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=Accent,(ING), and the social logic of listener perceptions;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=82;,citation_journal_title=American speech;,citation_publisher=Duke University Press;">
<meta name="citation_reference" content="citation_title=Deliberative control in audiovisual sociolinguistic perception;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_volume=25;,citation_journal_title=Journal of Sociolinguistics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Verbal guise test: Problems and solutions;,citation_author=Ka Long Roy Chan;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=Academia Letters;">
<meta name="citation_reference" content="citation_title=Production of phonetic and phonological contrast by heritage speakers of mandarin.;,citation_author=Charles B. Chang;,citation_author=Yao Yao;,citation_author=Erin F. Haynes;,citation_author=Russell Rhodes;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=The effects of explicit knowledge of and implicit attitudes about race on adult perceptions of children’s speech.;,citation_author=A. L. Christy;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Rapid adaptation to foreign-accented english;,citation_author=Constance M. Clarke;,citation_author=Merrill F. Garrett;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=http://link.aip.org/link/?JAS/116/3647/1;,citation_issue=6;,citation_doi=10.1121/1.1815131;,citation_volume=116;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Effects of talker variability on perceptual learning of dialects;,citation_author=Cynthia G Clopper;,citation_author=David B Pisoni;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=3;,citation_volume=47;,citation_journal_title=Language and speech;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=Linguistic experience and the perceptual classification of dialect variation.;,citation_author=C. G. Clopper;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_dissertation_institution=Indiana University;">
<meta name="citation_reference" content="citation_title=Allophonic cues to syllabification;,citation_author=Andries Coetzee;,citation_author=Kevin B. McGowan;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Heeding the voice of experience: The role of talker variation in lexical access;,citation_author=Sarah C. Creel;,citation_author=Richard N. Aslin;,citation_author=Michael K. Tanenhaus;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=106;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=On-line acoustic and semantic interpretation of talker information;,citation_abstract=Recent work demonstrates that listeners utilize talker-specific information in the speech signal to inform real-time language processing. However, there are multiple representational levels at which this may take place. Listeners might use acoustic cues in the speech signal to access the talker’s identity and information about what they tend to talk about, which then immediately constrains processing. Alternatively, or simultaneously, listeners might compare the signal to acoustically-detailed representations of words, without awareness of the talker’s identity. In a series of eye-tracked comprehension experiments, we explore the circumstances under which listeners utilize talker-specific information. Experiments 1 and 2 demonstrate talker-specific recognition benefits for newly-learned words both in isolation (Experiment 1) and with preceding context (Experiment 2), but suggest that listeners do not strongly semantically associate talkers with referents. Experiment 3 demonstrates that listeners can recognize talkers rapidly, almost as soon as acoustic information is available, and can associate talkers with multiple arbitrary referents. Experiment 4 demonstrates that if talker identity is highly diagnostic on each trial, listeners readily associate talkers with specific referents, but do not seem to make such associations when diagnostic value is low. Implications for speech processing, talker processing, and learning are discussed.;,citation_author=Sarah C. Creel;,citation_author=Melanie A. Tumlin;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/pii/S0749596X11000647;,citation_doi=DOI: 10.1016/j.jml.2011.06.005;,citation_issn=0749-596X;,citation_volume=In Press, Corrected Proof;,citation_journal_title=Journal of Memory and Language;">
<meta name="citation_reference" content="citation_title=Detection theory: A user’s guide;,citation_author=Daniel Creelman;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;">
<meta name="citation_reference" content="citation_title=The emergent paradigm in laboratory phonology: Phonological categories and statistical generalisation in cutler, beckman and edwards, frisch and bréa-spahn, kapatsinski, and walter.;,citation_author=Karen Croot;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=1;,citation_journal_title=Journal of Laboratory Phonology;">
<meta name="citation_reference" content="citation_title=How abstract phonemic categories are necessary for coping with speaker-related variation.;,citation_author=A. Cutler;,citation_author=F. Eisner;,citation_author=J. M. McQueen;,citation_author=D. Norris;,citation_editor=C. Fougeron;,citation_editor=B. Kühnert;,citation_editor=M. D’Imperio;,citation_conference_title=Laboratory phonology 10;,citation_conference=Association for Laboratory Phonology; de Gruyter;">
<meta name="citation_reference" content="citation_title=Subcategorical mismatches and the time course of lexical access: Evidence for lexical competition;,citation_author=Delphine Dahan;,citation_author=James S. Magnuson;,citation_author=Michael K. Tanenhaus;,citation_author=Ellen M. Hogan;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5/6;,citation_volume=16;,citation_journal_title=Language and Cognitive Processes;">
<meta name="citation_reference" content="citation_title=Pharyngeal dimensions in healthy men and women;,citation_author=Mauro Miguel Daniel;,citation_author=Maria Cecı́lia Lorenzi;,citation_author=Claudia Costa Leite;,citation_author=Geraldo Lorenzi-Filho;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=62;,citation_journal_title=Clinics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=An acoustic study of so-called creaky voice in tianjin mandarin;,citation_author=D. S. Davison;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_volume=78;,citation_journal_title=Working Papers in Phonetics;">
<meta name="citation_reference" content="citation_title=Speech perception;,citation_author=Lotto A. J. Holt L. L. Diehl;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=55;,citation_journal_title=Annual Review of Psychology;">
<meta name="citation_reference" content="citation_title=Sociophonetic variation in speech perception;,citation_abstract=Abstract In this paper, I review previous research that investigates sociophonetic variation in speech perception. I also argue that more speech perception work is needed to inform work on variation in speech production, particularly in the areas of language change and stereotype formation. Exploring the mental representations and processing of social and linguistic information as well as treating phonetic and social factors as multidimensional and interacting will take future work in sociophonetics in new and exciting directions.;,citation_author=Katie Drager;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=http://dx.doi.org/10.1111/j.1749-818X.2010.00210.x;,citation_issue=7;,citation_doi=10.1111/j.1749-818X.2010.00210.x;,citation_issn=1749-818X;,citation_volume=4;,citation_journal_title=Language and Linguistics Compass;,citation_publisher=Blackwell Publishing Ltd;">
<meta name="citation_reference" content="citation_title=Experimental methods in sociolinguistics;,citation_author=Katie Drager;,citation_editor=Janet Holmes;,citation_editor=Kirk Hazen;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Research methods in sociolinguistics: A practical guide;">
<meta name="citation_reference" content="citation_title=Experimental methods in sociolinguistics;,citation_author=Katie Drager;,citation_editor=Janet Holmes;,citation_editor=Kirk Hazen;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Research methods in sociolinguistics: A practical guide;">
<meta name="citation_reference" content="citation_title=Epenthetic vowels in japanese: A perceptual illusion?;,citation_author=Emmanuel Dupoux;,citation_author=Kazuhiko Kakehi;,citation_author=Yuki Hirose;,citation_author=Christophe Pallier;,citation_author=Jacques Mehler;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=25;,citation_journal_title=Journal of Experimental Psychology: Human Perception and Performance;">
<meta name="citation_reference" content="citation_title=Eye-movements as a window into spoken language comprehension in natural contexts.;,citation_author=K. M. Eberhard;,citation_author=Sedivy J. C. Spivey-Knowlton;,citation_author=M. K. Tanenhaus;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_volume=24;,citation_journal_title=Journal of Psycholinguistic Research;">
<meta name="citation_reference" content="citation_title=Seeing black: Race, crime, and visual processing.;,citation_author=J. L. Eberhardt;,citation_author=P. A. Goff;,citation_author=V. J. Purdie;,citation_author=P. G. Davies;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=87;,citation_journal_title=Journal of Personality and Social Psychology;">
<meta name="citation_reference" content="citation_title=Non-binary approaches to gender and sexuality;,citation_author=Penelope Eckert;,citation_author=Robert J Podesva;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The Routledge handbook of language, gender, and sexuality;,citation_publisher=Routledge;">
<meta name="citation_reference" content="citation_title=Variation and the indexical field 1;,citation_author=Penelope Eckert;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=4;,citation_volume=12;,citation_journal_title=Journal of sociolinguistics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Three waves of variation study: The emergence of meaning in the study of sociolinguistic variation;,citation_author=Penelope Eckert;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=41;,citation_journal_title=Annual review of Anthropology;">
<meta name="citation_reference" content="citation_title=Dual-process theories of higher cognition: Advancing the debate;,citation_author=Jonathan St BT Evans;,citation_author=Keith E Stanovich;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=8;,citation_journal_title=Perspectives on psychological science;,citation_publisher=Sage Publications Sage CA: Los Angeles, CA;">
<meta name="citation_reference" content="citation_title=Dual-processing accounts of reasoning, judgment, and social cognition;,citation_author=Jonathan St BT Evans;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=59;,citation_journal_title=Annu. Rev. Psychol.;,citation_publisher=Annual Reviews;">
<meta name="citation_reference" content="citation_title=Acoustic theory of speech production;,citation_author=G. Fant;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=Language lateralization development in children with autism: Insights from the late field magnetoencephalogram;,citation_abstract=Left hemisphere dominance represents the typical language lateralization profile for the majority of neurologically healthy, right-handed individuals. We investigated hemispheric dominance for language in language-impaired children with autism and typically developing controls to investigate the hypothesis that atypical functional specialization for language represents one component of developmental language impairment in autism. Late field magnetoencephalography (MEG) recordings were used to calculate a hemispheric Lateralization Index from the neuromagnetic activity evoked by passive auditory presentation of vowel stimuli. Results indicate that children with autism and typically developing children follow opposite maturational trajectories in language lateralization; while leftward lateralization (i.e. left hemisphere dominance) emerged from bilaterally symmetric neuronal activation as age increased in our sample of typically developing children, rightward lateralization emerged from bilaterally symmetric activity as age increased in our sample of children with autism.;,citation_author=Elissa J. Flagg;,citation_author=Janis E. Oram Cardy;,citation_author=Wendy Roberts;,citation_author=Timothy P. L. Roberts;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6T0G-4GNKS0R-2/2/41662293c8249f0e45505bc7ad7fccc4;,citation_issue=2;,citation_doi=DOI: 10.1016/j.neulet.2005.05.037;,citation_issn=0304-3940;,citation_volume=386;,citation_journal_title=Neuroscience Letters;">
<meta name="citation_reference" content="citation_title=Assessing bilingual dominance;,citation_author=J. Flege;,citation_author=I. MacKay;,citation_author=T. Piske;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=23;,citation_journal_title=Applied Psycholinguistics;">
<meta name="citation_reference" content="citation_title=The modularity of mind.;,citation_author=J. Fodor;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;">
<meta name="citation_reference" content="citation_title=Exploring social-indexical variation: A long past but a short history. Laboratory phonology;,citation_author=P. Foulkes;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=1;,citation_journal_title=Journal of Laboratory Phonology;">
<meta name="citation_reference" content="citation_title=The social life of phonetics and phonology;,citation_author=Paul Foulkes;,citation_author=Gerard Docherty;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=34;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Representation and competition in the perception of spoken words;,citation_author=M Gareth Gaskell;,citation_author=William D Marslen-Wilson;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=2;,citation_volume=45;,citation_journal_title=Cognitive psychology;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Phonetic diversity, statistical learning, and acquisition of phonology;,citation_author=Janet B Pierrehumbert;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=2-3;,citation_volume=46;,citation_journal_title=Language and speech;">
<meta name="citation_reference" content="citation_title=An event approach to the study of speech perception from a direct— realist perspective.;,citation_author=C. A. Fowler;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_volume=14;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Listeners do hear sounds, not tongues.;,citation_author=Carol A. Fowler;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=3;,citation_volume=99;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Compensation for coarticulation reflects gesture perception, not spectral contrast;,citation_author=Carol A. Fowler;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=2;,citation_volume=68;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;">
<meta name="citation_reference" content="citation_title=Phonetic categorization in auditory word perception;,citation_author=William F. Ganong;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_volume=6;,citation_journal_title=Journal of Experimental Psychology: Human Perception and Performance;">
<meta name="citation_reference" content="citation_title=Classification of self-normalized vowels;,citation_abstract=The classical vowel measurements of Peterson and Barney in 1952 have been reexamined on an individual basis to determine the minimum dimensionality required to classify a single talker’s vowels, and the minimum number of vowels required to specify the dimensions. It was found that two formants are adequate for this purpose, and that no more than three vowels are required to scale the frequencies of two-formant space. Within that self-normalized space, all vowels have standard locations which are similar for all talkers.;,citation_author=L. Gerstman;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=1;,citation_issn=0018-9278;,citation_volume=16;,citation_journal_title=Audio and Electroacoustics, IEEE Transactions on;">
<meta name="citation_reference" content="citation_title=Aero-tactile integration in speech perception;,citation_author=Bryan Gick;,citation_author=Donald Derrick;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=462;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Within-speaker variation in passing for a native speaker;,citation_author=Ksenia Gnevsheva;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_volume=21;,citation_journal_title=International Journal of Bilingualism;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=A complementary-systems approach to abstract and episodic speech perception.;,citation_author=S. D. Goldinger;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of 2007 international congress on phonetic sciences.;">
<meta name="citation_reference" content="citation_title=Puzzle-solving science: The quixotic quest for units in speech perception;,citation_abstract=Although speech signals are continuous and variable, listeners experience segmentation and linguistic structure in perception. For years, researchers have tried to identify the basic building-block of speech perception. In that time, experimental methods have evolved, constraints on stimulus materials have evolved, sources of variance have been identified, and computational models have been advanced. As a result, the slate of candidate units has increased, each with its own empirical support. In this article, we endorse Grossberg’s adaptive resonance theory (ART), proposing that speech units are emergent properties of perceptual dynamics. By this view, units only “exist” when disparate features achieve resonance, a level of perceptual coherence that allows conscious encoding. We outline basic principles of ART, then summarize five experiments. Three experiments assessed the power of social influence to affect phoneme-syllable competitions. Two other experiments assessed repetition effects in monitoring data. Together the data suggest that “primary” speech units are strongly and symmetrically affected by bottom-up and top-down knowledge sources.;,citation_author=Stephen D. Goldinger;,citation_author=Tamiko Azuma;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6WKT-49SWBD1-1/2/f53c16fa8e87ba8f793594d1424f663e;,citation_issue=3-4;,citation_doi=DOI: 10.1016/S0095-4470(03)00030-5;,citation_issn=0095-4470;,citation_volume=31;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Echoes of echoes? An episodic theory of lexical access;,citation_abstract=In this article the author proposes an episodic theory of spoken word representation,perception,and production.Bymosttheories,idiosyncraticaspectsof speech(voice details,ambientnoise,etc.)are considered noise and are filtered in perception. However, episodic theories suggest that perceptual details are stored inmemory and are integral to later perception. In this research theauthor tested an episodic model (MINERVA2; D. L. Hintzman, 1986) against speech production data from a word-shadowing task. The model predicted the shadowing-response-timepatterns, and it correctly predicted a tendency for shadowers to spontaneously imitate the acoustic patterns of words and nonwords.It also correctlypredictedimitationstrengthas a functionof &amp;amp;amp;quot;abstract&amp;quot; stimulusproper- ties, such as word frequency. Taken together, the data and theory suggest that detailed episodes constitute the basic substrate of the mental lexicon.;,citation_author=Stephen D. Goldinger;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=2;,citation_volume=105;,citation_journal_title=Psychological Review;">
<meta name="citation_reference" content="citation_title=Generative phonology: Its origins, its principles, and its successors;,citation_author=John Goldsmith;,citation_author=Bernard Laks;,citation_editor=Linda Waugh;,citation_editor=John E. Joseph;,citation_inbook_title=The cambridge history of linguistics;">
<meta name="citation_reference" content="citation_title=Integrating speech information across talkers, gender, and sensory modality: Female faces and male voices in the McGurk effect;,citation_author=Kerry Green;,citation_author=Patricia Kuhl;,citation_author=Andrew Meltzoff;,citation_author=Erica Stevens;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_fulltext_html_url=http://dx.doi.org/10.3758/BF03207536;,citation_issn=1943-3921;,citation_volume=50;,citation_journal_title=Attention, Perception, &amp;amp;amp; Psychophysics;,citation_publisher=Springer New York;">
<meta name="citation_reference" content="citation_title=Integrating speech information across talkers, gender, and sensory modality: Female faces and male voices in the McGurk effect;,citation_author=Kerry Green;,citation_author=Patricia Kuhl;,citation_author=Andrew Meltzoff;,citation_author=Erica Stevens;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_fulltext_html_url=http://dx.doi.org/10.3758/BF03207536;,citation_issue=6;,citation_issn=1943-3921;,citation_volume=50;,citation_journal_title=Attention, Perception, &amp;amp;amp; Psychophysics;">
<meta name="citation_reference" content="citation_title=Measuring individual differences in implicit cognition: The implicit association test.;,citation_author=Anthony G. Greenwald;,citation_author=Debbie E. McGhee;,citation_author=Jordan L. K. Schwartz;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=74;,citation_journal_title=Journal of Personality and Social Psychology;">
<meta name="citation_reference" content="citation_title=Pattern theory: From representation to inference;,citation_author=Ulf Grenander;,citation_author=Michael Miller;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=How “deep” is dynamism? Revisiting the evaluation of moroccan-flavored netherlandic dutch;,citation_author=Stefan Grondelaers;,citation_author=Paul Gent;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=s1;,citation_volume=5;,citation_journal_title=Linguistics Vanguard;,citation_publisher=De Gruyter Mouton;">
<meta name="citation_reference" content="citation_title=Situating experience in social meaning: Ethnography, experiments and exemplars in the enregisterment of istanbul greek;,citation_author=Matthew Hadodo;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Language and gender;,citation_author=Kira Hall;,citation_author=Rodrigo Borba;,citation_author=Mie Hiramoto;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The international encyclopedia of linguistic anthropology;,citation_publisher=John Wiley &amp;amp;amp; Sons Hoboken;">
<meta name="citation_reference" content="citation_title=Analysis by synthesis.;,citation_author=M. Halle;,citation_author=K. N. Stevens;,citation_editor=W. Wathen-Dunn;,citation_editor=L. E. Woods;,citation_publication_date=1959;,citation_cover_date=1959;,citation_year=1959;,citation_volume=2;,citation_conference_title=Proceedings of the seminar on speech compression and processing.;">
<meta name="citation_reference" content="citation_title=Structural linguistics;,citation_author=Zellig S. Harris;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;">
<meta name="citation_reference" content="citation_title=Roles and representations of systematic fine phonetic detail in speech understanding;,citation_author=Sarah Hawkins;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6WKT-4B26B98-5/2/a82d163ca7e04921e0c6f40a5beaf02a;,citation_issue=3-4;,citation_isbn=0095-4470;,citation_volume=31;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Stuffed toys and speech perception.;,citation_author=J. Hay;,citation_author=K. Drager;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=48;,citation_journal_title=Linguistics;">
<meta name="citation_reference" content="citation_title=From fush to feesh: Exemplar priming in speech perception.;,citation_author=J. Hay;,citation_author=A. Nolan;,citation_author=K. Drager;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=23;,citation_journal_title=The Linguistic Review;">
<meta name="citation_reference" content="citation_title=Factors influencing speech perception in the context of a merger-in-progress;,citation_author=J. Hay;,citation_author=P. Warren;,citation_author=K. Drager;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=34;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Causes and consequences of word structure;,citation_author=J. B. Hay;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_dissertation_institution=Northwestern University;">
<meta name="citation_reference" content="citation_title=Schema-abstraction in a multiple- trace memory model;,citation_author=D. L. Hintzman;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_volume=93;,citation_journal_title=Psychological Review;">
<meta name="citation_reference" content="citation_title=Using the visual world paradigm to study language processing: A review and critical evaluation;,citation_abstract=We describe the key features of the visual world paradigm and review the main research areas where it has been used. In our discussion we highlight that the paradigm provides information about the way language users integrate linguistic information with information derived from the visual environment. Therefore the paradigm is well suited to study one of the key issues of current cognitive psychology, namely the interplay between linguistic and visual information processing. However, conclusions about linguistic processing (e.g., about activation, competition, and timing of access of linguistic representations) in the absence of relevant visual information must be drawn with caution.;,citation_author=Falk Huettig;,citation_author=Joost Rommers;,citation_author=Antje S. Meyer;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/pii/S0001691810002180;,citation_issue=2;,citation_doi=DOI: 10.1016/j.actpsy.2010.11.003;,citation_issn=0001-6918;,citation_volume=137;,citation_journal_title=Acta Psychologica;">
<meta name="citation_reference" content="citation_title=ImageMagick;,citation_author=ImageMagick Studio LLC;,citation_publication_date=2023-01-04;,citation_cover_date=2023-01-04;,citation_year=2023;,citation_fulltext_html_url=https://imagemagick.org;">
<meta name="citation_reference" content="citation_title=When talk isn’t cheap: Language and political economy.;,citation_author=J. Irvine;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=2;,citation_volume=16;,citation_journal_title=American Ethnologist;">
<meta name="citation_reference" content="citation_title=Language ideology and linguistic differentiation.;,citation_author=Judith T. Irvine;,citation_author=Susan Gal;,citation_editor=P. Kroskrity;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_inbook_title=Regimes of language;">
<meta name="citation_reference" content="citation_title=Tracking the timecourse of social perception: The effects of racial cues on event-related brain potentials.;,citation_author=T. A. Ito;,citation_author=E. Thompson;,citation_author=J. T. Cacioppo;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=30;,citation_journal_title=Personality and Social Psychology Bulletin;">
<meta name="citation_reference" content="citation_title=Race and gender on the brain: Electrocortical measures of attention to the race and gender of multiply categorizable individuals.;,citation_author=T. A. Ito;,citation_author=G. R. Urland;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=85;,citation_journal_title=Journal of Personality and Social Psychology;">
<meta name="citation_reference" content="citation_title=Speaker normalization in speech perception;,citation_author=Keith Johnson;,citation_editor=D. B. Pisoni;,citation_editor=R. Remez;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_inbook_title=The handbook of speech perception;">
<meta name="citation_reference" content="citation_title=Auditory–visual integration of talker gender in vowel perception;,citation_author=Keith Johnson;,citation_author=Elizabeth A Strand;,citation_author=Mariapaola D’Imperio;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=4;,citation_volume=27;,citation_journal_title=Journal of phonetics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Contrast and normalization in vowel perception;,citation_author=Keith Johnson;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=2;,citation_volume=18;,citation_journal_title=Journal of Phonetics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=The $\Delta$f method of vocal tract length normalization for vowels;,citation_author=Keith Johnson;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=11;,citation_journal_title=Laboratory Phonology;,citation_publisher=Open Library of Humanities;">
<meta name="citation_reference" content="citation_title=Speech perception without speaker normalization: An exemplar model;,citation_author=Keith Johnson;,citation_editor=Keith Johnson;,citation_editor=John W. Mullennix;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_inbook_title=Talker variability in speech processing.;">
<meta name="citation_reference" content="citation_title=Resonance in an exemplar-based lexicon: The emergence of social identity and phonology.;,citation_author=Keith Johnson;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=34;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Acoustic phonetics;,citation_author=Martin Joos;,citation_publication_date=1948;,citation_cover_date=1948;,citation_year=1948;,citation_fulltext_html_url=http://www.jstor.org/stable/522229;,citation_issue=2;,citation_issn=00978507;,citation_volume=24;,citation_journal_title=Language;,citation_publisher=Linguistic Society of America;">
<meta name="citation_reference" content="citation_title=Speech perception and spoken word recognition: Past and present.;,citation_author=P. W. Jusczyk;,citation_author=P. A. Luce;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=1;,citation_volume=23;,citation_journal_title=Ear and Hearing;">
<meta name="citation_reference" content="citation_title=Conceptualizing thai genderscapes: Transformation and continuity in the thai sex/gender system;,citation_author=Dredge Byung’chu Käng;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Contemporary socio-cultural and political perspectives in thailand;">
<meta name="citation_reference" content="citation_title=Acoustic and auditory phonetics, 3rd edition;,citation_author=Keith Johnson;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Lifespan adult faces: Norms for age, familiarity, memorability, mood, and picture quality.;,citation_author=K. M. Kennedy;,citation_author=K. Hope;,citation_author=N. Raz;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=35;,citation_journal_title=Experimental Aging Research;">
<meta name="citation_reference" content="citation_title=Speaker and group specificity in spoken word recognition;,citation_author=Edward Thomas King;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=On the auditory perception of tones in mandarin;,citation_author=C. Kiriloff;,citation_publication_date=1969;,citation_cover_date=1969;,citation_year=1969;,citation_fulltext_html_url=http://www.karger.com/DOI/10.1159/000259274;,citation_issue=2-4;,citation_isbn=0031-8388;,citation_volume=20;,citation_journal_title=Phonetica;">
<meta name="citation_reference" content="citation_title=Chinese pragmatic norms and “china english”;,citation_abstract=In this paper we shall first consider a selection of discourse and rhetorical norms of Modern Standard Chinese and then contrast them with a comparable selection of discourse and rhetorical norms of an “inner circle” variety of English. As the transfer of discourse and rhetorical norms from a first to a second language commonly occurs, we predict that a Chinese variety of English is characterised by a number of discourse and rhetorical norms derived from Chinese. We argue that the presence of these L1 discourse and rhetorical norms should not be seen as “deviations” from Anglo norms, but that, as Chinese speakers are more likely to use the language with other English speakers in the East Asian region rather than with speakers of inner circle varieties of English, the Chinese variety of English is actually a more culturally appropriate model of English than any superimposed “Anglo” norm. Our discussion also considers the importance in China traditionally attached to “models” and “standards” and speculates on the extent to which educators and officials in China are likely to accept a Chinese variety of English as a model for the classroom.;,citation_author=Andy Kirkpatrick;,citation_author=Xu Zhichang;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=http://dx.doi.org/10.1111/1467-971X.00247;,citation_issue=2;,citation_doi=10.1111/1467-971X.00247;,citation_issn=1467-971X;,citation_volume=21;,citation_journal_title=World Englishes;,citation_publisher=Blackwell Publishers Ltd;">
<meta name="citation_reference" content="citation_title=Speech perception: A model of acoustic-phonetic analysis and lexical access.;,citation_author=D. H. Klatt;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_volume=7;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Virtues and perils of an empiricist approach to speech perception;,citation_author=Keith R. Kluender;,citation_author=Andrew J. Lotto;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=http://link.aip.org/link/?JAS/105/503/1;,citation_issue=1;,citation_doi=10.1121/1.424587;,citation_volume=105;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=The effect of perceived speaker age on the perception of PIN and PEN vowels in houston, texas;,citation_author=Christian Koops;,citation_author=Elizabeth Gentry;,citation_author=Andrew Pantos;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=14;,citation_journal_title=University of Pennsylvania Working Papers in Linguistics: Selected papers from NWAV 36;">
<meta name="citation_reference" content="citation_title=The role of creaky voice in cantonese tonal perception;,citation_abstract=Cantonese has anecdotally been claimed to have a low tone (Tone 4, 21/11) inconsistently realized with creaky voice. This paper shows that Cantonese listeners are sensitive to creaky voice in tonal perception: the presence of creak increases tonal identification accuracy for Tone 4 and biases listeners toward Tone 4 responses. Moreover, listeners are sensitive to details of creak production, suggesting that a more detailed representation of creak than a binary flag for the presence of creak is needed in tonal representation and automatic tonal recognition.;,citation_author=Kristine M. Yu;,citation_author=Hiu Wai Lam;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICPhS XVII;,citation_conference=International Congress of Phonetic Sciences;">
<meta name="citation_reference" content="citation_title=Computational analysis of present-day american english.;,citation_author=Henry Kucera;,citation_author=W. Nelson Francis;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;">
<meta name="citation_reference" content="citation_title=Is speech learning ’gated’ by the social brain?;,citation_abstract=I advance the hypothesis that the earliest phases of language acquisition 2013 the developmental transition from an initial universal state of language processing to one that is language-specific 2013 requires social interaction. Relating human language learning to a broader set of neurobiological cases of communicative development, I argue that the social brain ’gates’ the computational mechanisms involved in human language learning.;,citation_author=Patricia K. Kuhl;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=10;,citation_journal_title=Developmental Science;">
<meta name="citation_reference" content="citation_title=On the influence of context upon perception of voiceless fricative consonants;,citation_author=Osamu Kunisaki;,citation_author=Hyroya Fujisaki;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_volume=11;,citation_journal_title=Annual Bulletin;,citation_publisher=Research Institute of Logopedics; Phoniatrics Tokyo;">
<meta name="citation_reference" content="citation_title=The gnats and gnus document preparation system;,citation_author=L[eslie] A. Lamport;,citation_publication_date=1986-07;,citation_cover_date=1986-07;,citation_year=1986;,citation_issue=7;,citation_volume=41;,citation_journal_title=G-Animal’s Journal;">
<meta name="citation_reference" content="citation_title=Principles of linguistic change: Internal factors;,citation_author=W. Labov;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=Properties of the sociolinguistic monitor;,citation_author=William Labov;,citation_author=Sharon Ash;,citation_author=Maya Ravindranath;,citation_author=Tracey Weldon;,citation_author=Maciej Baranowski;,citation_author=Naomi Nagy;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=15;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=A sociolinguistic perspective on sociophonetic research;,citation_author=William Labov;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/pii/S0095447006000192;,citation_issue=4;,citation_doi=DOI: 10.1016/j.wocn.2006.05.002;,citation_issn=0095-4470;,citation_volume=34;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Information conveyed by vowels;,citation_author=Peter Ladefoged;,citation_author=Donald E. Broadbent;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_issue=1;,citation_volume=29;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=The mental representation of lexical form: A phonological approach to the recognition lexicon.;,citation_author=A. Lahiri;,citation_author=W. Marlsen-Wilson;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_volume=3;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=Evaluational reactions to spoken languages.;,citation_author=Wallace E Lambert;,citation_author=Richard C Hodgson;,citation_author=Robert C Gardner;,citation_author=Samuel Fillenbaum;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_issue=1;,citation_volume=60;,citation_journal_title=The journal of abnormal and social psychology;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=&amp;amp;amp;quot;Just another tool for online studies” (JATOS): An easy solution for setup and management of web servers supporting online studies;,citation_author=Kristian Lange;,citation_author=Simone Kuhn;,citation_author=Elisa Filevich;,citation_publication_date=2015-06;,citation_cover_date=2015-06;,citation_year=2015;,citation_issue=6;,citation_doi=10.1371/journal.pone.0130834;,citation_volume=10;,citation_journal_title=PLOS ONE;,citation_publisher=Public Library of Science;">
<meta name="citation_reference" content="citation_title=Listening with an accent: Speech perception in a second language by late bilinguals;,citation_abstract=The goal of the present study was to examine functioning of late bilinguals in their second language. Specifically, we asked how native and non-native Hebrew speaking listeners perceive accented and native-accented Hebrew speech. To achieve this goal we used the gating paradigm to explore the ability of healthy late fluent bilinguals (Russian and Arabic native speakers) to recognize words in L2 (Hebrew) when they were spoken in an accent like their own, a native accent (Hebrew speakers), or another foreign accent (American accent). The data revealed that for Hebrew speakers, there was no effect of accent, whereas for the two bilingual groups (Russian and Arabic native speakers), stimuli with an accent like their own and the native Hebrew accent, required significantly less phonological information than the other foreign accents. The results support the hypothesis that phonological assimilation works in a similar manner in these two different groups.;,citation_author=Mark Leikin;,citation_author=Raphiq Ibrahim;,citation_author=Zohar Eviatar;,citation_author=Shimon Sapir;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=http://dx.doi.org/10.1007/s10936-009-9099-1;,citation_issn=0090-6905;,citation_volume=38;,citation_journal_title=Journal of Psycholinguistic Research;,citation_publisher=Springer Netherlands;">
<meta name="citation_reference" content="citation_title=A theory of lexical access in speech production;,citation_author=Willem J. M. Levelt;,citation_author=Ardi Roelofs;,citation_author=Antje S. Meyer;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=22;,citation_journal_title=Behavioral and Brain Sciences;">
<meta name="citation_reference" content="citation_title=Social salience and the sociolinguistic monitor: A case study of ING and TH-fronting in britain;,citation_author=E. Levon;,citation_author=S. Fox;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=https://doi.org/10.1177/0075424214531487;,citation_issue=3;,citation_doi=10.1177/0075424214531487;,citation_volume=42;,citation_journal_title=Journal of English Linguistics;">
<meta name="citation_reference" content="citation_title=Speech: A special code.;,citation_author=A. M. Liberman;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=The role of selected stimulus variables in the perception of the unvoiced stop consonants;,citation_author=Alvin M. Liberman;,citation_author=Pierre C. Delattre;,citation_author=Franklin S. Cooper;,citation_publication_date=1952;,citation_cover_date=1952;,citation_year=1952;,citation_volume=65;,citation_journal_title=American Journal of Psychology;">
<meta name="citation_reference" content="citation_title=Some cues for the distinction between voiced and voiceless stops in initial position;,citation_author=Alvin M. Liberman;,citation_author=Pierre C. Delattre;,citation_author=Franklin S. Cooper;,citation_publication_date=1958;,citation_cover_date=1958;,citation_year=1958;,citation_volume=1;,citation_journal_title=Language and Speech;">
<meta name="citation_reference" content="citation_title=The discrimination of speech sounds within and across phoneme boundaries;,citation_author=Alvin M. Liberman;,citation_author=Katherine S. Harris;,citation_author=Belver C. Griffith;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_volume=54;,citation_journal_title=Journal of Experimental Psychology;">
<meta name="citation_reference" content="citation_title=The perception of speech.;,citation_author=J. C. R. Licklider;,citation_author=George A. Miller;,citation_editor=S. S. Stevens;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;,citation_fulltext_html_url=http://mirlyn.lib.umich.edu/Record/000662622;,citation_inbook_title=Handbook of experimental psychology.;">
<meta name="citation_reference" content="citation_title=Explaining phonetic variation: A sketch of the h&amp;amp;amp;h theory;,citation_author=B. Lindblom;,citation_editor=William J. Hardcastle;,citation_editor=Alain Marchal;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_inbook_title=Speech production and speech modelling;">
<meta name="citation_reference" content="citation_title=Koreans, chinese or indians? Attitudes and ideologies about non-native english speakers in the united states;,citation_author=Stephanie Lindemann;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3;,citation_volume=7;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=English with an accent:language,ideology,and discrimination in the united states;,citation_author=Rosina Lippi-Green;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;">
<meta name="citation_reference" content="citation_title=A cross-language study of voicing in initial stops: Acoustical measurements;,citation_author=L. Lisker;,citation_author=A. Abramson;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_volume=20;,citation_journal_title=Word;">
<meta name="citation_reference" content="citation_title=Some effects of context on voice onset time in english stops.;,citation_author=&amp;amp;amp; Abramson A. S. Lisker;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_issue=1;,citation_volume=10;,citation_journal_title=Language and Speech;">
<meta name="citation_reference" content="citation_title=“Voicing” in english: A catalogue of acoustic features signaling/b/versus/p/in trochees;,citation_author=Leigh Lisker;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=1;,citation_volume=29;,citation_journal_title=Language and speech;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=Closure duration and the intervocalic voiced-voiceless distinction in English;,citation_author=Leigh Lisker;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_issue=42-49;,citation_volume=33;,citation_journal_title=Language;">
<meta name="citation_reference" content="citation_title=Recognizing spoken words: The neighborhood activation model.;,citation_author=Paul A. Luce;,citation_author=David B. Pisoni.;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=19;,citation_journal_title=Ear and Hearing;">
<meta name="citation_reference" content="citation_title=The chicago face database: A free stimulus set of faces and norming data;,citation_author=D. S. Ma;,citation_author=J. Correll;,citation_author=B. Wittenbrink;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://doi.org/10.3758/s13428-014-0532-5;,citation_issue=4;,citation_volume=47;,citation_journal_title=Behavior research methods;">
<meta name="citation_reference" content="citation_title=The association between/s/quality and perceived sexual orientation of men’s voices: Implicit and explicit measures;,citation_author=Sara Mack;,citation_author=Benjamin Munson;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=40;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Categorical perception of english /r/ and /l/ by japanese bilinguals.;,citation_author=K. S. MacKain;,citation_author=C. T. Best;,citation_author=W. Strange;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_volume=2;,citation_journal_title=Applied Psycholinguistics;">
<meta name="citation_reference" content="citation_title=Spoken word recognition in the visual world paradigm reflects the structure of the entire lexicon.;,citation_author=J. S. Magnuson;,citation_author=M. K. Tanenhaus;,citation_author=R. N. Aslin;,citation_author=D. Dahan;,citation_editor=M. Hahn;,citation_editor=S. Stoness;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=Proceedings of the twenty first annual conference of the cognitive science society;,citation_conference=Erlbaum Associates;">
<meta name="citation_reference" content="citation_title=Lexical effects on compensation for coarticulation: The ghost of christmash past;,citation_abstract=The question of when and how bottom-up input is integrated with top-down knowledge has been debated extensively within cognition and perception, and particularly within language processing. A long running debate about the architecture of the spoken-word recognition system has centered on the locus of lexical effects on phonemic processing: does lexical knowledge influence phoneme perception through feedback, or post-perceptually in a purely feedforward system? Elman and McClelland (1988) reported that lexically restored ambiguous phonemes influenced the perception of the following phoneme, supporting models with feedback from lexical to phonemic representations. Subsequently, several authors have argued that these results can be fully accounted for by diphone transitional probabilities in a feedforward system (Cairns et al., 1995; Pitt &amp;amp;amp; McQueen, 1998). We report results strongly favoring the original lexical feedback explanation: lexical effects were present even when transitional probability biases were opposite to those of lexical biases.;,citation_author=James S. Magnuson;,citation_author=Bob McMurray;,citation_author=Michael K. Tanenhaus;,citation_author=Richard N. Aslin;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=2;,citation_volume=27;,citation_journal_title=Cognitive Science;">
<meta name="citation_reference" content="citation_title=Influence of vocalic context on perception of the [∫]-[s] distinction;,citation_author=Virginia A Mann;,citation_author=Bruno H Repp;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=3;,citation_volume=28;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Influence of preceding fricative on stop consonant perception;,citation_author=Virginia A. Mann;,citation_author=Bruno H. Repp;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_volume=69;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Influence of preceding liquid on stop consonant perception;,citation_author=Virginia A. Mann;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_volume=28;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;">
<meta name="citation_reference" content="citation_title=Opensesame: An open-source, graphical experiment builder for the social sciences;,citation_author=S. Mathôt;,citation_author=D. Schreij;,citation_author=J. Theeuwes;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=44;,citation_journal_title=Behavior research methods;">
<meta name="citation_reference" content="citation_title=Vocal tract normalization for /s/ and /š/;,citation_author=Janet May;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=SR-48;,citation_journal_title=Haskins Laboratories Status Report on Speech Research;">
<meta name="citation_reference" content="citation_title=Interactive processes in speech perception: The TRACE model;,citation_author=J. L. McClelland;,citation_author=J. L. Elman;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_isbn=0-262-13218-4;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=Perceiving isn’t believing: Divergence in levels of sociolinguistic awareness;,citation_author=Kevin B. McGowan;,citation_author=Anna M. Babel;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_volume=49;,citation_journal_title=Language in Society;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Tongues don’t twist – mental representations do;,citation_author=Kevin B. McGowan;,citation_author=David Medeiros;">
<meta name="citation_reference" content="citation_title=The role of socioindexical expectation in speech perception;,citation_author=Kevin B. McGowan;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_dissertation_institution=University of Michigan;">
<meta name="citation_reference" content="citation_title=Social expectation improves speech perception in noise;,citation_author=Kevin B. McGowan;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=58;,citation_journal_title=Language and Speech;,citation_publisher=Sage Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=Hearing lips and seeing voices;,citation_author=Harry McGurk;,citation_author=John MacDonald;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_volume=264;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Examining the time course of indexical specificity effects in spoken word recognition.;,citation_author=C. T. McLennan;,citation_author=P. A. Luce;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=31;,citation_journal_title=Journal of Experimental Psychology: Learning, Memory, and Cognition;">
<meta name="citation_reference" content="citation_title=The myth of categorical perception;,citation_author=Bob McMurray;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=6;,citation_volume=152;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Matched guise effects can be robust to speech style.;,citation_author=Meredith Tamminga;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=142 1;,citation_journal_title=The Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Language, gender, and sexuality;,citation_author=Miriam Meyerhoff;,citation_author=Susan Ehrlich;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=5;,citation_journal_title=Annual Review of Linguistics;,citation_publisher=Annual Reviews;">
<meta name="citation_reference" content="citation_title=Auditory-perceptual interpretation of the vowel;,citation_author=James D. Miller;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_fulltext_html_url=http://link.aip.org/link/?JAS/85/2114/1;,citation_issue=5;,citation_doi=10.1121/1.397862;,citation_volume=85;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Seeking the neurobiological bases of speech perception;,citation_author=Joanne L. Miller;,citation_author=Peter W. Jusczyk;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6T24-45RC76Y-4N/2/c2114999246e79728e4067a567d3f19f;,citation_issue=1-2;,citation_doi=DOI: 10.1016/0010-0277(89)90007-3;,citation_issn=0010-0277;,citation_volume=33;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=Some effects of later-occurring information on the perception of stop consonant and semivowel.;,citation_author=Joanne L. Miller;,citation_author=Alvin M. Liberman;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=6;,citation_volume=25;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;">
<meta name="citation_reference" content="citation_title=The motor theory of speech perception revised;,citation_author=Alvin M Liberman;,citation_author=Ignatius G Mattingly;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_issue=1;,citation_volume=21;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=Sociolinguistics: Method and interpretation.;,citation_author=Lesley Milroy;,citation_author=Matthew Gordon;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Stereotyped reactions to four educated accents in ulster;,citation_author=Lesley Milroy;,citation_author=Paul McClenaghan;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=4;,citation_volume=2;,citation_journal_title=Belfast Working Papers in Language and Linguistics;">
<meta name="citation_reference" content="citation_title=A lifespan database of adult facial stimuli.;,citation_author=M. Minear;,citation_author=D. C. Park;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=36;,citation_journal_title=Behavior Research Methods, Instruments and Computers.;">
<meta name="citation_reference" content="citation_title=An effect of linguistic experience: The discrimination of [r] and [l] by native speakers of japanese and english.;,citation_author=K. Miyawaki;,citation_author=W. Strange;,citation_author=Verbrugge R.;,citation_author=A. M. Liberman;,citation_author=J. J. Jenkins;,citation_author=O. Fujimura;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=5;,citation_volume=18;,citation_journal_title=Perception and Psychophysics;">
<meta name="citation_reference" content="citation_title=Pattern theory: The mathematics of perception;,citation_author=David Mumford;,citation_publication_date=2002-11;,citation_cover_date=2002-11;,citation_year=2002;,citation_journal_title=ArXiv Mathematics e-prints;">
<meta name="citation_reference" content="citation_title=Lavender lessons learned, or, what sexuality can teach us about phonetic variation.;,citation_author=B. Munson;,citation_journal_title=American Speech;">
<meta name="citation_reference" content="citation_title=Perceived gender affects ratings of the quality of children’s spoken narratives;,citation_author=Benjamin Munson;,citation_author=V. Seppanen;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=2009;">
<meta name="citation_reference" content="citation_title=The influence of actual and imputed talker gender on fricative perception, revisited (l);,citation_author=Benjamin Munson;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=5;,citation_volume=130;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Levels of phonological abstraction and knowledge of socially motivated speech-sound variation: A review, a proposal, and a commentary on the papers by clopper, pierrehumbert, and tamati; drager; foulkes; mack; and smith, hall, and munson.;,citation_author=Benjamin Munson;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=1;,citation_journal_title=Journal of Laboratory Phonology;">
<meta name="citation_reference" content="citation_title=The influence of actual and imputed talker gender on fricative perception, revisited (l);,citation_author=Benjamin Munson;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=5;,citation_volume=130;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Speech perception as pattern recognition;,citation_author=Terrance M. Nearey;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_fulltext_html_url=http://link.aip.org/link/?JAS/101/3241/1;,citation_issue=6;,citation_doi=10.1121/1.418290;,citation_volume=101;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Context effects in a double-weak theory of speech perception;,citation_abstract=The present study provides an elaboration of the &amp;amp;amp;quot;double-weak&amp;quot; theory of speech perception proposed by Nearey (1990, 1991). In this framework, the objects of speech perception (and production) are viewed as neither primarily auditory nor primarily gestural; rather, they are abstract, symbolic elements lawfully constrained to map onto relatively simple (but not entirely transparent) patterns in both domains. Speech cannot be understood unless both articulation and acoustics are considered: Many production strategies appear to be directed at achieving acoustically-oriented goals, yet most context effects in speech perception seem to be motivated by the consequences of gestural overlap. The double-weak framework suggests that speech perception and speech production are less-than-perfect inverses of each other. Despite long-term accommodation of each for the demands of the other, real-time production and perception may operate as autonomous subsystems. A family of perceptual models is discussed that provides varying degrees of approximation to &quot;ideal solutions&quot; (in the sense of minimizing error rate) to classifying production data exhibiting contextual interactions. Members of this family that provide substantial, yet incomplete, compensation for the consequences of gestural overlap appear to be adequate to account for the results of many speech perception experiments. Such partial perceptual compensation allows, in principle, for the kind of imperfect &quot;error correction&quot; discussed by Ohala (1981, 1990) in conjunction with hypo-and hypercorrec-tion phenomena.;,citation_author=Terrance M. Nearey;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1-2;,citation_doi=10.1177/002383099203500213;,citation_volume=35;,citation_journal_title=Language and Speech;">
<meta name="citation_reference" content="citation_title=Imitated or authentic? Listeners’ judgements of foreign accents;,citation_abstract=This paper presents a perception experiment which investigates (1) whether listeners are able to distinguish between authentic non-native accents and non- authentic (imitated) accents and (2) whether they are able to identify the accents being produced. The results show that native-German-speaking listeners are able to identify (to name) imitated accents bet- ter than authentic non-native accents, probably due to the presence or absence of stereotypical patterns being used by the speakers. However, listeners were less able to judge the authenticity of the presented accents which probably can be related to the wide variation in the speakers’ ability to imitate an accent.;,citation_author=Sara Neuhauser;,citation_author=Adrian P. Simpson;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=ICPhS XVI;,citation_conference=International Congress of Phonetic Sciences;">
<meta name="citation_reference" content="citation_title=“Do you sound asian when you speak english?” Racial identification and voice in Chinese and Korean Americans’ English.;,citation_author=Michael Newman;,citation_author=Angela Wu;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=86;,citation_journal_title=American Speech;">
<meta name="citation_reference" content="citation_title=The effect of social information on the perception of sociolinguistic variables;,citation_author=Nancy Niedzielski;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=18;,citation_journal_title=Journal of Language and Social Psychology;">
<meta name="citation_reference" content="citation_title=The effect of social information on the phonetic perception of sociolinguistic variables.;,citation_author=Nancy Niedzielski;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_dissertation_institution=University of California, Santa Barbara;">
<meta name="citation_reference" content="citation_title=Acoustic analysis and language attitudes in detroit.;,citation_author=Nancy Niedzielski;,citation_editor=M. Meyerhoff;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_volume=3;,citation_conference_title=(N)waves and means: University of pennsylvania working papers in lingusitics;,citation_conference=University of Pennsylvania Press;">
<meta name="citation_reference" content="citation_title=Exemplar and prototype models revisited: Response strategies, selective attention, and stimulus generalization;,citation_abstract=J. D. Smith and colleagues (J. P. Minda &amp;amp;amp; J. D. Smith, 2001; J. D. Smith &amp; J. P. Minda, 1998, 2000; J. D. Smith, M. J. Murray, &amp; J. P. Minda, 1997) presented evidence that they claimed challenged the predictions of exemplar models and that supported prototype models. In the authors’ view, this evidence confounded the issue of the nature of the category representation with the type of response rule (probabilistic vs. deterministic) that was used. Also, their designs did not test whether the prototype models correctly predicted generalization performance. The present work demonstrates that an exemplar model that includes a response-scaling mechanism provides a natural account of all of Smith et al.’s experimental results. Furthermore, the exemplar model predicts classification performance better than the prototype models when novel transfer stimuli are included in the experimental designs.;,citation_author=Robert M. Nosofsky;,citation_author=Safa R. Zaki;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=5;,citation_volume=28;,citation_journal_title=Journal of Experimental Psychology;">
<meta name="citation_reference" content="citation_title=Attention, similarity, and the identification-categorization relationship;,citation_abstract=A unified quantitative approach to modeling subjects’ identification and categorization of multidi- mensional perceptual stimuli is proposed and tested. Two subjects identified and categorized the same set of perceptually confusable stimuli varying on separable dimensions. The identification data were modeled using Sbepard’s (1957) multidimensional scaling-choice framework. This framework was then extended to model the subjects’ categorization performance. The categorization model, which generalizesthe context theory of classificationdevelopedby Medin and Schaffer(1978), assumes that subjects store category exemplars in memory. Classification decisions are based on the similarity of stimuli to the stored exemplars. It is assumed that the same multidimensional perceptual representation underlies performance in both the identification and Categorizationparadigms. However,because of the influence of selectiveattention, similarityrelationships change systematicallyacross the two par- adigrns.Somesupport wasgainedforthe hypothesisthat subjectsdistribute attention amongcomponent dimensions so as to optimize categorization performance. Evidence was also obtained that subjects may have augmented their category representations with inferred exemplars. Implications of the results for theories of multidimensional scaling and categorization are discussed.;,citation_author=Robert M. Nosofsky;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=1;,citation_volume=115;,citation_journal_title=Journal of Experimental Psychology;">
<meta name="citation_reference" content="citation_title=Talker normalization: Phonetic constancy as a cognitive process;,citation_author=H. Nusbaum;,citation_author=J. Magnuson;,citation_editor=Keith Johnson;,citation_editor=J. W. Mullenix;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_inbook_title=Talker variability in speech processing;">
<meta name="citation_reference" content="citation_title=Speech perception as a talker-contingent process;,citation_author=Lynne C Nygaard;,citation_author=Mitchell S Sommers;,citation_author=David B Pisoni;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=1;,citation_volume=5;,citation_journal_title=Psychological Science;">
<meta name="citation_reference" content="citation_title=Perceptual stability and informative variation: A commentary on remez, goldinger, azuma, and local;,citation_author=Lynne C. Nygaard;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=31;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Pre-lexical abstraction of speech in the auditory cortex;,citation_author=Jonas Obleser;,citation_author=Frank Eisner;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6VH9-4V4BV93-1/2/643e410e389cdedf4e26929c54fa12e9;,citation_issue=1;,citation_doi=DOI: 10.1016/j.tics.2008.09.005;,citation_issn=1364-6613;,citation_volume=13;,citation_journal_title=Trends in Cognitive Sciences;">
<meta name="citation_reference" content="citation_title=Consumer’s guide to evidence in phonology;,citation_author=J. J. Ohala;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_volume=3;,citation_journal_title=Phonology Yearbook;">
<meta name="citation_reference" content="citation_title=An ethological perspective on common cross-language utilization of F₀ of voice;,citation_author=John J Ohala;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=1;,citation_volume=41;,citation_journal_title=Phonetica;,citation_publisher=S. Karger AG Basel, Switzerland;">
<meta name="citation_reference" content="citation_title=The frequency code underlies the sound-symbolic use of voice pitch;,citation_author=John J Ohala;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_journal_title=Sound symbolism;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Cross-language use of pitch: An ethological view;,citation_author=John J Ohala;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=1;,citation_volume=40;,citation_journal_title=Phonetica;,citation_publisher=S. Karger AG;">
<meta name="citation_reference" content="citation_title=Acoustics of american english speech;,citation_author=J. P. Olive;,citation_author=A. Greenwood;,citation_author=J. Coleman;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=A tutorial introduction to bayesian models of cognitive development;,citation_author=Amy Perfors;,citation_author=Joshua B. Tenenbaum;,citation_author=Thomas L. Griffiths;,citation_author=Fei Xu;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6T24-521N89V-1/2/36504313cfbc76f32faebd10f2401928;,citation_doi=DOI: 10.1016/j.cognition.2010.11.015;,citation_issn=0010-0277;,citation_volume=In Press, Corrected Proof;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=The acoustic bases for gender identification from children’s voices;,citation_author=Theodore L Perry;,citation_author=Ralph N Ohde;,citation_author=Daniel H Ashmead;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=6;,citation_volume=109;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Control methods used in a study of the vowels;,citation_author=Gordon E. Peterson;,citation_author=Harold L. Barney;,citation_publication_date=1952;,citation_cover_date=1952;,citation_year=1952;,citation_fulltext_html_url=http://dx.doi.org/10.1121/1.1906875;,citation_issue=2;,citation_doi=10.1121/1.1906875;,citation_volume=24;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Reflections on the relation between direct/indirect methods and explicit/implicit attitudes;,citation_author=Nicolai Pharao;,citation_author=Tore Kristiansen;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=s1;,citation_volume=5;,citation_journal_title=Linguistics Vanguard;,citation_publisher=De Gruyter Mouton;">
<meta name="citation_reference" content="citation_title=The macro-level social meanings of late-modern danish accents;,citation_author=Tore Kristiansen;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=41;,citation_journal_title=Acta linguistica hafniensia;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Exemplar dynamics: Word frequency, lenition and contrast;,citation_author=Janet B. Pierrehumbert;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=In;,citation_conference=John Benjamins;">
<meta name="citation_reference" content="citation_title=The next toolkit;,citation_author=Janet B. Pierrehumbert;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=34;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Sociophonetics, gender, and sexuality;,citation_author=Robert J Podesva;,citation_author=Sakiko Kajino;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=The handbook of language, gender, and sexuality;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Sociophonetics, Gender, and Sexuality;,citation_author=Robert J. Podesva;,citation_author=Sakiko Kajino;,citation_editor=Susan Ehrlich;,citation_editor=Miriam Meyerhoff;,citation_editor=Janet Holmes;,citation_publication_date=2014-03;,citation_cover_date=2014-03;,citation_year=2014;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/10.1002/9781118584248.ch5;,citation_doi=10.1002/9781118584248.ch5;,citation_isbn=978-1-118-58424-8 978-0-470-65642-6;,citation_inbook_title=The Handbook of Language, Gender, and Sexuality;">
<meta name="citation_reference" content="citation_title=Rich phonology: Some background material;,citation_author=Robert F. Port;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_publisher=http://www.cs.indiana.edu/&nbsp;port/HDphonol/HDphonology.supporting.materials.html;">
<meta name="citation_reference" content="citation_title=Toward the specification of speech;,citation_author=R. K. Potter;,citation_author=J. C. Steinberg;,citation_publication_date=1950;,citation_cover_date=1950;,citation_year=1950;,citation_fulltext_html_url=http://link.aip.org/link/?JAS/22/807/1;,citation_issue=6;,citation_doi=10.1121/1.1906694;,citation_volume=22;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Whaddayaknow?: The modes of folk linguistic awareness;,citation_author=Dennis R Preston;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=1;,citation_volume=5;,citation_journal_title=Language awareness;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Folk linguistics;,citation_author=Nancy Niedzielski;,citation_author=Dennis Richard Preston;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_volume=122;">
<meta name="citation_reference" content="citation_title=Whaddayaknow now;,citation_author=Dennis R Preston;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=Awareness and control in sociolinguistic research;,citation_publisher=Cambridge University Press Cambridge;">
<meta name="citation_reference" content="citation_title=Folk linguistics and the perception of language variety;,citation_author=Dennis R Preston;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=10;,citation_journal_title=Handbuch Sprache im Urteil der Öffentlichkeit;,citation_publisher=Walter de Gruyter GmbH &amp;amp;amp; Co KG;">
<meta name="citation_reference" content="citation_title=Why china english should stand alongside british, american, and the other;,citation_author=Hu Xiao Qiong;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=http://dx.doi.org/10.1017/S0266078404002056;,citation_issue=02;,citation_doi=10.1017/S0266078404002056;,citation_volume=20;,citation_journal_title=English Today;">
<meta name="citation_reference" content="citation_title=Eye movements in reading and information processing: 20 years of research;,citation_abstract=Recent studies of eye movementsin reading and other information processing tasks, such as music reading,typing,visualsearch,andsceneperception,arereviewed.Themajoremphasisofthereview is on reading as a specific example of cognitive processing. Basic topics discussed with respect to reading are (a) the characteristics of eye movements, (b) the perceptual span, (c) integration of information across saccades, (d) eye movementcontrol, and (e) individual differences (including dyslexia). Similar topics are discussed with respect to the other tasks examined. The basic theme of the review is that eye movementdata reflect moment-to-momentcognitiveprocesses in the various tasks examined.Theoreticaland practicalconsiderationsconcerningthe use of eye movementdata are also discussed.;,citation_author=Keith Rayner;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=3;,citation_volume=124;,citation_journal_title=Psychological Bulletin;">
<meta name="citation_reference" content="citation_title=Establishing and maintaining perceptual coherence: Unimodal and multimodal evidence;,citation_author=Robert E. Remez;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6WKT-49YHBTW-1/2/5f386932e23baebc03a009df21c6ae7a;,citation_issue=3-4;,citation_doi=DOI: 10.1016/S0095-4470(03)00042-1;,citation_issn=0095-4470;,citation_volume=31;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Duplex perception: Confirmation of fusion;,citation_abstract=Duplex perception—the simultaneous perception of a speech syllable and of a nonspeech chirp —occurs when a single formant transition and the remainder (the base ) of a synthetic syllable are presented to different ears. Two experiments were conducted to test whether the speech percept derives from the dichotic fusion of the transition with the base or from phonetic information extracted directly from the isolated transition. Experiment 1 showed that subjects were unable to assign speech labels to isolated transitions in a consistent manner, although the same transitions led to accurate identification when paired with the constant base in the other ear. Experiment 2 used an AXB paradigm to show that selective attention to the ear receiving the base does not prevent the contribution of the contralateral transition to the speech percept. Both experiments support the hypothesis that the speech percept in the duplex situation results from dichotic fusion at a relatively early stage in processing.;,citation_author=Bruno Repp;,citation_author=Christina Milburn;,citation_author=John Ashkenas;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_fulltext_html_url=http://dx.doi.org/10.3758/BF03205880;,citation_issn=1943-3921;,citation_volume=33;,citation_journal_title=Attention, Perception and Psychophysics;,citation_publisher=Springer New York;">
<meta name="citation_reference" content="citation_title=The role of psychophysics in understanding speech perception;,citation_author=Bruno B. Repp;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_publisher=Kluwer;">
<meta name="citation_reference" content="citation_title=Phonetic trading relations and context effects: New experimental evidence for a speech mode of perception.;,citation_author=Bruno H Repp;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_issue=1;,citation_volume=92;,citation_journal_title=Psychological bulletin;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=Implicitness and experimental methods in language variation research;,citation_author=Laura Rosseel;,citation_author=Stefan Grondelaers;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=s1;,citation_volume=5;,citation_journal_title=Linguistics Vanguard;,citation_publisher=De Gruyter Mouton;">
<meta name="citation_reference" content="citation_title=Nonlanguage factors affecting undergraduates’ judgments of nonnative english-speaking teaching assistants;,citation_author=Donald L Rubin;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_volume=33;,citation_journal_title=Research in Higher Education;">
<meta name="citation_reference" content="citation_title=Changes in nasal cavity dimensions in children and adults by gender and age;,citation_author=Bolesław K Samoliński;,citation_author=Antoni Grzanka;,citation_author=Tomasz Gotlib;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=8;,citation_volume=117;,citation_journal_title=The Laryngoscope;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The influence of /s/ quality on ratings of men’s sexual orientation: Explicit and implicit measures of the “gay lisp” stereotype;,citation_author=Sara Mack;,citation_author=Benjamin Munson;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_doi=https://doi.org/10.1016/j.wocn.2011.10.002;,citation_issn=0095-4470;,citation_volume=40;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Gradient perception of children’s productions of/s/and/$\theta$: A comparative study of rating methods;,citation_author=Sarah K Schellinger;,citation_author=Benjamin Munson;,citation_author=Jan Edwards;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=31;,citation_journal_title=Clinical Linguistics &amp;amp;amp; Phonetics;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Memory for words recently classified;,citation_author=Arthur I. Schulman;,citation_publication_date=1974-01;,citation_cover_date=1974-01;,citation_year=1974;,citation_fulltext_html_url=http://link.springer.com/10.3758/BF03197491;,citation_issue=1;,citation_doi=10.3758/BF03197491;,citation_issn=0090-502X, 1532-5946;,citation_volume=2;,citation_journal_title=Memory &amp;amp;amp; Cognition;">
<meta name="citation_reference" content="citation_title=The effect of geometry on source mechanisms of fricative consonants;,citation_author=Christine H Shadle;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=3-4;,citation_volume=19;,citation_journal_title=Journal of phonetics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=The acoustics of fricative consonants;,citation_author=Christine Helen Shadle;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_dissertation_institution=Massachusetts Institute of Technology, Research Laboratory of Electronics;">
<meta name="citation_reference" content="citation_title=The effect of perceived gender on teachers’ evaluations of students’ spoken responses;,citation_author=Michael Shepherd;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Indexical order and the dialectics of sociolinguistic life;,citation_abstract=The concept of indexical order is introduced, necessary to any empirical investigation of the inherently dialectical facts of indexicality. Indexical order is central to analyzing how semiotic agents access macro-sociological plane categories and concepts as values in the indexable realm of the micro-contextual. Through such access their relational identities are presupposed and creatively (trans)formed in interaction. We work through several classic examples of indexicality well-known in the literature of sociolinguistics, the clarification of which can be enhanced by using the concept of indexical order, viz., [“]T/V” deference-indexicality, speech levels, indexically significant variation in phonetics informed by a standard phonological register. We conclude with an analysis of identity-commoditizing indexical overlays such as the American English register here dubbed “oinoglossia,” “wine talk”.;,citation_author=Michael Silverstein;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6VB6-48N2NP6-1/2/aa1c8d12368399f0a8ec2401731d7873;,citation_issue=3-4;,citation_doi=DOI: 10.1016/S0271-5309(03)00013-2;,citation_issn=0271-5309;,citation_volume=23;,citation_journal_title=Language &amp;amp;amp; Communication;">
<meta name="citation_reference" content="citation_title=Sociolinguistic priming and the perception of agreement variation: Testing predictions of exemplar-theoretic grammar.;,citation_author=L. Squires;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_dissertation_institution=University of Michigan;">
<meta name="citation_reference" content="citation_title=Enregistering internet language;,citation_author=Lauren M. Squires;,citation_journal_title=Language in Society;">
<meta name="citation_reference" content="citation_title=Recognizing uptalk: Memory and metalinguistic commentary for a sociolinguistic feature;,citation_author=Amelia Stecker;,citation_author=Annette D’Onofrio;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Gender stereotype effects in speech processing;,citation_author=E. A. Strand;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_dissertation_institution=The Ohio State University;">
<meta name="citation_reference" content="citation_title=Gradient and visual speaker normalization in the perception of fricatives.;,citation_author=Elizabeth A Strand;,citation_author=Keith Johnson;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=KONVENS;">
<meta name="citation_reference" content="citation_title=Uncovering the role of gender stereotypes in speech perception;,citation_author=Elizabeth A Strand;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=18;,citation_journal_title=Journal of language and social psychology;,citation_publisher=Sage Publications Sage CA: Thousand Oaks, CA;">
<meta name="citation_reference" content="citation_title=The socially weighted encoding of spoken words: A dual-route approach to speech perception;,citation_author=Meghan Sumner;,citation_author=Seung Kyung Kim;,citation_author=Ed King;,citation_author=Kevin B. McGowan;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=4;,citation_journal_title=Frontiers in psychology;,citation_publisher=Frontiers Media SA;">
<meta name="citation_reference" content="citation_title=Eye-tracking.;,citation_author=M. K. Tanenhaus;,citation_author=M. J. Spivey-Knowlton;,citation_editor=F. Grosjean;,citation_editor=U. Frauenfelder;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=11;,citation_journal_title=Language &amp;amp;amp; Cognitive Processes;">
<meta name="citation_reference" content="citation_title=Mutual intelligibility of chinese dialects experimentally tested;,citation_author=Chaoju Tang;,citation_author=Vincent J. Heuven;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/pii/S0024384108001678;,citation_issue=5;,citation_doi=DOI: 10.1016/j.lingua.2008.10.001;,citation_issn=0024-3841;,citation_volume=119;,citation_journal_title=Lingua;">
<meta name="citation_reference" content="citation_title=Sociophonetic applications of speech perception experiments;,citation_author=Erik R. Thomas;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=2;,citation_doi=10.1215/00031283-77-2-115;,citation_volume=77;,citation_journal_title=American Speech;">
<meta name="citation_reference" content="citation_title=Mimicked accents - do speakers have similar cognitive prototypes?;,citation_author=N. Torstensson;,citation_author=Eriksson E. J.;,citation_author=Sullivan K. P. H.;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Proceedings of the 10th australian international conference on speech science &amp;amp;amp; technology;,citation_conference=Australian Speech Science &amp;amp; Technology Association Inc.;">
<meta name="citation_reference" content="citation_title=Perceiving gender while perceiving language: Integrating psycholinguistics and gender theory;,citation_author=Alayo Tripp;,citation_author=Benjamin Munson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=2;,citation_volume=13;,citation_journal_title=Wiley Interdisciplinary Reviews: Cognitive Science;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Sentence recognition in native- and foreign-language multi-talker background noise.;,citation_author=K. Van Engen;,citation_author=A. R. Bradlow;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=121;,citation_journal_title=Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Eye movement of perceivers during audiovisual speech perception;,citation_abstract=Perceiver eye movements were recorded during audiovisual presentations of extended monologues. Monologues were presented at different image sizes and with different levels of acoustic masking noise. Two clear targets of gaze fixation were identified, the eyes and the mouth. Regardless of image size, perceivers of both Japanese and English gazed more at the mouth as masking noise levels increased. However, even at the highest noise levels and largest image sizes, subjects gazed at the mouth only about half the time. For the eye target, perceivers typically gazed at one eye more than the other, and the tendency became stronger at higher noise levels. English perceivers displayed more variety of gaze- sequence patterns (e.g., left eye to mouth to left eye to right eye) and persisted in using them at higher noise levels than did Japanese perceivers. No segment-level correlations were found between perceiver eye motions and phoneme identity of the stimuli.;,citation_author=Eric Vatikiotis-Bateson;,citation_author=Inge-Marie Eigsti;,citation_author=Sumio Yano;,citation_author=Kevin G. Munhall;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=6;,citation_volume=60;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;">
<meta name="citation_reference" content="citation_title=Mental maps and perceptual dialectology;,citation_author=Jennifer Cramer;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_volume=15;,citation_journal_title=Language and Linguistics Compass;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Congruence between ‘word age’and ‘voice age’facilitates lexical access;,citation_author=Abby Walker;,citation_author=Jen Hay;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=2;,citation_journal_title=Laboratory Phonology;,citation_publisher=Walter de Gruyter GmbH &amp;amp;amp; Co. KG;">
<meta name="citation_reference" content="citation_title=Spoken-word recognition in foreign-accented speech by L2 listeners;,citation_abstract=Two cross-modal priming studies investigated the recognition of English words spoken with a foreign accent. Auditory English primes were either typical of a Dutch accent or typical of a Japanese accent in English and were presented to both Dutch and Japanese L2 listeners. Lexical-decision times to subsequent visual target words revealed that foreign-accented words can facilitate word recognition for L2 listeners if at least one of two requirements is met: the foreign-accented production is in accordance with the language background of the L2 listener, or the foreign accent is perceptually confusable with the standard pronunciation for the L2 listener. If neither one of the requirements is met, no facilitatory effect of foreign accents on L2 word recognition is found. Taken together, these findings suggest that linguistic experience with a foreign accent affects the ability to recognize words carrying this accent, and there is furthermore a general benefit for L2 listeners for recognizing foreign-accented words that are perceptually confusable with the standard pronunciation.;,citation_author=Andrea Weber;,citation_author=Mirjam Broersma;,citation_author=Makiko Aoyagi;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://www.sciencedirect.com/science/article/B6WKT-51XWW0D-2/2/d5b95c338f6604bedac5226adfcad431;,citation_doi=DOI: 10.1016/j.wocn.2010.12.004;,citation_issn=0095-4470;,citation_volume=In Press, Corrected Proof;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Subcategorical phonetic mismatches slow phonetic judgments;,citation_author=Douglas H. Whalen;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_volume=10.;,citation_journal_title=Percept Psychophys.;">
<meta name="citation_reference" content="citation_title=Perception of the english/s/–/∫/distinction relies on fricative noises and transitions, not on brief spectral slices;,citation_author=Douglas H Whalen;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=4;,citation_volume=90;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Effects of vocalic formant transitions and vowel quality on the english [s]–[š] boundary;,citation_author=Douglas H Whalen;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=1;,citation_volume=69;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Subcategorical phonetic mismatches slow phonetic judgments;,citation_author=Douglas H Whalen;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_volume=35;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Effects of vocalic formant transitions and vowel quality on the english [s]–[š] boundary;,citation_author=Douglas H Whalen;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=1;,citation_volume=69;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Perception of the english/s/–//distinction relies on fricative noises and transitions, not on brief spectral slices;,citation_author=Douglas H Whalen;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=4;,citation_volume=90;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=The integration of social and acoustic cues during speech perception;,citation_author=Eric Wilbanks;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_dissertation_institution=University of California, Berkeley;">
<meta name="citation_reference" content="citation_title=Perception of vowel phonemes in fort erie, ontario, canada, and buffalo, new york: An application of synthetic vowel categorization tests to dialectology;,citation_abstract=The question of correlation between dialect and perception (that is, categorization) of synthetic vowels by speakers of different dialects of English was investigated experimentally for speakers from Fort Erie, Ontario, Canada, and Buffalo, New York. Eighty-eight high-school-age subjects were administered three tests in which they were asked to associate synthetic vowel sounds with English words. The results of these tests were compared with previously established phonetic features of the subjects’ dialects. A correlation was found (1) between categorization of the opposition /varepsilon/-/ae/ (bet/bat) and dialectal difference in pronunciation of the phoneme /ae/, (2) between categorization of the opposition /ae/-/alpha/ (hat/hot), and dialectal difference in pronunciation of the phoneme /alpha/. A third pair of oppositions, /e/-/i/ (bait/beet) and /o/-/u/ (boat/boot), showed problematic results which are discussed. It is concluded that the use of synthetic vowel perception tests in dialectology allows rapid and objective collection of data relevant to phonetic features of spoken dialects, and can assist in clarifying the phonetic nature of differences among dialects.;,citation_author=C. Willis;,citation_publication_date=1972;,citation_cover_date=1972;,citation_year=1972;,citation_fulltext_html_url=http://jslhr.asha.org/cgi/content/abstract/15/2/246;,citation_issue=2;,citation_volume=15;,citation_journal_title=J Speech Hear Res;">
<meta name="citation_reference" content="citation_title=Housing policy and linguistic profiling: An audit study of three american dialects;,citation_author=Kelly Elizabeth Wright;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=Language;,citation_publisher=Linguistic Society of America;">
<meta name="citation_reference" content="citation_title=Queer excursions: Retheorizing binaries in language, gender, and sexuality;,citation_author=Lal Zimman;,citation_author=Jenny Davis;,citation_author=Joshua Raclaw;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Transgender voices: Insights on identity, embodiment, and the gender of the voice;,citation_author=Lal Zimman;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=8;,citation_volume=12;,citation_journal_title=Language and Linguistics Compass;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Gender as stylistic bricolage: Transmasculine voices and the relationship between fundamental frequency and/s;,citation_author=Lal Zimman;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=3;,citation_volume=46;,citation_journal_title=Language in Society;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=The attention schema theory: A mechanistic account of subjective awareness;,citation_abstract=We recently proposed the attention schema theory, a novel way to explain the brain basis of subjective awareness in a mechanistic and scientifically testable manner. The theory begins with attention, the process by which signals compete for the brain’s limited computing resources. This internal signal competition is partly under a bottom–up influence and partly under top–down control. We propose that the top–down control of attention is improved when the brain has access to a simplified model of attention itself. The brain therefore constructs a schematic model of the process of attention, the “attention schema,” in much the same way that it constructs a schematic model of the body, the “body schema.” The content of this internal model leads a brain to conclude that it has a subjective experience. One advantage of this theory is that it explains how awareness and attention can sometimes become dissociated; the brain’s internal models are never perfect, and sometimes a model becomes dissociated from the object being modeled. A second advantage of this theory is that it explains how we can be aware of both internal and external events. The brain can apply attention to many types of information including external sensory information and internal information about emotions and cognitive states. If awareness is a model of attention, then this model should pertain to the same domains of information to which attention pertains. A third advantage of this theory is that it provides testable predictions. If awareness is the internal model of attention, used to help control attention, then without awareness, attention should still be possible but should suffer deficits in control. In this article, we review the existing literature on the relationship between attention and awareness, and suggest that at least some of the predictions of the theory are borne out by the evidence.;,citation_author=Michael S. A. Graziano;,citation_author=Taylor W. Webb;,citation_publication_date=2015-04;,citation_cover_date=2015-04;,citation_year=2015;,citation_fulltext_html_url=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4407481/;,citation_doi=10.3389/fpsyg.2015.00500;,citation_issn=1664-1078;,citation_pmid=25954242;,citation_volume=6;,citation_journal_title=Frontiers in Psychology;">
<meta name="citation_reference" content="citation_title=Unconscious perception;,citation_abstract=Before the twentieth century, there was little appreciation of the fact that mental activity can occur without consciousness. Now unconscious mentality is widely accepted. This owes, in part, to Freud who emphasized unconscious motivations, but belief in the unconscious became more deeply entrenched with the rise of experimental psychology, and the discovery that human behavior is often best explained by appeal to processes that take place without awareness. Unconscious perception is one of the most extensively studied phenomena of this kind. There is extensive evidence that we respond to stimuli presented to our senses without awareness. In this chapter, I will review some of that evidence and raise several questions: what does it mean to say that there is unconscious perception? Is the evidence decisive? And how does unconscious perception differ from conscious perception? (PsycINFO Database Record (c) 2019 APA, all rights reserved);,citation_author=Jesse J. Prinz;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_doi=10.1093/oxfordhb/9780199600472.001.0001;,citation_isbn=978-0-19-960047-2;,citation_inbook_title=The Oxford handbook of philosophy of perception;">
<meta name="citation_reference" content="citation_title=Towards a cognitive neuroscience of consciousness: Basic evidence and a workspace framework;,citation_abstract=This introductory chapter attempts to clarify the philosophical, empirical, and theoretical bases on which a cognitive neuroscience approach to consciousness can be founded. We isolate three major empirical observations that any theory of consciousness should incorporate, namely (1) a considerable amount of processing is possible without consciousness, (2) attention is a prerequisite of consciousness, and (3) consciousness is required for some specific cognitive tasks, including those that require durable information maintenance, novel combinations of operations, or the spontaneous generation of intentional behavior. We then propose a theoretical framework that synthesizes those facts: the hypothesis of a global neuronal workspace. This framework postulates that, at any given time, many modular cerebral networks are active in parallel and process information in an unconscious manner. An information becomes conscious, however, if the neural population that represents it is mobilized by top-down attentional amplification into a brain-scale state of coherent activity that involves many neurons distributed throughout the brain. The long-distance connectivity of these ’workspace neurons’ can, when they are active for a minimal duration, make the information available to a variety of processes including perceptual categorization, long-term memorization, evaluation, and intentional action. We postulate that this global availability of information through the workspace is what we subjectively experience as a conscious state. A complete theory of consciousness should explain why some cognitive and cerebral representations can be permanently or temporarily inaccessible to consciousness, what is the range of possible conscious contents, how they map onto specific cerebral circuits, and whether a generic neuronal mechanism underlies all of them. We confront the workspace model with those issues and identify novel experimental predictions. Neurophysiological, anatomical, and brain-imaging data strongly argue for a major role of prefrontal cortex, anterior cingulate, and the areas that connect to them, in creating the postulated brain-scale workspace.;,citation_author=S. Dehaene;,citation_author=L. Naccache;,citation_publication_date=2001-04;,citation_cover_date=2001-04;,citation_year=2001;,citation_issue=1-2;,citation_doi=10.1016/s0010-0277(00)00123-2;,citation_issn=0010-0277;,citation_pmid=11164022;,citation_volume=79;,citation_journal_title=Cognition;">
<meta name="citation_reference" content="citation_title=Perceptual dialectology;,citation_author=Jennifer Cramer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Recognition without awareness: Encoding and retrieval factors.;,citation_abstract=The article reports 4 experiments that explore the notion of recognition without awareness using words as the material. Previous work by Voss and associates has shown that complex visual patterns were correctly selected as targets in a 2-alternative forced-choice (2-AFC) recognition test although participants reported that they were guessing. The present experiments sought to extend this earlier work by having participants study words in different ways and then attempt to recognize the words later in a series of 4-alternative forced-choice (4-AFC) tests, some of which contained no target word. The data of interest are cases in which a target was present and participants stated that they were guessing, yet chose the correct item. This value was greater than p ϭ .25 in all conditions of the 4 experiments, demonstrating the phenomenon of recognition without awareness. Whereas Voss and colleagues attributed their findings with kaleidoscope patterns to enhanced processing fluency of perceptual attributes, the main factor associated with different levels of recognition without awareness in the present studies was a variable criterion for the subjective state accompanying selection of the “guess” option, depending on the overall difficulty of the recognition test. We conclude by discussing some implications of the results for the distinction between implicit and explicit memory.;,citation_author=Fergus I. M. Craik;,citation_author=Nathan S. Rose;,citation_author=Nigel Gopie;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=http://doi.apa.org/getdoi.cfm?doi=10.1037/xlm0000137;,citation_issue=5;,citation_doi=10.1037/xlm0000137;,citation_issn=1939-1285, 0278-7393;,citation_volume=41;,citation_journal_title=Journal of Experimental Psychology: Learning, Memory, and Cognition;">
<meta name="citation_reference" content="citation_title=Voice quality and indexical information;,citation_author=John D. M. Laver;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=1;,citation_doi=10.3109/13682826809011440;,citation_volume=3;,citation_journal_title=British Journal of Disorders of Communication;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Evaluative reactions to accents;,citation_author=Howard Giles;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_issue=3;,citation_volume=22;,citation_journal_title=Educational review;,citation_publisher=Taylor &amp;amp;amp; Francis;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Removing the disguise: the matched guise technique and listener awareness</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliations</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Kyler Laycock <a href="mailto:laycock.21@buckeyemail.osu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-3731-0841" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        The Ohio State University
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">&nbsp;Kevin B McGowan <a href="mailto:kbmcgowan@uky.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-8214-1901" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University of Kentucky
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">October 26, 2024</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF</a></p></div><div class="quarto-title-meta-contents"><p><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></p></div></div></div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        <p>Sociophonetic perception is often studied using versions of the matched guise technique. Linguists using this technique appear united in the methodological assumptions that participants believe the manipulation and that this belief influences perception below the level of introspective awareness. We report an audiovisual matched guise experiment with a novel ‘unhidden’ instruction condition. The basic task is a replication of the Strand effect <span class="citation" data-cites="strandJohnson1996 strand1999">(<a href="#ref-strandJohnson1996" role="doc-biblioref">Strand and Johnson 1996</a>; <a href="#ref-strand1999" role="doc-biblioref">Strand 1999</a>)</span>. Participants in the ‘unhidden’ condition were instructed that the man or woman in the photo did not represent the voice they were listening to. Participants in both guises exhibited the Strand effect to nearly numerically identical extents. This result suggests that participants need not believe a link exists between a voice and a purported social category for visually-cued social information to influence segmental perception. We explore the implications of this result for the MGT and for theories of social awareness and speech perception more broadly.</p>
      </div>
    </div>

    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>awareness, control, inverse matched guise, sociophonetic perception</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro">Introduction</a>
  <ul class="collapse">
  <li><a href="#sub-mgt" id="toc-sub-mgt" class="nav-link" data-scroll-target="#sub-mgt">Matched Guise: Perception, Evaluation, and Awareness</a></li>
  <li><a href="#sec-coart-soc" id="toc-sec-coart-soc" class="nav-link" data-scroll-target="#sec-coart-soc">Coarticulatory and Social Information Influence [ʃ]-[s] perception</a></li>
  <li><a href="#sub-gender" id="toc-sub-gender" class="nav-link" data-scroll-target="#sub-gender">Phonetics, Speech Perception, and the Social-Construction of Gender</a></li>
  </ul></li>
  <li><a href="#sec-method" id="toc-sec-method" class="nav-link" data-scroll-target="#sec-method">Method</a>
  <ul class="collapse">
  <li><a href="#sub-participants" id="toc-sub-participants" class="nav-link" data-scroll-target="#sub-participants">Participants</a></li>
  <li><a href="#sub-stimuli" id="toc-sub-stimuli" class="nav-link" data-scroll-target="#sub-stimuli">Stimulus Materials</a>
  <ul class="collapse">
  <li><a href="#sub-stimuli-auditory" id="toc-sub-stimuli-auditory" class="nav-link" data-scroll-target="#sub-stimuli-auditory">Auditory Stimuli</a></li>
  </ul></li>
  <li><a href="#sub-stim-evals" id="toc-sub-stim-evals" class="nav-link" data-scroll-target="#sub-stim-evals">Explicit Evaluations of Auditory Stimuli</a>
  <ul class="collapse">
  <li><a href="#sub-stimuli-visual" id="toc-sub-stimuli-visual" class="nav-link" data-scroll-target="#sub-stimuli-visual">Visual Stimuli</a></li>
  </ul></li>
  <li><a href="#sub-procedure" id="toc-sub-procedure" class="nav-link" data-scroll-target="#sub-procedure">Procedure</a></li>
  </ul></li>
  <li><a href="#sec-predictions" id="toc-sec-predictions" class="nav-link" data-scroll-target="#sec-predictions">Predicted Results</a>
  <ul class="collapse">
  <li><a href="#sub-pred-face" id="toc-sub-pred-face" class="nav-link" data-scroll-target="#sub-pred-face">Face: male or female</a></li>
  <li><a href="#sub-pred-congruence" id="toc-sub-pred-congruence" class="nav-link" data-scroll-target="#sub-pred-congruence">Congruence: pairing of face and voice</a></li>
  <li><a href="#sub-pred-guise" id="toc-sub-pred-guise" class="nav-link" data-scroll-target="#sub-pred-guise">Guise: Hidden or Unhidden</a></li>
  </ul></li>
  <li><a href="#sec-results" id="toc-sec-results" class="nav-link" data-scroll-target="#sec-results">Results</a>
  <ul class="collapse">
  <li><a href="#sub-results-fricative" id="toc-sub-results-fricative" class="nav-link" data-scroll-target="#sub-results-fricative">[ʃ]-[s] Percepts</a></li>
  <li><a href="#sub-results-stats" id="toc-sub-results-stats" class="nav-link" data-scroll-target="#sub-results-stats">Logistic Regression and Quantitative Analysis</a></li>
  <li><a href="#sub-results-rt" id="toc-sub-results-rt" class="nav-link" data-scroll-target="#sub-results-rt">Response Times</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#sec-references" id="toc-sec-references" class="nav-link" data-scroll-target="#sec-references">References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="sec-intro" class="level1">
<h1>Introduction</h1>
<p>There is abundant, converging evidence from experimental, ethnographic, and sociocultural approaches to the study of language that gender is performed by talkers and perceived by interlocutors through a stylistic bricolage <span class="citation" data-cites="zimman2017">(<a href="#ref-zimman2017" role="doc-biblioref">Zimman 2017</a>)</span> comprising both non-linguistic and linguistic resources <span class="citation" data-cites="barrett2014 bucholtz2002">(<a href="#ref-barrett2014" role="doc-biblioref">Barrett et al. 2014</a>; <a href="#ref-bucholtz2002" role="doc-biblioref">Bucholtz 2002</a>)</span>. Gender is a culturally-situated practice, and, crucially, social meaning is performed by embodied voices that simultaneously produce the distinctions necessary for both social and linguistic meaning <span class="citation" data-cites="hall2021language podesvaKajino2014 bucholtzHall2016 sumner2014">(<a href="#ref-hall2021language" role="doc-biblioref">Hall, Borba, and Hiramoto 2021</a>; <a href="#ref-podesvaKajino2014" role="doc-biblioref">Podesva and Kajino 2014</a>; <a href="#ref-bucholtzHall2016" role="doc-biblioref">Bucholtz and Hall 2016</a>; <a href="#ref-sumner2014" role="doc-biblioref">Sumner et al. 2014</a>)</span>. This intersection of the construction of social and linguistic meaning via precise, dynamic speech articulation is perhaps nowhere more evident than in the palato-alveolar and alveolar fricative categories, [ʃ] and [s]; the first segments in words like <em>ship</em> and <em>sip</em> in English <span class="citation" data-cites="strand1999 mackMunson2012b calder2018">(<a href="#ref-strand1999" role="doc-biblioref">Strand 1999</a>; <a href="#ref-mackMunson2012b" role="doc-biblioref">Mack and Munson 2012a</a>; <a href="#ref-calder2018" role="doc-biblioref">Calder 2018</a>)</span>.</p>
<p>There is little consensus, however, around the extent to which language users are aware of, and can control, these fine gradations of social meaning in production and perception. In the context of this chapter we are using ‘awareness’ to refer to explicit, conscious awareness of the tripartite relationship between a social label, its phonetic reflexes, and the connections between these <span class="citation" data-cites="BabelIssue bakhtin1981">(<a href="#ref-BabelIssue" role="doc-biblioref">Babel this issue</a>; <a href="#ref-bakhtin1981" role="doc-biblioref">Bakhtin 1981</a>)</span>. The cognitive reality of this tripartite relationship between the concepts of gender identities and instances of fine phonetic detail is essential for the performance of those identities. This observation holds regardless of talker and listener awareness. This observation remains true even if what the listener believes about the talker is false; a monolingual American listener might expect a Beijing voice to be non-rhotic <span class="citation" data-cites="mcgowan2016">(<a href="#ref-mcgowan2016" role="doc-biblioref">McGowan 2016</a>)</span> or a gay male voice to have a lisp <span class="citation" data-cites="mackmunson2012">(<a href="#ref-mackmunson2012" role="doc-biblioref">Mack and Munson 2012b</a>)</span>. Expectations need not be accurate to shape perception <span class="citation" data-cites="preston1996">(<a href="#ref-preston1996" role="doc-biblioref">Preston 1996</a>)</span>.</p>
<p>Relatedly, one can <em>control</em>, in production, the phonetics of one’s gender without explicit acknowledgement or introspective awareness that one is doing so or what those details might be. Indeed, children as young as 4, well before any effects of puberty might have arrived, can do precisely this <span class="citation" data-cites="perryOhdeAshmead2001">(<a href="#ref-perryOhdeAshmead2001" role="doc-biblioref">Perry, Ohde, and Ashmead 2001</a>)</span> and many of our own college students, when first confronted with the idea that they participate in the social construction of gender through the fine phonetic details of their speech will respond with real, sometimes agitated, disbelief. Even trained, experienced sociolinguists and phoneticians tend to conceive of the fundamental frequency of the voice, the prevailing frequency of vocal fold vibration during voiced sounds, as a primary, biological phonetic detail associated with gender performance <span class="citation" data-cites="foulkesDocherty2006">(<a href="#ref-foulkesDocherty2006" role="doc-biblioref">Foulkes and Docherty 2006, 411</a>)</span>; when this cue is neither necessary nor sufficient for the production and perception of gender identity <span class="citation" data-cites="zimman2017 johnson2005">(<a href="#ref-zimman2017" role="doc-biblioref">Zimman 2017</a>; <a href="#ref-johnson2005" role="doc-biblioref">Johnson 2005</a>)</span>.</p>
<p>In perception the concept of control is less intuitive, but it is necessary to explore perceptual control for the purposes of the present chapter. Here we owe much of our general conceptualization of ‘control’ to <span class="citation" data-cites="BabelIssue">(<a href="#ref-BabelIssue" role="doc-biblioref">Babel this issue</a>)</span>‘s application of the semiotic role of the interpretant in perception and Preston’s <span class="citation" data-cites="preston1996 preston2016">(<a href="#ref-preston1996" role="doc-biblioref">1996</a>, <a href="#ref-preston2016" role="doc-biblioref">2016</a>)</span> four modes of awareness. Critical to our understanding of this phenomenon is the stipulation that the ability to ’perform’ or to ‘employ’ the linking relationship between a social label and its phonetic reflexes is just as clearly a task for the listener as it is for the talker. Social meaning making occurs in interaction; a listener must be able to control, to link, the auditory cues of a performed gender identity to the cognitive representation of that identity just as much as a talker’s vocal tract must be capable of the gestural control required to implement the phonetics of that identity if the tripartite, dialogic construction of identity in discourse is to occur. Again, none of this <em>requires</em> introspective awareness as perception and even attention are possible without awareness on the part of the perceiver <span class="citation" data-cites="craik_recognition_2015 prinz_unconscious_2015 graziano_attention_2015 dehaene_towards_2001">(<a href="#ref-craik_recognition_2015" role="doc-biblioref">Craik, Rose, and Gopie 2015</a>; <a href="#ref-prinz_unconscious_2015" role="doc-biblioref">Prinz 2015</a>; <a href="#ref-graziano_attention_2015" role="doc-biblioref">Graziano and Webb 2015</a>; <a href="#ref-dehaene_towards_2001" role="doc-biblioref">Dehaene and Naccache 2001</a>)</span>.</p>
<p>Clarifying these definitions and exploring their implications for the sociophonetic perception of gender is important because gender perception is a phenomenon that crosses disciplinary and subdisciplinary boundaries and approaches to language and social meaning. With these varying disciplinary and subdisciplinary contexts come quite different, sometimes contradictory, assumptions and theoretical commitments about the extent to which language users can bring aspects of perception into introspective awareness and control (conscious or otherwise). Even more than this, there are at least two, quite distinct, meanings in regular use for the word ‘perception’ <span class="citation" data-cites="mcgowanBabel2020">(<a href="#ref-mcgowanBabel2020" role="doc-biblioref">McGowan and Babel 2020</a>)</span>. Researchers, typically working within the fields of segmental speech perception or word recognition have used perception to describe a kind of low-level, implicit, processing of sensory input <span class="citation" data-cites="evans2008">(see <a href="#ref-evans2008" role="doc-biblioref">Evans 2008, ‘type 1’</a> processing)</span> into linguistic units like segments <span class="citation" data-cites="lisker1986 pierrehumbert2003phonetic">(<a href="#ref-lisker1986" role="doc-biblioref">Lisker 1986</a>; <a href="#ref-pierrehumbert2003phonetic" role="doc-biblioref">Pierrehumbert 2003</a>)</span>, speech gestures <span class="citation" data-cites="Fowler1986">(<a href="#ref-Fowler1986" role="doc-biblioref">Fowler 1986</a>)</span>, and words <span class="citation" data-cites="gaskell2002representation Goldinger1998">(<a href="#ref-gaskell2002representation" role="doc-biblioref">Gaskell and Marslen-Wilson 2002</a>; <a href="#ref-Goldinger1998" role="doc-biblioref">Goldinger 1998</a>)</span>. Perception, thus construed, is typically assumed to be automatic and to occur below the level of conscious awareness <span class="citation" data-cites="Joos1948">(<a href="#ref-Joos1948" role="doc-biblioref">Joos 1948, 63</a>)</span> and inaccessible to introspection even, in the case of subcategorical phonetic differences, by researchers themselves <span class="citation" data-cites="whalen1984">(<a href="#ref-whalen1984" role="doc-biblioref">Whalen 1984</a>)</span>. <span class="citation" data-cites="Johnson2006">Johnson (<a href="#ref-Johnson2006" role="doc-biblioref">2006, 492–94</a>)</span> proposes the word as the lowest level of linguistic experience that most language users typically have awareness of.</p>
<p>The other meaning of perception in common use in the various language disciplines describes a higher-level, sometimes implicit, sometimes explicit, evaluative judgment of talkers and voices <span class="citation" data-cites="evans2008">(see <a href="#ref-evans2008" role="doc-biblioref">Evans 2008, ‘type 2’</a> processing)</span>. This is the meaning of perception employed in folk linguistics <span class="citation" data-cites="niedzielskiPreston2000">(<a href="#ref-niedzielskiPreston2000" role="doc-biblioref">Niedzielski and Preston 2000</a>)</span> and perceptual dialectology <span class="citation" data-cites="cramer2021">(<a href="#ref-cramer2021" role="doc-biblioref">Cramer 2021</a>)</span>. This is also the level of perception, for example, at which the sociolinguistic monitor is proposed by variationist sociolinguists to operate<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a><span class="citation" data-cites="labovEtAl2011">(<a href="#ref-labovEtAl2011" role="doc-biblioref">Labov et al. 2011</a>)</span>. Importantly for the present study, this higher, evaluative level of perception is also the level for which the Matched Guise Technique (MGT) was originally developed.</p>
<section id="sub-mgt" class="level3">
<h3 class="anchored" data-anchor-id="sub-mgt">Matched Guise: Perception, Evaluation, and Awareness</h3>
<p>In their foundational use of the MGT <span class="citation" data-cites="lambertEtAl1960">Lambert et al. (<a href="#ref-lambertEtAl1960" role="doc-biblioref">1960</a>)</span> found that four bilingual Montrealer’s voices evoked quite different social evaluations in their French vs their English guises. Using the same talkers in both guises allowed researchers to control for “idiosyncratic settings of the voice” that might distract judges from the focus of the experiment <span class="citation" data-cites="laver1968">(<a href="#ref-laver1968" role="doc-biblioref">Laver 1968</a>)</span>. Lambert et al.&nbsp;were clearly concerned that the evaluative judgments they sought were subject to listeners’ subjective awareness; taking pains to deceive participants with filler voices, withholding the information that some of the talkers in the study might be bilingual, and ultimately reporting that, “[t]here was no indication that any S became aware of the fact that bilingual speakers were used” <span class="citation" data-cites="lambertEtAl1960">(<a href="#ref-lambertEtAl1960" role="doc-biblioref">Lambert et al. 1960, 44</a>)</span>. <span class="citation" data-cites="pharaoKristiansen2019">Pharao and Kristiansen (<a href="#ref-pharaoKristiansen2019" role="doc-biblioref">2019, 2</a>)</span> note that researchers, across both psychology of language and sociolinguistic traditions, go to great lengths to ensure this lack of awareness.</p>
<p>One, perhaps surprising but recurring, demonstration of the two distinct uses of the term perception described here is that, when both levels are examined in the same study, listeners’ low level perceptions and high level evaluations need not agree. <span class="citation" data-cites="mcgowanBabel2020">McGowan and Babel (<a href="#ref-mcgowanBabel2020" role="doc-biblioref">2020</a>)</span>, for example, found that listeners’ performance on an AXB vowel discrimination task and their answers in a subsequent interview about the voices heard in that task sometimes agreed, but sometimes diverged. When they diverged, the low level perceptions tracked vowel categories established by the listeners’ earlier experience with the voice while high level evaluations of the talker much more closely tracked language ideologies regarding the Quechua-dominant or Spanish-dominant speaker social labels provided by the experiment. Indeed, several participants explicitly commented on the differences between the fricatives used by the two guises; speech sounds that had been held identical in the stimuli.</p>
<p>In an early use of the MGT to study listeners’ evaluations of regional accents in the UK and the Republic of Ireland, <span class="citation" data-cites="milroyMcClenaghan1977">Milroy and McClenaghan (<a href="#ref-milroyMcClenaghan1977" role="doc-biblioref">1977</a>)</span> employed four speakers to each perform their own single accent: Received Pronunciation, Ulster, Dublin, or Scottish. They note that Lambert’s bilingual investigation in which “unknown to the judges a single speaker was heard in different guises … seems more suitable for use in the bilingual situation where it was originally developed than for use with different accents.” (p.&nbsp;2). The methodological consideration here is one of control, rather than awareness, on the part of both talker and listener. Milroy &amp; McClenaghan express “grave reservations” that a single talker, even a talented mimic, could authentically control all four of the regional varieties to be evaluated. Unstated in this preoccupation with production is the corresponding concern that listeners will not <em>believe</em> the mimicked accents.</p>
<p>The predominantly protestant Ulster listeners in this task provided both subjective evaluations of the voice quality of each talker on 8 personal characteristics such as intelligence, generosity, and friendliness and were asked to name the region associate with each voice. While the personal characteristics ratings closely tracked expected ideologies for an Ulster judge responding to a Scottish, RP, Dublin, and Ulster accent, the participants proved almost entirely incapable of correctly labeling each variety <span class="citation" data-cites="campbell-kiblerIssue clopperPisoni2004 kristiansen2009">(see also <a href="#ref-campbell-kiblerIssue" role="doc-biblioref">Campbell-Kibler, this issue</a>; <a href="#ref-clopperPisoni2004" role="doc-biblioref">Clopper and Pisoni 2004</a>; <a href="#ref-kristiansen2009" role="doc-biblioref">Kristiansen 2009</a>)</span>. Milroy and McClenaghan suggest in their conclusion that perhaps accent identification “takes place below the level of conscious awareness” with implicit stereotypical associations of a given accent arising in the listener independently of a conscious ability to explicitly name that accent.</p>
<p>This recurring disjunction in listeners’ implicit and explicit responses, even within a speaker evaluation paradigm, points to what <span class="citation" data-cites="kristiansen2009">(<a href="#ref-kristiansen2009" role="doc-biblioref">Kristiansen 2009, 169</a>)</span> has described as “layers of consciousness” and motivates <span class="citation" data-cites="BabelIssue">(<a href="#ref-BabelIssue" role="doc-biblioref">Babel this issue</a>)</span> to describe perception as a “complex, multi-layered process”. The picture that is emerging is one of simultaneous, layered complexity in the interactive process of social meaning making. A listener to even a single spoken word combines multi-modal sensory information, their own experiences with language, their own experiences with social meanings, their stereotypes, and their context-driven expectations about the voice they are likely to hear, the words that voice is likely to produce, and the socioindexical properties that voice is likely to embody. And rather than the outcome of perception (broadly construed) being a simple lexical item, a set of speech segments, a single attitude, or a summary evaluative judgment, the listeners subjective experience appears to be a rich, potentially contradictory, superposition of all of these and more.</p>
<p>The Matched Guise technique has been deployed in numerous configurations but, at its core, the technique pairs a single linguistic signal: such as an identical talker <span class="citation" data-cites="giles1970">(<a href="#ref-giles1970" role="doc-biblioref">Giles 1970</a>)</span>, identical recordings <span class="citation" data-cites="Niedzielski1999">(<a href="#ref-Niedzielski1999" role="doc-biblioref">Niedzielski 1999</a>)</span>, identical texts with multiple talkers <span class="citation" data-cites="milroyMcClenaghan1977">(<a href="#ref-milroyMcClenaghan1977" role="doc-biblioref">Milroy and McClenaghan 1977</a>)</span>, or some combination of these. This signal is paired with multiple purported social categories to investigate the influence of those categories on participants’ evaluations <span class="citation" data-cites="campbell-kibler2005 campbell-kibler2007">(<a href="#ref-campbell-kibler2005" role="doc-biblioref">Campbell-Kibler 2005</a>, <a href="#ref-campbell-kibler2007" role="doc-biblioref">2007</a>)</span> or language attitudes <span class="citation" data-cites="hadodoIssue chan2021">(<a href="#ref-hadodoIssue" role="doc-biblioref">Hadodo this issue</a>; <a href="#ref-chan2021" role="doc-biblioref">Chan 2021</a>)</span>.</p>
<p>In social, segmental speech perception research, cross-modal audio/visual extensions of the MGT are common in which visual information serves as a ‘guise’ for identical voice recordings. <span class="citation" data-cites="campbell-kibler2016 gnevsheva2017 McGowan2015 rubin1992">(<a href="#ref-campbell-kibler2016" role="doc-biblioref">Campbell-Kibler 2016</a>; <a href="#ref-gnevsheva2017" role="doc-biblioref">Gnevsheva 2017</a>; <a href="#ref-McGowan2015" role="doc-biblioref">McGowan 2015</a>; <a href="#ref-rubin1992" role="doc-biblioref">Rubin 1992</a>)</span>. This type of guise manipulation has been called ‘inverted’ matched guise <span class="citation" data-cites="McGowan2015">(<a href="#ref-McGowan2015" role="doc-biblioref">McGowan 2015</a>)</span> or simply ‘identification’ <span class="citation" data-cites="drager2013">(<a href="#ref-drager2013" role="doc-biblioref">Drager 2013</a>)</span>. The inverse MGT has traveled far from its original context of bilingual evaluations but uniting these linguistic researchers, and delineating them from colleagues in social psychology <span class="citation" data-cites="rosseelGrondelaers2019">(for discussion, see <a href="#ref-rosseelGrondelaers2019" role="doc-biblioref">Rosseel and Grondelaers 2019</a>)</span>, is the foundational methodological assumption that the connection of voice to social type is available to participants’ introspective awareness and therefore requires that listeners not become aware of the guise manipulation.</p>
<p>A central focus of <span class="citation" data-cites="mcgowanBabel2020">McGowan and Babel (<a href="#ref-mcgowanBabel2020" role="doc-biblioref">2020, 246–48</a>)</span>’s discussion, particularly of their interview results, centers on the question of whether deception was successful and listeners <em>believed</em> the two MGT guise manipulations. In part this is because they observe a stark disjunction between the segmental and evaluative levels of perception. In part, belief is especially important in a paper that reports the outcome of an unusual within-subjects MGT which presents both guises to each participant. But more fundamentally, and of interest to anyone employing the MGT for language perception or evaluation research, the assumption of belief, of the requirement that listeners not become aware of the deception inherent in whatever version of the signal/social label guise manipulation being deployed, is at the core of the MGT, and has been from the beginning.</p>
<p>However, the majority of studies cannot speak directly to this lack of awareness. XXX</p>
<p>during segmental perception because the data provided by the participants is relatively late in processing and involves layers of potential introspection and evaluation that block access to the initial online percept for listeners and researchers alike.</p>
<p>XXX I was working here</p>
<p>Articulatorily, these fricatives mainly differ in the distance between the point of lingual articulation and the teeth. The size of the resulting space behind the teeth gives these sounds their characteristic sibilance <span class="citation" data-cites="fant1960 shadle1991">(<a href="#ref-fant1960" role="doc-biblioref">Fant 1960</a>; <a href="#ref-shadle1991" role="doc-biblioref">Shadle 1991</a>)</span>. English [s] has a short resonating chamber behind the teeth; it is typically produced by holding the tongue tip near enough to the alveolar ridge to cause relatively high frequency turbulent airflow. English [ʃ] has a comparatively larger resonating chamber; it is typically produced with a more posterior, palato-alveolar tongue position which creates a larger resonating chamber between the place of articulation and the teeth, causing lower frequency noise than an [s] for the same talker. Concomittant with this articulatory difference for English listeners is a cultural association of masculinity with larger, longer vocal tracts and femininity with smaller, shorter vocal tracts <span class="citation" data-cites="may1976 ohala1994 eckert2012">(<a href="#ref-may1976" role="doc-biblioref">May 1976</a>; <a href="#ref-ohala1994" role="doc-biblioref">Ohala 1994</a>; <a href="#ref-eckert2012" role="doc-biblioref">Eckert 2012</a>)</span>. [s] produced from a larger vocal tract will typically be lower in frequency than an [s] produced from a smaller vocal tract, and listeners know this <span class="citation" data-cites="may1976">(<a href="#ref-may1976" role="doc-biblioref">May 1976</a>)</span>. This effect is, in practice, entirely separable from between-talker differences in fundamental frequency (F0) and, like F0, can be used to perform and perceive gender identity.</p>
<p>A commonly used methodology in speech perception research involves the creation of synthetic fricative continua between [ʃ] and [s] . These continua have endpoints in prototypical examples of [ʃ] and [s] with some number of acoustic steps spliced, synthesized, or even mixed between these. Near the middle of such a continuum will be a synthetic fricative that is ambiguous as to category membership: not clearly a [ʃ] and not clearly an [s]. <span class="citation" data-cites="may1976">May (<a href="#ref-may1976" role="doc-biblioref">1976</a>)</span> paired such a continuum from [ʃ] (centered at 2.9 kHz) to [s] (centered at 4.4 kHz) with synthetic [æ] vowels to form simple CV syllables. May found that listeners perceived a higher proportion of the fricative continuum as [ʃ] when paired with vowel stimuli from a smaller vocal tract. The logic here is that smaller resonating chambers between the lingual articulation and teeth will have a higher mean frequency than larger resonating chambers. Listeners’ use of apparent vocal tract size in perception reflect their knowledge of this variation <span class="citation" data-cites="munson2011">(<a href="#ref-munson2011" role="doc-biblioref">Munson 2011</a>)</span>.</p>
<p>Previous research in sociophonetic perception has established that listeners are so acutely sensitive to the alignment of these acoustic facts and cultural associations that perceived gender and fricative category participate in a relationship that is highly reminiscent of a phonetic trading relation <span class="citation" data-cites="repp1982">(<a href="#ref-repp1982" role="doc-biblioref">Repp 1982</a>)</span> such that, for example, fricative sounds consistent with a larger vocal tract are perceived as more masculine <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019</a>)</span> and, in tandem, believing that a talker identifies as male can lead listeners to perceive more [ʃ]-like sounds as [s] <span class="citation" data-cites="strandJohnson1996 munson2011">(<a href="#ref-strandJohnson1996" role="doc-biblioref">Strand and Johnson 1996</a>; <a href="#ref-munson2011" role="doc-biblioref">Munson 2011</a>)</span>.</p>
<p>The goal of the present study is to take advantage of this sociophonetic trading relation in listeners’ fricative categories to explore the role of awareness in socially-informed speech perception. It is well established that social information can influence how listeners perceive <span class="citation" data-cites="foulkesDocherty2006">(<a href="#ref-foulkesDocherty2006" role="doc-biblioref">Foulkes and Docherty 2006</a>)</span>, retrieve <span class="citation" data-cites="walkerHay2011">(<a href="#ref-walkerHay2011" role="doc-biblioref">Walker and Hay 2011</a>)</span>, and even remember <span class="citation" data-cites="nygaard1994">(<a href="#ref-nygaard1994" role="doc-biblioref">Nygaard, Sommers, and Pisoni 1994</a>)</span> the linguistic aspect of the speech signal. However, because our knowledge of these phenomena come from disparate intellectual traditions, working with a range of quantitative and qualitative methods, with differing assumptions about the role of introspective awareness during the integration of social and linguistic information <span class="citation" data-cites="babelCampbell-kiblerMcGowanIssue">(<a href="#ref-babelCampbell-kiblerMcGowanIssue" role="doc-biblioref">Babel, Campbell-Kibler, and McGowan, this issue</a>)</span>, one can come away from a detailed, rigorous review of the sociolinguistics, linguistic anthropology, and phonetics literature simultaneously convinced that listeners’ use of social information happens both obligatorily above and below the level of conscious awareness.</p>
</section>
<section id="sec-coart-soc" class="level2">
<h2 class="anchored" data-anchor-id="sec-coart-soc">Coarticulatory and Social Information Influence [ʃ]-[s] perception</h2>
<p>Listeners are sensitive to these socially-informative patterns of [ʃ]-[s] variation, but it is important to understand how similar this sensitivity is to what has previously been observed in segmental speech perception. Just as vocal tract size can alter the frequencies of fricatives <span class="citation" data-cites="may1976">(e.g. <a href="#ref-may1976" role="doc-biblioref">May 1976</a>)</span>, so too can coarticulation with a following vowel. Due to both place of articulation of the vowel and a change in lip rounding, the fricative in <em>see</em> [si] or <em>she</em> [ʃi] will sound higher than the fricative in <em>sue</em> [su] or <em>shoe</em> [ʃu] <span class="citation" data-cites="MannRepp1980 kunisakifujisaki1977 whalen1981">(<a href="#ref-MannRepp1980" role="doc-biblioref">Mann and Repp 1980</a>; <a href="#ref-kunisakifujisaki1977" role="doc-biblioref">Kunisaki and Fujisaki 1977</a>; <a href="#ref-whalen1981" role="doc-biblioref">Whalen 1981</a>)</span>. <span class="citation" data-cites="whalen1984">Whalen (<a href="#ref-whalen1984" role="doc-biblioref">1984</a>)</span> paired synthesized vowels with incongruously coarticulated fricatives and found that, although researchers could not consciously identify the mismatched stimuli, participants nevertheless showed longer reaction times due to these coarticulatory mismatches. Listeners will readily fill-in missing or ambiguous information, the presence of actively <em>incongruous</em> articulatory information slows listener judgments.</p>
<p>Working in the context of segmental speech perception, <span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> replicated May’s (1976) finding, extending it to natural productions of vowels spoken by a male or female-identified talker. Similar to May’s results with simulated vocal tract size, Mann &amp; Repp found a higher proportion of the fricative continuum was heard as [ʃ] when paired with the speech of the female talker. This early work, as was common in the period <span class="citation" data-cites="ohala1984">(<a href="#ref-ohala1984" role="doc-biblioref">Ohala 1984</a>)</span>, theorized size as being a relatively deterministic feature of talker sexual dimorphism. One consequence of this view is that gender-related variation in the speech signal was considered mechanistic, universal, and following from purely physical laws. If vocal tract size is presumably not available for individual performance then listener knowledge of this variation can be correspondingly simple. Vocal tract size may influence perception, but it does so implicitly, automatically, and below the level of introspective awareness.</p>
<p><span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span> conducted a pair of experiments investigating the influence of purported gender of a talker on the perception of the [ʃ]-[s] boundary. In their first experiment, listeners heard a [ʃ]-[s] continuum paired with voices previously normed as prototypically female, non-prototypically female, prototypically male, and non-prototypically male. The result replicates <span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> and extends it to show that the influence of a gendered voice correlates with the protypicality of that voice. Their second experiment finds that presenting listeners with prototypically-gendered videos of their purported talker can, again, shift perceptions of the [ʃ]-[s] such that listeners report hearing a higher proportion of the continuum as [ʃ] when watching a female talker and a higher proportion of the same continuum as [s] when watching a male talker.</p>
<p>This AV condition is reminiscent of <span class="citation" data-cites="McGurkMacDonald1976">McGurk and MacDonald (<a href="#ref-McGurkMacDonald1976" role="doc-biblioref">1976</a>)</span> and is presented in that context. In the McGurk Effect, listeners presented with, for example, video of a person pronouncing the syllable [ga], paired with audio of the syllable [ba] will experience a third, fused, percept [da]. A striking feature of this effect is its automaticity; participants can not choose to perceive the two components of a fused percept independently. Awareness of the manipulation does not undermine the effect. Indeed, <span class="citation" data-cites="greenKuhlMeltzoffStevens1991">Green et al. (<a href="#ref-greenKuhlMeltzoffStevens1991" role="doc-biblioref">1991a</a>)</span> found that the McGurk Effect succeeds even when listeners know that the visual talker and the auditory talker can not be the same person. McGurk can occur below the level of introspective awareness or, with instruction, above the level of introspective awareness. However, listeners, even with awareness, can not control their experience of the effect.</p>
<p>Listeners’ phonetic judgments, whether above or below the level of conscious awareness, depend on a rich constellation of evidence and expectation. Vocal tract size, following vowel quality, coarticulatory cues, and visual information, along with the acoustic properties of the coarticulated fricative itself, can all shape how listeners report experiencing a particular fricative. Rather than relying on a single, invariant, phonetic cue, listeners take the entire fricative and context into account <span class="citation" data-cites="whalen1991">(<a href="#ref-whalen1991" role="doc-biblioref">Whalen 1991</a>)</span>. It is conceivable that such exquisite sensitivity to the phonetic cues conveying linguistic category membership might somehow restrict language users’ freedom to communicate and perceive social information via the same phonetic signal. This would be the prediction of a phonetic theory in which linguistic information and social information share the phonetic signal in a kind of zero sum game –where listeners must normalize away social variation to recover linguistic information or lose linguistic information in favor of the social. Instead, with these fricatives at least, we can observe the opposite. The fricatives [ʃ] and [s] often carry social meaning <span class="citation" data-cites="podesvaKajino2014 mackMunson2012b">(<a href="#ref-podesvaKajino2014" role="doc-biblioref">Podesva and Kajino 2014</a>; <a href="#ref-mackMunson2012b" role="doc-biblioref">Mack and Munson 2012a</a>)</span> with [s] being “perhaps the most iconic phonetic variable in the field” <span class="citation" data-cites="calder2018">(<a href="#ref-calder2018" role="doc-biblioref">Calder 2018</a>)</span>. The implication is that the social and linguistic meanings of particular phonetic cues are not necessarily in competition with one another.</p>
<p>It is unclear from <span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span> and subsequent work whether the perceptual influence of visually-presented social information about gender is implicit and automatic, as observed with coarticulation, vocal tract size, and the McGurk effect or whether the effect is altered (or diminished) when listeners are made aware of the manipulation and their attention is drawn to socially-meaningful variables <span class="citation" data-cites="labovEtAl2011">(<a href="#ref-labovEtAl2011" role="doc-biblioref">Labov et al. 2011</a>)</span>. The present work seeks to resolve this cognitive question to better understand precisely how the stylistic bricolage of gender is perceived and how gender perception functions in interaction. How do linguistic and non-linguistic resources interact during perception and, finally, what happens when these signals conflict? In order to conduct this study, however, it is necessary to be precise about how we conceive of and operationalize gender for the purposes of a speech perception experiment.</p>
</section>
<section id="sub-gender" class="level2">
<h2 class="anchored" data-anchor-id="sub-gender">Phonetics, Speech Perception, and the Social-Construction of Gender</h2>
<p>It has long seemed normal in phonetics to imagine that gender is a simple, binary projection from biological sex onto social identity <span class="citation" data-cites="daniel2007 samolinski2007">(<a href="#ref-daniel2007" role="doc-biblioref">Daniel et al. 2007</a>; <a href="#ref-samolinski2007" role="doc-biblioref">Samoliński, Grzanka, and Gotlib 2007</a>)</span>. However, if these biological tendencies were simply deterministic we would expect to see differentiation emerge only at puberty. It does not. In fact, prior to the onset of puberty, girls’ oral and nasal cavities tend to be larger than those of boys <span class="citation" data-cites="samolinski2007">(<a href="#ref-samolinski2007" role="doc-biblioref">Samoliński, Grzanka, and Gotlib 2007</a>)</span>. If anything, we should expect lower formants and lower center and peak frequencies for girls, inverting the adult pattern. Instead what we observe is that listeners can differentiate the voices of children as young as 4 years of age using vowel formant frequencies <span class="citation" data-cites="perryOhdeAshmead2001">(<a href="#ref-perryOhdeAshmead2001" role="doc-biblioref">Perry, Ohde, and Ashmead 2001</a>)</span>. <span class="citation" data-cites="schellingerMunsonEdwards2017">Schellinger, Munson, and Edwards (<a href="#ref-schellingerMunsonEdwards2017" role="doc-biblioref">2017</a>)</span> report a pair of experiments in which participants heard words produced by children between the ages of 2 and 5, and provided continuous ratings identifying fricatives, vowels, and gender typicality. Children typically show gendered patterns in speech at age 4 and up despite vocal tract length being non-distinct for this cohort. It is critical to remember that formants and fricatives are the result of not purely vocal tract biology but also articulator coordination. Even without biologically-differentiated vocal tracts, people who identify as male or female can perform that identity through gestural style. Vowels, in both their linguistic and social aspects, are the acoustic consequence of gestural control.</p>
<p>Gender is more likely the product of, rather than an explanation for, linguistic variation <span class="citation" data-cites="eckertPodesva2021">(<a href="#ref-eckertPodesva2021" role="doc-biblioref">Eckert and Podesva 2021</a>)</span>. Just as with words, genders are arbitrary; both the social labels and their acoustic correlates are language specific <span class="citation" data-cites="johnson2005 Johnson2006">(<a href="#ref-johnson2005" role="doc-biblioref">Johnson 2005</a>, <a href="#ref-Johnson2006" role="doc-biblioref">2006</a>)</span> and the constellation of meanings are socially-constructed in interaction <span class="citation" data-cites="eckert2008">(<a href="#ref-eckert2008" role="doc-biblioref">Eckert 2008</a>)</span>. The formant ratios that distinguish ‘male’ from ‘female’ in Norwegian are markedly different from the formant ratios that do this in Danish <span class="citation" data-cites="Johnson2006">(<a href="#ref-Johnson2006" role="doc-biblioref">Johnson 2006</a>)</span>; what it means to be ‘male’ versus ‘female’ is quite different in Thailand than in Japan <span class="citation" data-cites="kang2013 alpert2014">(<a href="#ref-kang2013" role="doc-biblioref">Käng 2013</a>; <a href="#ref-alpert2014" role="doc-biblioref">Alpert 2014</a>)</span>. Children don’t perform adult-like vowel formant patterns because they were born tiny men and women, children perform adult-like vowel formant patterns because they identify as a gender and are using the cultural and linguistic resources available to communicate that gender to others. Humans are meaning-making agents, not deterministically resonating meat tubes.</p>
<p>In the earliest sociophonetic perception research it was still possible to imagine that the kind of knowledge listeners drew on to perceive gender was knowledge of primary biological traits. We now understand that, instead, the influence of gender-based expectations in speech perception is evidence of the influence of cultural knowledge on what might previously have been construed as purely linguistic decisions <span class="citation" data-cites="boydfruehwaldhall-lew_2021">(<a href="#ref-boydfruehwaldhall-lew_2021" role="doc-biblioref">Boyd, Fruehwald, and Hall-Lew 2021</a>)</span>. Just as vowel quality, lip rounding, and syllable affiliation influence the perception of these fricatives, so too do socially-constructed gender categories.</p>
<p>This paper reports an audiovisual matched guise experiment with both standard ‘hidden’ and novel ‘unhidden’ instruction conditions. The basic task is a replication of <span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span>. Listeners are asked to identify an ambiguous word as <em>sack</em> or <em>shack</em> on a [ʃ]-[s] continuum given manipulated beliefs about the gender identity of the talker <span class="citation" data-cites="trippMunson2022 steckerDOnofrioIssue">(<a href="#ref-trippMunson2022" role="doc-biblioref">Tripp and Munson 2022</a>; <a href="#ref-steckerDOnofrioIssue" role="doc-biblioref">Stecker and D’Onofrio, this issue</a>)</span>. As described above, numerous previous replications have found that listeners perceive more of the ambiguous continuum as [ʃ] when they believe the speaker identifies as a woman and more as [s] when they believe the speaker identifies as a man and that, furthermore, this effect is bi-directional, with fricative type influencing perception of gender for an ambiguous voice <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019</a>)</span>. Unusually, participants in the present study’s ‘unhidden’ instruction condition were briefed, in the instructions, about the guise manipulation. They were instructed that the man or woman in the photo was not associated with the voice they were listening to. <span class="citation" data-cites="campbell-kibler2020">(<a href="#ref-campbell-kibler2020" role="doc-biblioref">Campbell-Kibler 2021</a>)</span>, using a similar manipulation, finds that listeners have some ability to disregard social information when making accentedness or attractiveness judgments but that influence of available social information, particularly from the voice, is difficult to disregard completely. In the present study, participants were asked to provide a <em>sack</em>/<em>shack</em> lexical decision either with, or without, explicit instructions to disregard the visual stimulus.</p>
</section>
</section>
<section id="sec-method" class="level1">
<h1>Method</h1>
<section id="sub-participants" class="level2">
<h2 class="anchored" data-anchor-id="sub-participants">Participants</h2>
<p>120 participants (self-identified 59 female, 61 male; ages 20 to 75) were recruited to complete the online experiment online. These participants were recruited through prolific.com and had provided language history and demographic data as part of Prolific’s general pre-screening questionnaire. Participation was restricted to a standard sample of desktop computer users located in the USA, who spent most of their childhoods in the US, spoke English as their first and primary language, and with no known language or hearing difficulties. Additionally, due to an audio playback restriction imposed by Apple Computer, the Safari web browser could not be used. Participants were urged only to accept the task if they could do so in a quiet space, free from distractions and wearing headphones for the 6 to 10 minute duration of the experiment (average time 6:51). Headphone usage was not verified within the instrument. No participants’ data were excluded from analysis. Participants were paid $3 for their time, pro-rated from a projected rate of $20/hour (actual rate: $26.29/hour). This same instrument was piloted in the Speech Perception lab of The Ohio State University and, while reaction times online were generally slower than in-person, results from the online administration were generally consistent with results collected under laboratory conditions. Four participants were excluded for low accuracy rates (below 85%).</p>
</section>
<section id="sub-stimuli" class="level2">
<h2 class="anchored" data-anchor-id="sub-stimuli">Stimulus Materials</h2>
<section id="sub-stimuli-auditory" class="level3">
<h3 class="anchored" data-anchor-id="sub-stimuli-auditory">Auditory Stimuli</h3>
<p>The auditory stimuli used in this study are the same wav-format files used in <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019</a>)</span>. The stimuli, which were generously shared with us, contain two parts, both of which are drawn from synthetic continua: a fricative onset and a VC rime. The fricative onsets comprise a synthetic six step /ʃ-s/ continuum. These steps were generated with the Klatt Synthesizer in Praat <span class="citation" data-cites="praat2001">(<a href="#ref-praat2001" role="doc-biblioref">Boersma 2001</a>)</span> using parameters identical to <span class="citation" data-cites="munson2011">Munson (<a href="#ref-munson2011" role="doc-biblioref">2011</a>)</span> ranging between the values of Munson’s second and eighth continuum steps (which were, in turn, based on the parameters used in <span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span>). Centers of Gravity ranged from 3.2 kHz (/ʃ/-like) to 7 kHz (/s/-like).</p>
<p>For the VC rime, two additional continua were modified from natural productions of [æk] spoken by one male-identifying and one female-identifying talker in the carrier phrase “Say sack again”. These five-step rime continua were created by evenly spacing mean F0 across consecutive steps such that the male /æk/ continuum increased F0 frequency and formant spacing from their unmodified values while the female talker’s /æk/ continuum decreased both parameters from unmodified. Following the separate creations of these continua, each synthesized fricative token was concatenated with each CV rime of /æk/ resulting in a total of 60 unique auditory stimuli. These manipulations are described in greater detail in Bouavichith et al’s section 2.1 and summarized visually in <a href="#fig-stimuli" class="quarto-xref">Figure&nbsp;1</a>. Unlike MGT studies that ask a talented, multi-dialectal talker to consciously change their speech style <span class="citation" data-cites="wright2023">(e.g. <a href="#ref-wright2023" role="doc-biblioref">Wright 2023</a>)</span>, these stimuli were produced by one female and one male talker who were asked to record speech in their normal voices. As these talkers were advanced doctoral students in a linguistics PhD program, some of the elements of such an identity are likely available to conscious reflection, but many of these indexical features are likely implicit, unavailable for conscious control, even for them.</p>
<div id="fig-stimuli" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-stimuli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/figure1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: @bouavichithEtAl2019 auditory stimulus continua. S1, S2, S3, S4, and S5 represent continuum steps from most sack-like to most shack-like fricatives. F0 and F1:F2 Ratio plots show the manipulations to the Male and Female voiced vowels."><img src="images/figure1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-stimuli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <span class="citation" data-cites="bouavichithEtAl2019">Bouavichith et al. (<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">2019</a>)</span> auditory stimulus continua. S1, S2, S3, S4, and S5 represent continuum steps from most <em>sack</em>-like to most <em>shack</em>-like fricatives. F0 and F1:F2 Ratio plots show the manipulations to the Male and Female voiced vowels.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sub-stim-evals" class="level2">
<h2 class="anchored" data-anchor-id="sub-stim-evals">Explicit Evaluations of Auditory Stimuli</h2>
<p>Because voices carry social information, we elicited explicit social ratings to better understand how our auditory stimuli might influence participants’ perception of the identities of the two talkers.40 undergraduate students at the Ohio State University (25 female, 15 male, ages 18-26) who participated in an in-person pilot version of the inverse matched guise experiment were asked to make judgments regarding the gender, gender prototypicality, and sexuality of a natural, unresynthesized, production of <em>sack</em> produced by each of the two talkers. Participants listened to the recording and then selected from a fixed set of responses; no free form responses were elicited.</p>
<p>Participants’ judgments of the female voice indicate general agreement about the gender identity of the speaker. Most participants (93%) indicated the speaker’s gender to be female (2 participants further specified ‘trans-female’), and 3 were unsure or otherwise unable to determine the speaker’s gender. For the female voice, average prototypicality ratings (in which, for a given gender, 0 is least prototypical, and 5 is most prototypical) were 4.3/5 if the participant had indicated ‘female’, and 2.75/5 if the participant had indicated ‘trans female’. Judgements of the voice’s sexuality were more variable, with 54% indicating they were unsure, 40% indicating the speaker was most likely heterosexual, and 1 participant each indicating the speaker was most likely bisexual or another sexuality.</p>
<p>Participants’ judgments of the male voice suggest similar agreement. 80% of participants indicated the speaker’s gender to be male,(1 further specified ‘trans-male’) and 21% were unsure of the gender of the speaker. Average prototypicality ratings were lower for the male speaker but similarly consistent: 3.6/5 if the participant had indicated the voice belonged to a ‘male’ speaker, and 2/5 if they had indicated the person speaking was a ‘trans male’. As with the female voice, judgements of the voice’s sexuality were more variable. 65% indicated they were unsure, 14% indicated the speaker was most likely heterosexual, and 16% indicated homosexual and, again, 1 each indicating the speaker was most likely bisexual, or another sexuality not listed. Crucially, no participants rated the female voice as male, or the male voice as female. The variation among ratings may be due to the presentation of options beyond binary female and male categories, and/or to the current cultural understanding of gender performance as distinct from sex. Despite this variability in responses, no ‘implausible’ answers were given. All things being equal, it is reasonable for a listener to believe there may be little perceptual difference in cis and trans voices for either male or female performances <span class="citation" data-cites="zimman2018">Zimman (<a href="#ref-zimman2018" role="doc-biblioref">2018</a>)</span>, and reasonable to consider ‘unsure’ the most acceptable option in lieu of asking the talker for their gender identity.</p>
<section id="sub-stimuli-visual" class="level3">
<h3 class="anchored" data-anchor-id="sub-stimuli-visual">Visual Stimuli</h3>
<p>The visual stimuli used in this study, again identical to the images used in <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019</a>)</span>, are shown in <a href="#fig-visual" class="quarto-xref">Figure&nbsp;2</a>. These included two face images, used for the guise manipulation, which were retrieved from the Chicago Face Database <span class="citation" data-cites="ChicagoFaceDatabase">(<a href="#ref-ChicagoFaceDatabase" role="doc-biblioref">Ma, Correll, and Wittenbrink 2015</a>)</span>, a resource containing high-resolution, normed images of faces indexed by gender and ethnicity. The faces selected were normalized for both physical attributes (i.e., measurements of particular facial dimensions), subjective ratings such as attractiveness, and for gender and gender prototypicality. As in Bouavichith et al., CFD-WF-015-006-N was selected as the representation of the gender-protypical female talker and CFD-WM-029-023-N was selected as the representation of the gender-prototypical male talker. Both images were converted to greyscale at the command line using ImageMagick <span class="citation" data-cites="imagemagick">(<a href="#ref-imagemagick" role="doc-biblioref">LLC 2023</a>)</span>.</p>
<p>Additionally, two gray-scale line drawings were used as visual representations of <em>shack</em> and <em>sack</em>. These images were used in place of orthographic targets both to maintain consistency with Bouavichith et al’s design and to facilitate future eye tracking investigation of this phenomenon.</p>
<div id="fig-visual" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-visual-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/facesanddrawings.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Stimuli comprised shack and sack targets (top) and a gender-protypical ‘male’ and ‘female’ face (bottom)"><img src="images/facesanddrawings.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-visual-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Stimuli comprised <em>shack</em> and <em>sack</em> targets (top) and a gender-protypical ‘male’ and ‘female’ face (bottom)
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sub-procedure" class="level2">
<h2 class="anchored" data-anchor-id="sub-procedure">Procedure</h2>
<p>The experiment was created in OpenSesame v3.3 <span class="citation" data-cites="opensesame">(<a href="#ref-opensesame" role="doc-biblioref">Mathôt, Schreij, and Theeuwes 2012</a>)</span> and exported for the web using OSWeb v1.4.14.0. Modifications to the experiment included translating portions of the python code into JavaScript and adding code to collect Prolific IDs and provide proof of completion to Prolific at the end of the experiment. This experiment was hosted on a JATOS <span class="citation" data-cites="JATOS">(<a href="#ref-JATOS" role="doc-biblioref">Lange, Kuhn, and Filevich 2015</a>)</span> instance hosted on an Ohio State University Linguistics Department server. Participants received a link to the experiment via Prolific and used their own computers, keyboards, and headphones to complete the experiment.</p>
<p>In a between-subjects design, participants were randomly assigned to one of two awareness conditions. These conditions differed only in the initial information provided as to the nature of the experiment. Participants in the <em>hidden</em> condition experienced a standard Matched Guise task. They were given no information about the task or the stimulus materials beyond the general instructions for completing the experiment: listen to the voice, press ‘z’ if you heard the word on the left, press ‘m’ for the word on the right. Participants in the <em>unhidden</em> condition also received this instruction and were given a partial debriefing regarding the task. They were informed that– while they would see faces onscreen while hearing words– the voices in a given trial were not produced by the person shown in the images, the images had been downloaded from a database of photographs created at the University of Chicago for experimental use, and that the auditory and visual stimuli were in no way related to each other. Participants were divided equally among these two conditions. Neither awareness condition was informed about the synthetic nature of the auditory stimuli.</p>
<p>Additionally, participants were assigned to one of two gender congruity conditions. Although the manipulated rimes sounded gender ambiguous to us, and had been rated as ambiguous by <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019</a>)</span>’s pilot participants, the possibility remained that the voices, particularly at the end-points, might be perceived incongruously with the faces as in, for example, <span class="citation" data-cites="McGowan2015">(<a href="#ref-McGowan2015" role="doc-biblioref">McGowan 2015</a>)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>In congruous trials, the faces and voices were paired such that participants were only presented with auditory stimuli from the female talker’s continuum alongside the female face and tokens from the male talker were only presented alongside the male face. In incongruous trials, by contrast, auditory stimuli from the female talker’s continuum were only ever presented alongside the male face and tokens from the male talker’s continuum were only ever presented alongside the female face. Half of participants were randomly assigned to each congruity condition, resulting in a 4-way between-subjects design across instruction and congruity conditions. Each participant heard all 60 auditory stimuli; 30 paired with the male face and 30 paired with the female face.</p>
<p>In each trial, participants were shown one of the two faces for 1500ms. Following this initial presentation, the face remained onscreen and was flanked by the <em>shack</em> and <em>sack</em> images. Simultaneously, one of the auditory stimuli was played over the headphones. The trial ended when the participant pressed an appropriate key on their physical keyboard and their response and reaction time data were uploaded to the JATOS instance. In both congruous and incongruous conditions, all 60 unique trials (30 per face) were presented twice to each participant for a total of 120 trials.</p>
</section>
</section>
<section id="sec-predictions" class="level1">
<h1>Predicted Results</h1>
<section id="sub-pred-face" class="level2">
<h2 class="anchored" data-anchor-id="sub-pred-face">Face: male or female</h2>
<p>Consistent with previous results, we expect to replicate the Strand effect; in general, we anticipate that more of the [ʃ]-[s] continuum will be heard as [ʃ] when participants are shown the female face and more to be heard as [s] when participants are shown the male face. However, these general predictions about the Face presentation when the congruence of auditory and visual components of the guise are taken as a whole.</p>
</section>
<section id="sub-pred-congruence" class="level2">
<h2 class="anchored" data-anchor-id="sub-pred-congruence">Congruence: pairing of face and voice</h2>
<p>To our knowledge, the influence of congruence has not been directly investigated for listeners’ joint perception of gender and fricative place. <span class="citation" data-cites="johnsonstranddimperio1999">(<a href="#ref-johnsonstranddimperio1999" role="doc-biblioref">Johnson, Strand, and D’Imperio 1999</a>)</span> tested AV integration of Male and Female faces with prototypical and non-prototypical gendered voices in a vowel quality perception task. They find what appears to be an incongruence effect with the prototypical male voice; listeners reported no difference in perceived vowel quality with this voice in either Face condition <span class="citation" data-cites="johnsonstranddimperio1999">(<a href="#ref-johnsonstranddimperio1999" role="doc-biblioref">Johnson, Strand, and D’Imperio 1999, 376</a>, Table 4)</span>. For this reason, we anticipate a replication of the Strand effect on fricative identification in our congruous trials (when Face and Voice do not conflict) but a failure to replicate for the incongruous trials (when Face and Voice provide conflicting social information). This difference may be stronger with the male voice, given both Johnson, Strand, and D’Imperio’s finding but also <span class="citation" data-cites="king2021">(<a href="#ref-king2021" role="doc-biblioref">King 2021</a>)</span>.</p>
<p>We make a similar prediction for reaction times. <span class="citation" data-cites="johnsonstranddimperio1999">(<a href="#ref-johnsonstranddimperio1999" role="doc-biblioref">Johnson, Strand, and D’Imperio 1999</a>)</span> did not collect reaction time data, but <span class="citation" data-cites="McGowan2011">(<a href="#ref-McGowan2011" role="doc-biblioref">McGowan 2011</a>)</span> reports longer reaction times for incongruous trials, albeit in a very different task, and <span class="citation" data-cites="whalen1984">(<a href="#ref-whalen1984" role="doc-biblioref">Whalen 1984</a>)</span> would seem to suggest that this should hold for listeners’ identification of fricatives on a [ʃ]-[s] continuum. Specifically, we predict longer reaction times, in general, for the Incongruous conditions. Furthermore, when gender information is most clear, at gender continuum steps 1 and 2 for the Male talker and at gender steps 4 &amp; 5 for the Female talker, and in conflict with the presented Face, listeners’ response times should be slower.</p>
<p>Since strong phonetic correlates of gender, F0 and F3, have been manipulated over the course of the VC rime continua in our auditory stimuli, we anticipate that the effect of incongruous face and voice should be strongest for the natural end points of the continua where the difference is most salient and weaker as phonetically-cued gender information becomes more ambiguous. These stimuli have been independently normed for ambiguity <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019, 1040</a>, Table 1)</span> in the 2nd and 3rd levels of the rime continua. This means we anticipate an interaction between Face and Rime step but only in the incongruous trials and only at the extremes of the rime continuum.</p>
</section>
<section id="sub-pred-guise" class="level2">
<h2 class="anchored" data-anchor-id="sub-pred-guise">Guise: Hidden or Unhidden</h2>
<p>The primary goal of this experiment was to explore the role of listener awareness and control in the matched guise technique. The tremendous care researchers take to ensure that the guise manipulation is hidden from participants suggests a kind of imagined fragility of the effects of social information on language perception. From this view: listeners who become aware of the guise manipulation will have introspective access to and deliberative control over the influence of visual social information on perception. If this is true, explaining the guise manipulation, in the unhidden condition, should have a strongly negative effect on the Strand effect. Alternatively, if the influence of social information is not available to introspection or deliberative control, we should see no change between the (traditional) hidden matched guise and the unhidden guise.</p>
<p>Additionally, we speculate that there may be a response time difference between the Hidden and Unhidden guises even if there is no apparent difference in percept between the conditions. It can certainly be the case that participants will arrive at the same behavioral responses via different cognitive processing paths, perhaps drawing on different levels of knowledge and awareness, and that these differences may be visible in response times between the Instruction conditions.</p>
</section>
</section>
<section id="sec-results" class="level1">
<h1>Results</h1>
<p>Participants provided a total of 14,400 trials (120 trials from each of 120 online participants; 3600 trials in each instruction x congruity condition). It is not clear what it means to be ‘accurate’ when asked to perceive fricatives from a continuum so accuracy was calculated only for responses to the [ʃ] and [s] endpoints. Overall, participants were highly accurate (96.8%) but four participants were excluded from further analysis for accuracy below the pre-determined 85% threshold reducing the total number of trials to 13,920. Trials were coded as correct if the participant responded ‘shack’ to onset step 1 or ‘sack’ to onset step 6. The four excluded participants all scored 67.5% accuracy or lower.</p>
<p>An additional 50 trials were excluded due to response times that were either too fast or too slow. To reduce the effects of response time outliers on subsequent analyses, all response times shorter than 50 ms (N=0) and longer than 5000ms (N=50) were excluded. The 5000ms response time cutoff was used instead of imposing an in-experiment time limit on responses to a trial to ensure that participants were required to respond to each trial. Altogether, 530 trials were excluded, leaving data from 13,870 trials for analysis (approximately 96.3% of the initial data set). The majority (96.8%) of the remaining response times were within a range between 200 and 2000ms. To increase normality of the distribution of response times across participants, the remaining response times were log-transformed.</p>
<section id="sub-results-fricative" class="level2">
<h2 class="anchored" data-anchor-id="sub-results-fricative">[ʃ]-[s] Percepts</h2>
<p><a href="#fig-scurve" class="quarto-xref">Figure&nbsp;3</a> presents listeners’ percepts on this 2AFC task. The horizontal axis in each of these four plots is the fricative (syllable Onset) continuum step. Step 1 of the continuum is most [ʃ]-like, step 6 is the most [s]-like, steps 3 &amp; 4 are the most ambiguous. Darker lines in <a href="#fig-scurve" class="quarto-xref">Figure&nbsp;3</a> present trials using the female Face; lighter lines present trials using the male Face. The Hidden and Unhidden instruction conditions are represented by the left and right columns of figures, respectively. The rows present the Congruous blocks where Face and Coda speaker voice shared a gender identity (top) and Incongruous trials where Face and Coda speaker voice mismatched in gender identity (bottom).</p>
<div id="fig-scurve" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scurve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Scurve.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: ‘sack’ responses plotted as a function of [ʃ]-[s] fricative (Onset) continuum steps and purported gender presented by the face."><img src="images/Scurve.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scurve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: ‘sack’ responses plotted as a function of [ʃ]-[s] fricative (Onset) continuum steps and purported gender presented by the face.
</figcaption>
</figure>
</div>
<p>A successful replication of the Strand effect would mean that a higher proportion of the ambiguous stimuli would be heard as [s] when the purported gender suggested by the face is male than when the face is female. This pattern appears to hold in both the Hidden and Unhidden conditions, but only when gender identity of the talker who produced the CV rime stimuli was congruous with the gender presented in the visual portion of the guise. From <a href="#fig-scurve" class="quarto-xref">Figure&nbsp;3</a> it would appear that listeners’ reported percepts more closely track the voice of the talker than the face in the picture when these sources of information are incongruous.</p>
<div id="fig-rimes" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rimes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/ambiguous-by-rime-step.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: ‘sack’ responses on ambiguous fricative trials plotted as a function of CV rime continuum steps and gender identity of stimulus talker."><img src="images/ambiguous-by-rime-step.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rimes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: ‘sack’ responses on ambiguous fricative trials plotted as a function of CV rime continuum steps and gender identity of stimulus talker.
</figcaption>
</figure>
</div>
<p>We predicted that, since strong phonetic correlates of gender have been manipulated over the course of the VC rime continua, the effect of incongruence should be strongest for the end points of the continua where the social information presented by the voice is, presumably, most salient and weaker as phonetically-cued gender information becomes more ambiguous. <a href="#fig-rimes" class="quarto-xref">Figure&nbsp;4</a> suggests that this prediction is at least partially borne out. <a href="#fig-rimes" class="quarto-xref">Figure&nbsp;4</a> plots proportion ‘sack’ responses to the ambiguous portion of the [ʃ]-[s] continuum (steps 3 &amp; 4) as a function of rime continuum step. The meaning of line color has changed in this figure. Dark lines represent the male talker and lighter lines represent the female talker. Step 1 on this continuum includes the most natural token for the male talker and the most manipulated token for the female talker while step 5 includes the most natural token for the male talker and the most manipulated token for the female talker. As before, columns present the Hidden and Unhidden conditions while rows present the Congruous and Incongruous blocks.</p>
<p>In a 2AFC task with unbiased stimuli, chance is 50%. Responses at the .5 line in <a href="#fig-rimes" class="quarto-xref">Figure&nbsp;4</a> suggest that the ambiguous fricatives remained ambiguous while responses that tend to be above this line reflect a tendency toward [s] percepts and responses that tend to be below this line reflect a tendency toward [ʃ]. Across all 4 conditions we observe a declination from highest-proportion [s] responses in step 1 of the F0 continua to lowest in step 5. When face and voice were congruous, virtually all male-voice (and male face) responses are above or at 50% ‘sack’ and virtually all female-voiced (and female face) responses are at or <em>below</em> 50% ‘sack’. This is the same pattern that can be observed at Onset continuum steps 3 &amp; 4 in <a href="#fig-scurve" class="quarto-xref">Figure&nbsp;3</a>. It is not clear from <a href="#fig-rimes" class="quarto-xref">Figure&nbsp;4</a> alone if there is any difference at all between the Congruous and Incongruous conditions. However, it is important to recall about the bottom row of this figure that male talker responses in the incongruous trials were presented with a female face while female talker trials were presented with a male face. Even a weakly-significant Strand effect would predict that the female talker, particularly on the more ambiguous continuum steps, should show more ‘sack’ responses consistent with having been shown a male face and no such effect is evident in this plot.</p>
<p>Indeed, a striking feature of these figures (<a href="#fig-scurve" class="quarto-xref">3</a>, <a href="#fig-rimes" class="quarto-xref">4</a>) is how the apparent influence of gender information flips between congruous and incongruous conditions in the former but remains essentially constant in the latter. Taken together, these plots suggest that cues to gender in F0 is a stronger predictor of listeners’ reported percept in this matched guise task than just the purported gender of the face.</p>
<p>Finally, the main objective of this experiment was to explore the role of listener awareness in the matched guise technique. Here again there may be differences between the congruous and incongruous conditions that will be better understood through quantitative analysis, but the overall trend is clear. If there is an effect of explaining to participants that the voice and face in the matched guise task are unrelated to each other, that effect is so weak as to be essentially invisible in these visual interrogations of the data. Categorical responses in the Hidden and Unhidden instruction conditions appear to be identical.</p>
</section>
<section id="sub-results-stats" class="level2">
<h2 class="anchored" data-anchor-id="sub-results-stats">Logistic Regression and Quantitative Analysis</h2>
<p>These qualitative assessments of listener responses can be examined further through quantitative analysis. Through model comparison we initially arrived at a logistic mixed model to predict percept with Congruity condition, instruction condition, Onset step, Face, and Rime step with interactions for all but Rime step. This model was justified by model selection but given the notorious difficulty of interpreting a 4-way interaction and the preceding visual interrogation of the data, we opted to separate Congruence into a pair of 3-way models. Using <code>glmer()</code> <span class="citation" data-cites="lme4">(<a href="#ref-lme4" role="doc-biblioref">Bates, Maechler, and Bolker 2011</a>)</span>, we divided the data into congruous and incongruous subsets and fitted a pair of logistic mixed models (estimated using ML and BOBYQA optimizer) to predict percept with Instruction condition, Onset.step, Face and Rime step (<code>percept ~ Instruction * Onset.step * Face + Rime.step</code>). The models included random intercepts for subject. All categorical predictors were coded using contrast coding.</p>
<div id="fig-coefs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-coefs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/coefs_instruction.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Beta coefficients for listener responses in the Congruous (black) and Incongruous (gray) logistic regression models plotted with 95% confidence intervals."><img src="images/coefs_instruction.png" class="img-fluid figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Beta coefficients for listener responses in the Congruous (black) and Incongruous (gray) logistic regression models plotted with 95% confidence intervals.
</figcaption>
</figure>
</div>
<p>Beta coefficients for the two separate logistic mixed models are plotted together in <a href="#fig-coefs" class="quarto-xref">Figure&nbsp;5</a>. Terms plotted to the left of the dashed zero line have a negative influence on ‘sack’ percepts in the model while terms plotted to the right have a positive influence. As a consistency check we can observe that the levels of the Onset continuum behave in precisely the expected ways and all levels are statistically significant predictors of percept in both models. Onset step 1 ([ʃ]) is negatively associated with ‘sack’ responses and significant in both the Congruous (<span class="math inline">\(β=-5.00\)</span>, <span class="math inline">\(SE=0.28\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) and Incongruous (<span class="math inline">\(β=-4.84\)</span>, <span class="math inline">\(SE=0.24\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) models. Onset step 5 ([s]) is positively associated with ‘sack’ responses and significant in both the Congruous (<span class="math inline">\(β=4.35\)</span>, <span class="math inline">\(SE=0.22\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) and Incongruous (<span class="math inline">\(β=4.12\)</span>, <span class="math inline">\(SE=0.19\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) models.</p>
<p>As visual inspection of the data suggests, this study includes a replication of the Strand effect in the Congruous condition. There is a main effect of Face in the model (<span class="math inline">\(β=-0.22, SE=0.09, p&lt;0.05\)</span>). Face is negatively associated with ‘sack’ responses suggesting that, with these stimuli, at least, it is more appropriate to understand the effect of Face as an increase of ‘shack’ responses given the female Face. The inclusion of the interaction term for Onset and Face allows us to see that the effect of Face is greatest on the ambiguous Onset steps 3 (<span class="math inline">\(β=-0.43\)</span>, <span class="math inline">\(SE=0.11\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) and, to a lesser extent, 4 (<span class="math inline">\(β=-0.23\)</span>, <span class="math inline">\(SE=0.11\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>).</p>
<p>However, the Strand effect observed in the Congruous condition is not attributable entirely to the main effect of Face. Rime F0 is also significant; Rime level 1, the male end of the continuum, is positively associated with ‘sack’ responses (<span class="math inline">\(β=0.61\)</span>, <span class="math inline">\(SE=0.10\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) as is Rime level 2 (<span class="math inline">\(β=0.52\)</span>, <span class="math inline">\(SE=0.10\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>). Rime level 3, where the continuum is most gender ambiguous, is not statistically significant. Rime level 4, on the female end of the continuum, is negatively associated with ‘sack’ responses and significant (<span class="math inline">\(β=-0.49\)</span>, <span class="math inline">\(SE=0.10\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>).</p>
<p>Unsurprisingly, the Strand effect has not been replicated in the incongruous condition. As is visible in the bottom row of <a href="#fig-scurve" class="quarto-xref">Figure&nbsp;3</a>, the effect of Face on ‘sack’ responses is not significant. The interaction of Onset and Face also behaves quite differently in the Incongruous model. Onset x Face is negatively associated with ‘sack’ responses at Onset step 1 (<span class="math inline">\(β=-0.66\)</span>, <span class="math inline">\(SE=0.24\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) but positively associated with ‘sack’ responses and significant at Onset step 3 (<span class="math inline">\(β=0.27\)</span>, <span class="math inline">\(SE=0.11\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>).</p>
<p>Interestingly, the significant effect of Rime observed in the Congruous model also holds, nearly identically, in the Incongruous model. Rime level 1, the male end of the continuum, is again positively associated with ‘sack’ responses (<span class="math inline">\(β=0.77\)</span>, <span class="math inline">\(SE=0.10\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) as is Rime level 2 (<span class="math inline">\(β=0.41\)</span>, <span class="math inline">\(SE=0.10\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>). Rime level 3 is also not statistically significant in the Incongruous model. Rime level 4, on the female end of the continuum, is negatively associated with ‘sack’ responses and significant (<span class="math inline">\(β=-0.36\)</span>, <span class="math inline">\(SE=0.10\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>).</p>
<p>Finally, the quantitative analysis of the primary objective of this experiment, exploring the effect of unhiding the matched guise manipulation from participants, largely supports the qualitative analysis. As can be observed in <a href="#fig-coefs" class="quarto-xref">Figure&nbsp;5</a>, there is no significant main effect of Instruction condition in either model. Still, a somewhat more nuanced picture emerges from the interactions of Instruction condition with Onset and the 3 way interaction of Instruction, Onset, and Face in the Congruous trials. The interaction of Instruction with Onset is significant, or nearly so, at every step of the fricative continuum other than the most significant. In the [ʃ]-like portion of the continuum, the interaction with face is positively associated with ‘sack’ responses at step 1 (<span class="math inline">\(β=0.65\)</span>, <span class="math inline">\(SE=0.28\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>) and 2 (<span class="math inline">\(β=0.44\)</span>, <span class="math inline">\(SE=0.18\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>). The interaction of guise with the most ambiguous onset step is not significant (<span class="math inline">\(β=0.011\)</span>, <span class="math inline">\(SE=0.12\)</span>). The interaction of Instruction with Onset step 4, on the [s] end of the continuum is negatively associated with ‘sack’ responses and statistically significant (<span class="math inline">\(β=-0.43\)</span>, <span class="math inline">\(SE=0.12\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>). Instruction x Onset step4 is also negatively associated with ‘sack’ responses but does not reach significance at the standard alpha level (<span class="math inline">\(β=-0.40\)</span>, <span class="math inline">\(SE=0.22\)</span>, <span class="math inline">\(p = 0.067\)</span>). The 3-way interaction of Instruction x Onset x Face is positively associated with ‘sack’ responses at step 2 (<span class="math inline">\(β=0.41\)</span>, <span class="math inline">\(SE=0.17\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>) and weakly, but not significantly, negatively associated with ‘sack’ responses at step 5 (<span class="math inline">\(β=-0.38\)</span>, <span class="math inline">\(SE=0.21\)</span>, <span class="math inline">\(p = 0.080\)</span>).</p>
<p>There is also no main effect of Instruction in the Incongruous trials. The 3-way interaction of Instruction x Onset x Face, while justified by model selection for inclusion in this model, also does not reach statistical significance. However the 2-way interaction of Instruction with Onset step is positively associated with ‘sack’ responses at Onset step 2 (<span class="math inline">\(β=0.53\)</span>, <span class="math inline">\(SE=0.21\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>) and approaches significance at step 3, where it is weakly positively associated (<span class="math inline">\(β=0.18\)</span>, $SE=0.11, <span class="math inline">\(p = 0.095\)</span>) and step 5 where it is weakly negatively associated (<span class="math inline">\(β=-0.32\)</span>, <span class="math inline">\(SE=0.19\)</span>, <span class="math inline">\(p = 0.086\)</span>).</p>
</section>
<section id="sub-results-rt" class="level2">
<h2 class="anchored" data-anchor-id="sub-results-rt">Response Times</h2>
<p>As with the logistic regression models, we again opted to separate Congruence into a pair of 3-way models for linear mixed model analysis of our log-transformed response time data. Using <code>lmer()</code> <span class="citation" data-cites="lme4">(<a href="#ref-lme4" role="doc-biblioref">Bates, Maechler, and Bolker 2011</a>)</span>, we reused the congruous and incongruous subsets created for the logistic regression models and We fitted a linear mixed model (estimated using REML and nloptwrap optimizer) to predict logRT with Guise, Onset, Face and Rime (<code>logRT ~ Instruction * Onset * Face + Rime</code>). The models included random intercepts for subject. All categorical predictors were coded using contrast coding. Beta coefficients for both models are plotted in <a href="#fig-coefs-logRT" class="quarto-xref">Figure&nbsp;6</a>. Terms plotted to the left of the zero line are associated with a decrease in log response time while terms plotted to the right of the zero line are associated with an increase in log response time. Notably, the longest response times are associated with the most ambiguous steps of the [ʃ]-[s] onset continuum. Onset step 3 is positively associated with response time and significant in both the congruous (<span class="math inline">\(β=0.08\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) and incongruous ($β=0.0$7, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.001\)</span> ) models. The same is true of step 4 in the congruous (<span class="math inline">\(β=0.07\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) and incongruous (<span class="math inline">\(β=0.07\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>) models as well. On the other hand, steps 1, 2, and 5 are all negatively associated with response time and also significant in both models (see <a href="#fig-coefs-logRT" class="quarto-xref">Figure&nbsp;6</a>).</p>
<div id="fig-coefs-logRT" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-coefs-logRT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/coefs-logRT_instructions.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Beta coefficients for log-transformed response times in the Congruous (black) and Incongruous (gray) linear regression models plotted with 95% confidence intervals."><img src="images/coefs-logRT_instructions.png" class="img-fluid figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefs-logRT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Beta coefficients for log-transformed response times in the Congruous (black) and Incongruous (gray) linear regression models plotted with 95% confidence intervals.
</figcaption>
</figure>
</div>
<p>We predicted overall slower response times in the Incongruous than Congruous conditions and this prediction is not borne out by the data. Apart from generally higher variability in the incongruous conditions, there is no positive or negative trend in response times between the two Congruity models. For example, within the Incongruous model response times given the interaction of Onset step 3 * Face are longer (<span class="math inline">\(β=-0.009\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p = 0.17\)</span>), which would seem to support our prediction, but response times for Onset step 4 * Face are shorter (<span class="math inline">\(β-0.02\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.01\)</span>), the opposite of what we predicted. The exact opposite pattern appears within the Congruous model where response times are shorter given Onset 3 * Face (<span class="math inline">\(β=-0.02\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.01\)</span>) but longer given Onset step 4 * Face (<span class="math inline">\(β=0.04\)</span>, <span class="math inline">\(SE=0.007\)</span>, <span class="math inline">\(p &lt; 0.001\)</span>). These crossing patterns can be seen in <a href="#fig-coefs-logRT" class="quarto-xref">Figure&nbsp;6</a>.</p>
<p>Given the replication of the Strand effect in the Congruous, but not the Incongruous conditions described in the previous section, it may be notable that there is a significant main effect of Face in the Congruous model where it is negatively associated with response time (<span class="math inline">\(β=0.22\)</span>, <span class="math inline">\(SE=0.08\)</span>, <span class="math inline">\(p &lt; 0.05\)</span>) and not significant in the Incongruous model.</p>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>The question that motivated this study was a desire to understand the role of listener awareness and control in the matched guise technique. We believe that the careful measures researchers generally employ to obscure the nature of the guise manipulation from participants is attributable to a long-held assumption in the sociolinguistics literature that social knowledge is high-level knowledge, available to introspective control, and that this differs from linguistic knowledge which is low-level knowledge, unavailable to control <span class="citation" data-cites="campbell-kibler2016">(<a href="#ref-campbell-kibler2016" role="doc-biblioref">Campbell-Kibler 2016</a>)</span>. The results of the present study are inconsistent with this imagined fragility of the influence of social knowledge. Revealing the nature of the guise manipulation did not significantly influence listener responses in either the congruous or incongruous conditions. Nor did this revelation have a significant influence on response times in either condition.</p>
<p>The finding that the Matched Guise effect holds for speech perception both when hidden from the participant and when unhidden is inconsistent with a model of processing in which social knowledge simply acts as a filter on linguistic knowledge. Social knowledge influences perception even when listeners are aware that it is, or may be, false. This result parallels previous results for accentedness and attractiveness judgments <span class="citation" data-cites="campbell-kibler2020">(<a href="#ref-campbell-kibler2020" role="doc-biblioref">Campbell-Kibler 2021</a>)</span>. A similar result may be present, for social information, in the within-participants guise manipulation of <span class="citation" data-cites="mcgowanBabel2020">(<a href="#ref-mcgowanBabel2020" role="doc-biblioref">McGowan and Babel 2020</a>)</span>. In that study, the authors use participants’ metalinguistic commentaries to assess the extent to which the guise manipulations were or were not ‘believed’. The results of the present study suggests that that belief may be irrelevant. The present result also gives additional context to studies demonstrating influence of social knowledge even when listeners have no reason to believe the guise manipulation <span class="citation" data-cites="Niedzielski1999 haynolandrager2006 HayDrager2010">(<a href="#ref-Niedzielski1999" role="doc-biblioref">Niedzielski 1999</a>; <a href="#ref-haynolandrager2006" role="doc-biblioref">Hay, Nolan, and Drager 2006</a>; <a href="#ref-HayDrager2010" role="doc-biblioref">Hay and Drager 2010</a>)</span>. It is unclear whether social knowledge will prove to be as resilient to awareness as the obligatory McGurk effect <span class="citation" data-cites="McGurkMacDonald1976">(<a href="#ref-McGurkMacDonald1976" role="doc-biblioref">McGurk and MacDonald 1976</a>)</span> which persists even when participants actively identify that the face and voice in the experiment are mismatched <span class="citation" data-cites="GreenEtAl1991">(<a href="#ref-GreenEtAl1991" role="doc-biblioref">Green et al. 1991b</a>)</span>, but the suggestion is that it will.</p>
<p>The gender identity of the talker who produced the VC Rime supplemented Face in the Congruous conditions to make the Strand effect even stronger; the mechanism may prove similar to the way lip-rounding accentuates the backness of back vowels. In the Incongruous conditions, though, listeners’ perception of the [ʃ]-[s] continuum tracked the VC Rimes, rather than the purported gender of the Face. This pattern was strongest in the least-ambiguous portions of the Rime continuum and weakest in the most-ambiguous. In a sense, by separating trials by congruity of face and voice we have replicated <span class="citation" data-cites="strandJohnson1996">(<a href="#ref-strandJohnson1996" role="doc-biblioref">Strand and Johnson 1996</a>)</span>’s exp1 and exp2 simultaneously. One wonders, looking back at their exp2, whether this classic result was <em>also</em> a congruous condition in which listeners had sufficient gender information from the voice to supplement the purported information from the Face. Even the non-prototypical voices used in that study did pattern, in exp1, in weakly gendered ways. This finding may provide some insight into recent failures to replicate the original Strand effect <span class="citation" data-cites="schellingerMunsonEdwards2017 wilbanks2022">(<a href="#ref-schellingerMunsonEdwards2017" role="doc-biblioref">Schellinger, Munson, and Edwards 2017</a>; <a href="#ref-wilbanks2022" role="doc-biblioref">Wilbanks 2022</a>)</span>.</p>
<p>The phonetic correlates of gender manipulated in the VC rimes for this study are F0 and formant ratios. However, these may not be the only cues listeners are drawing upon with their knowledge of US English. Surely, F0 and vowel formant ratios <em>can be</em> important to listeners, just as voice onset time and vocal fold vibration can be important cues to the voicing of /t/ and /d/. But as <span class="citation" data-cites="lisker1986">(<a href="#ref-lisker1986" role="doc-biblioref">Lisker 1986</a>)</span> catalogs, there are 16 cues to this apparently simple feature in English, any of which might be sufficient to communicate voicing, but none of which is required. In this study we have used manipulated stimuli that obscure, over the course of two gender continua, the gender identity of the talker who produced the basis token for that continuum. At an explicit level, these continua <em>sound ambiguous</em> to the experimenters in much the way that <span class="citation" data-cites="whalen1984">(<a href="#ref-whalen1984" role="doc-biblioref">Whalen 1984</a>)</span>’s stimuli do not sound obviously mismatched. But our perception results suggest that listeners are still aware, albeit implicitly, of the gender identity we have attempted to obscure by altering the phonetic correlates of gender.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Decades of research since <span class="citation" data-cites="strandJohnson1996">(<a href="#ref-strandJohnson1996" role="doc-biblioref">Strand and Johnson 1996</a>)</span>‘s original finding have demonstrated that a visual cue can shift fricative perceptions when paired with an ambiguously-gendered voice (although cf Munson 2017 and Wilbanks 2022). <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al. 2019</a>)</span> demonstrated with eye-tracking that this effect is fast and bi-directional. One could come away from Strand &amp; Johnson’s exp1 and exp2 and subsequent replications with a theoretical model in which visually-cued social information and phonetically-cued social information exert equivalent influence on speech perception. Prototypically-gendered voices can shift perception of a [ʃ]-[s] continuum and prototypically-gendered visual information can as well. However, listeners’ behavior in our Congruous and Incongruous conditions is inconsistent with such a model and suggests, instead, that when visually-cued and phonetically-cued social information are in congruence, they can enhance one another. When, on the other hand, these information sources conflict, it is the phonetically-cued social information that will dominate <span class="citation" data-cites="campbell-kibler2020">(<a href="#ref-campbell-kibler2020" role="doc-biblioref">Campbell-Kibler 2021</a>)</span>.</p>
<p>It is unlikely that fricatives are unique in this respect. For example, the incongruous results seen in this study are, perhaps, predicted by lack of Face effect for <span class="citation" data-cites="johnsonstranddimperio1999">(<a href="#ref-johnsonstranddimperio1999" role="doc-biblioref">Johnson, Strand, and D’Imperio 1999</a>)</span>’s vowel perception results in exp2 given a stereotypical face (particularly, in that study, for the male voice). As listeners, we do not have veridical access to the speech sounds intended by a talker. Instead, we must combine the speech signal with our phonological knowledge, lexical knowledge, social expectations, visual input, expectations of the social world <span class="citation" data-cites="BabelIssue">(<a href="#ref-BabelIssue" role="doc-biblioref">Babel this issue</a>)</span> and other sensory information to arrive at a percept. The implication is that perception is more holistic than is dreamt of in our phonologies. Category boundaries, whether for speech sounds or social categories, are fuzzy and perception needs to be fast. We retain knowledge of, and use, detailed social and linguistic knowledge at both high and low levels of processing. Enumerating the phonetic correlates of gender may not be the wrong question, but it is certainly premature given the limitations of current theory to account for what listeners actually do. A better question is something like “what kinds of knowledge do listeners draw on during perception and when?”</p>
<p><span class="citation" data-cites="barrett2014">(<a href="#ref-barrett2014" role="doc-biblioref">Barrett et al. 2014, 205</a>)</span> writes, “any assumption of essentialism will ultimately marginalize those individuals who do not fit the essentialist understandings of human behavior”. It may not feel brutal or reductive to read <span class="citation" data-cites="may1976">(<a href="#ref-may1976" role="doc-biblioref">May 1976</a>)</span>’s findings about large and small vocal tracts as if they refer to male and female vocal tracts, respectively, but it does necessarily imply that tall, long-necked women and short, squat-necked men need to find some other way of labeling themselves. The idea that male voices come from large bodies and female voices come from small bodies need not be literally true for the phonetic and perceptual correlates of size to become enregistered alongside other features in the creation of gendered personae (D’Onofrio 2020). Our prediction that incongruity in face and voice would slow listener judgments was not supported. It is tempting to interpret this as evidence that, unlike misleading coarticulatory information, listeners are aware of the diversity of gender expression, but this is not a question the current study can resolve.</p>
<p>What the current study can resolve is that listeners’ social knowledge of speech is not delicate. The present result is equally inconsistent with a model that disregards social knowledge entirely and with any model of speech perception that presumes <em>all</em> social knowledge to be late, high-level, and available to introspective control. Part of what listeners know when they know a language includes the simultaneous patterning of ‘linguistic’ and ‘social’ information in a shared phonetic signal. Social knowledge is not a weakly-associated prime; Social knowledge and linguistic knowledge are deeply intertwined in speech perception and it is perverse to assume that the language subsystem underlying this ability would necessarily distinguish them.</p>
</section>
<section id="sec-references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-alpert2014" class="csl-entry" role="listitem">
Alpert, Erika Renée. 2014. <span>“Language, Gender, and Ideology in Japanese Professional Matchmaking.”</span> PhD thesis, University of Michigan, Department of Anthropology.
</div>
<div id="ref-BabelIssue" class="csl-entry" role="listitem">
Babel, Anna M. this issue. <span>“A Semiotic Approach to Awareness and Control.”</span> <em>Journal of Sociolinguistics</em> 42 (1).
</div>
<div id="ref-babelCampbell-kiblerMcGowanIssue" class="csl-entry" role="listitem">
Babel, Anna M., Kathryn Campbell-Kibler, and Kevin B. McGowan. This issue. <span>“Introduction to the Thematic Issue.”</span> <em>Journal of Sociolinguistics</em> 42 (1).
</div>
<div id="ref-bakhtin1981" class="csl-entry" role="listitem">
Bakhtin, Mikhail Mikhaı̆lovich. 1981. <em>The Dialogic Imagination: Four Essays</em>. University of texas Press.
</div>
<div id="ref-barrett2014" class="csl-entry" role="listitem">
Barrett, Rusty, L Zimman, J Davis, and J Raclaw. 2014. <span>“The Emergence of the Unmarked.”</span> <em>Queer Excursions: Retheorizing Binaries in Language, Gender, and Sexuality</em>, 195–223.
</div>
<div id="ref-lme4" class="csl-entry" role="listitem">
Bates, Douglas, Martin Maechler, and Ben Bolker. 2011. <em>Lme4: Linear Mixed-Effects Models Using S4 Classes</em>. <a href="http://CRAN.R-project.org/package=lme4">http://CRAN.R-project.org/package=lme4</a>.
</div>
<div id="ref-praat2001" class="csl-entry" role="listitem">
Boersma, Paul. 2001. <span>“Praat.”</span> <em>A System for Doing Phonetics by Computer. <span>Glot</span> <span>International</span></em>, 341–45.
</div>
<div id="ref-bouavichithEtAl2019" class="csl-entry" role="listitem">
Bouavichith, Dominique A., Ian C. Calloway, Justin T. Craft, Tamarae Hildebrandt, Stephen J. Tobin, and Patrice S. Beddor. 2019. <span>“Bidirectional Effects of Priming in Speech Perception: Social-to-Lexical and Lexical-to-Social.”</span> <em>The Journal of the Acoustical Society of America</em> 145. <a href="https://doi.org/10.1121/1.5101933">https://doi.org/10.1121/1.5101933</a>.
</div>
<div id="ref-boydfruehwaldhall-lew_2021" class="csl-entry" role="listitem">
Boyd, Zac, Josef Fruehwald, and Lauren Hall-Lew. 2021. <span>“Crosslinguistic Perceptions of /s/ Among English, French, and German Listeners.”</span> <em>Language Variation and Change</em> 33 (2): 165–91. <a href="https://doi.org/10.1017/S0954394521000089">https://doi.org/10.1017/S0954394521000089</a>.
</div>
<div id="ref-bucholtz2002" class="csl-entry" role="listitem">
Bucholtz, Mary. 2002. <span>“From <span>‘Sex Differences’</span> to Gender Variation in Sociolinguistics.”</span> <em>University of Pennsylvania Working Papers in Linguistics</em> 8 (3): 33–45.
</div>
<div id="ref-bucholtzHall2016" class="csl-entry" role="listitem">
Bucholtz, Mary, and Kira Hall. 2016. <span>“Embodied Sociolinguistics.”</span> <em>Sociolinguistics: Theoretical Debates</em> 1 (1): 173–200.
</div>
<div id="ref-calder2018" class="csl-entry" role="listitem">
Calder, Jeremy. 2018. <span>“From <span>‘Gay Lisp’</span> to <span>‘Fierce Queen’</span>: The Sociophonetics of Sexuality’s Most Iconic Variable.”</span> In <em>The Oxford Handbook of Language and Sexuality</em>, edited by Kira Hall and Rusty Barrett, 1–23.
</div>
<div id="ref-campbell-kibler2005" class="csl-entry" role="listitem">
Campbell-Kibler, Kathryn. 2005. <span>“Listener Perceptions of Sociolinguistic Variables: The Case of (ING).”</span> PhD thesis, Stanford University.
</div>
<div id="ref-campbell-kibler2007" class="csl-entry" role="listitem">
———. 2007. <span>“Accent,(ING), and the Social Logic of Listener Perceptions.”</span> <em>American Speech</em> 82 (1): 32–64.
</div>
<div id="ref-campbell-kibler2016" class="csl-entry" role="listitem">
———. 2016. <span>“Toward a Cognitively Realistic Model of Meaningful Sociolinguistic Variation.”</span> In <em>Awareness and Control in Sociolinguistic Research</em>, edited by Anna M. Babel, 123–51. Cambridge University Press Cambridge.
</div>
<div id="ref-campbell-kibler2020" class="csl-entry" role="listitem">
———. 2021. <span>“Deliberative Control in Audiovisual Sociolinguistic Perception.”</span> <em>Journal of Sociolinguistics</em> 25 (2): 253–71.
</div>
<div id="ref-campbell-kiblerIssue" class="csl-entry" role="listitem">
———. This issue. <span>“Accentedness Ratings Do Not Predict Sensitivity to Regional Variation in Vowel Quality.”</span> <em>Journal of Sociolinguistics</em> 42 (1).
</div>
<div id="ref-chan2021" class="csl-entry" role="listitem">
Chan, Ka Long Roy. 2021. <span>“Verbal Guise Test: Problems and Solutions.”</span> <em>Academia Letters</em>.
</div>
<div id="ref-clopperPisoni2004" class="csl-entry" role="listitem">
Clopper, Cynthia G, and David B Pisoni. 2004. <span>“Effects of Talker Variability on Perceptual Learning of Dialects.”</span> <em>Language and Speech</em> 47 (3): 207–38.
</div>
<div id="ref-craik_recognition_2015" class="csl-entry" role="listitem">
Craik, Fergus I. M., Nathan S. Rose, and Nigel Gopie. 2015. <span>“Recognition Without Awareness: <span>Encoding</span> and Retrieval Factors.”</span> <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em> 41 (5): 1271–81. <a href="https://doi.org/10.1037/xlm0000137">https://doi.org/10.1037/xlm0000137</a>.
</div>
<div id="ref-cramer2021" class="csl-entry" role="listitem">
Cramer, Jennifer. 2021. <span>“Mental Maps and Perceptual Dialectology.”</span> <em>Language and Linguistics Compass</em> 15 (2): e12405.
</div>
<div id="ref-daniel2007" class="csl-entry" role="listitem">
Daniel, Mauro Miguel, Maria Cecı́lia Lorenzi, Claudia da Costa Leite, and Geraldo Lorenzi-Filho. 2007. <span>“Pharyngeal Dimensions in Healthy Men and Women.”</span> <em>Clinics</em> 62 (1): 5–10.
</div>
<div id="ref-dehaene_towards_2001" class="csl-entry" role="listitem">
Dehaene, S., and L. Naccache. 2001. <span>“Towards a Cognitive Neuroscience of Consciousness: Basic Evidence and a Workspace Framework.”</span> <em>Cognition</em> 79 (1-2): 1–37. <a href="https://doi.org/10.1016/s0010-0277(00)00123-2">https://doi.org/10.1016/s0010-0277(00)00123-2</a>.
</div>
<div id="ref-drager2013" class="csl-entry" role="listitem">
Drager, Katie. 2013. <span>“Experimental Methods in Sociolinguistics.”</span> In <em>Research Methods in Sociolinguistics: A Practical Guide</em>, edited by Janet Holmes and Kirk Hazen, 58–73. Oxford: Wiley Blackwell.
</div>
<div id="ref-eckert2008" class="csl-entry" role="listitem">
Eckert, Penelope. 2008. <span>“Variation and the Indexical Field 1.”</span> <em>Journal of Sociolinguistics</em> 12 (4): 453–76.
</div>
<div id="ref-eckert2012" class="csl-entry" role="listitem">
———. 2012. <span>“Three Waves of Variation Study: <span>The</span> Emergence of Meaning in the Study of Sociolinguistic Variation.”</span> <em>Annual Review of Anthropology</em> 41 (1): 87–100.
</div>
<div id="ref-eckertPodesva2021" class="csl-entry" role="listitem">
Eckert, Penelope, and Robert J Podesva. 2021. <span>“Non-Binary Approaches to Gender and Sexuality.”</span> <em>The Routledge Handbook of Language, Gender, and Sexuality</em>, 25–36.
</div>
<div id="ref-evans2008" class="csl-entry" role="listitem">
Evans, Jonathan St BT. 2008. <span>“Dual-Processing Accounts of Reasoning, Judgment, and Social Cognition.”</span> <em>Annu. Rev. Psychol.</em> 59: 255–78.
</div>
<div id="ref-fant1960" class="csl-entry" role="listitem">
Fant, G. 1960. <em>Acoustic Theory of Speech Production</em>. The Hague, The Netherlands: Mouton.
</div>
<div id="ref-foulkesDocherty2006" class="csl-entry" role="listitem">
Foulkes, Paul, and Gerard Docherty. 2006. <span>“The Social Life of Phonetics and Phonology.”</span> <em>Journal of Phonetics</em> 34: 409–38.
</div>
<div id="ref-Fowler1986" class="csl-entry" role="listitem">
Fowler, C. A. 1986. <span>“An Event Approach to the Study of Speech Perception from a Direct— Realist Perspective.”</span> <em>Journal of Phonetics</em> 14: 3–28.
</div>
<div id="ref-gaskell2002representation" class="csl-entry" role="listitem">
Gaskell, M Gareth, and William D Marslen-Wilson. 2002. <span>“Representation and Competition in the Perception of Spoken Words.”</span> <em>Cognitive Psychology</em> 45 (2): 220–66.
</div>
<div id="ref-giles1970" class="csl-entry" role="listitem">
Giles, Howard. 1970. <span>“Evaluative Reactions to Accents.”</span> <em>Educational Review</em> 22 (3): 211–27.
</div>
<div id="ref-gnevsheva2017" class="csl-entry" role="listitem">
Gnevsheva, Ksenia. 2017. <span>“Within-Speaker Variation in Passing for a Native Speaker.”</span> <em>International Journal of Bilingualism</em> 21 (2): 213–27.
</div>
<div id="ref-Goldinger1998" class="csl-entry" role="listitem">
Goldinger, Stephen D. 1998. <span>“Echoes of Echoes? An Episodic Theory of Lexical Access.”</span> <em>Psychological Review</em> 105 (2): 251–79.
</div>
<div id="ref-graziano_attention_2015" class="csl-entry" role="listitem">
Graziano, Michael S. A., and Taylor W. Webb. 2015. <span>“The Attention Schema Theory: A Mechanistic Account of Subjective Awareness.”</span> <em>Frontiers in Psychology</em> 6 (April): 500. <a href="https://doi.org/10.3389/fpsyg.2015.00500">https://doi.org/10.3389/fpsyg.2015.00500</a>.
</div>
<div id="ref-GreenEtAl1991" class="csl-entry" role="listitem">
Green, Kerry, Patricia Kuhl, Andrew Meltzoff, and Erica Stevens. 1991b. <span>“Integrating Speech Information Across Talkers, Gender, and Sensory Modality: Female Faces and Male Voices in the McGurk Effect.”</span> <em>Attention, Perception, &amp; Psychophysics</em> 50: 524–36. <a href="http://dx.doi.org/10.3758/BF03207536">http://dx.doi.org/10.3758/BF03207536</a>.
</div>
<div id="ref-greenKuhlMeltzoffStevens1991" class="csl-entry" role="listitem">
———. 1991a. <span>“Integrating Speech Information Across Talkers, Gender, and Sensory Modality: <span>Female</span> Faces and Male Voices in the <span>McGurk</span> Effect.”</span> <em>Attention, Perception, &amp; Psychophysics</em> 50 (6): 524–36. <a href="http://dx.doi.org/10.3758/BF03207536">http://dx.doi.org/10.3758/BF03207536</a>.
</div>
<div id="ref-hadodoIssue" class="csl-entry" role="listitem">
Hadodo, Matthew. this issue. <span>“Situating Experience in Social Meaning: Ethnography, Experiments and Exemplars in the Enregisterment of Istanbul Greek.”</span> <em>Journal of Sociolinguistics</em> 42 (1).
</div>
<div id="ref-hall2021language" class="csl-entry" role="listitem">
Hall, Kira, Rodrigo Borba, and Mie Hiramoto. 2021. <span>“Language and Gender.”</span> <em>The International Encyclopedia of Linguistic Anthropology</em>, 892–912.
</div>
<div id="ref-HayDrager2010" class="csl-entry" role="listitem">
Hay, J., and K. Drager. 2010. <span>“Stuffed Toys and Speech Perception.”</span> <em>Linguistics</em> 48 (4): 865–92.
</div>
<div id="ref-haynolandrager2006" class="csl-entry" role="listitem">
Hay, J., A. Nolan, and K. Drager. 2006. <span>“From Fush to Feesh: Exemplar Priming in Speech Perception.”</span> <em>The Linguistic Review</em> 23 (3): 351–79.
</div>
<div id="ref-johnson2005" class="csl-entry" role="listitem">
Johnson, Keith. 2005. <span>“Speaker Normalization in Speech Perception.”</span> In <em>The Handbook of Speech Perception</em>, edited by D. B. Pisoni and R. Remez, 363–89.
</div>
<div id="ref-Johnson2006" class="csl-entry" role="listitem">
———. 2006. <span>“<span class="nocase">Resonance in an exemplar-based lexicon: The emergence of social identity and phonology.</span>”</span> <em>Journal of Phonetics</em> 34: 485–99.
</div>
<div id="ref-johnsonstranddimperio1999" class="csl-entry" role="listitem">
Johnson, Keith, Elizabeth A Strand, and Mariapaola D’Imperio. 1999. <span>“Auditory–Visual Integration of Talker Gender in Vowel Perception.”</span> <em>Journal of Phonetics</em> 27 (4): 359–84.
</div>
<div id="ref-Joos1948" class="csl-entry" role="listitem">
Joos, Martin. 1948. <span>“Acoustic Phonetics.”</span> <em>Language</em> 24 (2): 5–136. <a href="http://www.jstor.org/stable/522229">http://www.jstor.org/stable/522229</a>.
</div>
<div id="ref-kang2013" class="csl-entry" role="listitem">
Käng, Dredge Byung’chu. 2013. <span>“Conceptualizing Thai Genderscapes: Transformation and Continuity in the Thai Sex/Gender System.”</span> In <em>Contemporary Socio-Cultural and Political Perspectives in Thailand</em>, 409–29. Springer.
</div>
<div id="ref-king2021" class="csl-entry" role="listitem">
King, Edward Thomas. 2021. <span>“Speaker and Group Specificity in Spoken Word Recognition.”</span> PhD thesis, Stanford, CA: Stanford University.
</div>
<div id="ref-kristiansen2009" class="csl-entry" role="listitem">
Kristiansen, Tore. 2009. <span>“The Macro-Level Social Meanings of Late-Modern Danish Accents.”</span> <em>Acta Linguistica Hafniensia</em> 41 (1): 167–92.
</div>
<div id="ref-kunisakifujisaki1977" class="csl-entry" role="listitem">
Kunisaki, Osamu, and Hyroya Fujisaki. 1977. <span>“On the Influence of Context Upon Perception of Voiceless Fricative Consonants.”</span> <em>Annual Bulletin</em> 11: 85–91.
</div>
<div id="ref-labovEtAl2011" class="csl-entry" role="listitem">
Labov, William, Sharon Ash, Maya Ravindranath, Tracey Weldon, Maciej Baranowski, and Naomi Nagy. 2011. <span>“Properties of the Sociolinguistic Monitor.”</span> <em>Journal of Sociolinguistics</em> 15 (4): 431–63.
</div>
<div id="ref-lambertEtAl1960" class="csl-entry" role="listitem">
Lambert, Wallace E, Richard C Hodgson, Robert C Gardner, and Samuel Fillenbaum. 1960. <span>“Evaluational Reactions to Spoken Languages.”</span> <em>The Journal of Abnormal and Social Psychology</em> 60 (1): 44.
</div>
<div id="ref-JATOS" class="csl-entry" role="listitem">
Lange, Kristian, Simone Kuhn, and Elisa Filevich. 2015. <span>“"Just Another Tool for Online Studies” (JATOS): An Easy Solution for Setup and Management of Web Servers Supporting Online Studies.”</span> <em>PLOS ONE</em> 10 (6): 1–14. <a href="https://doi.org/10.1371/journal.pone.0130834">https://doi.org/10.1371/journal.pone.0130834</a>.
</div>
<div id="ref-laver1968" class="csl-entry" role="listitem">
Laver, John D. M. 1968. <span>“Voice Quality and Indexical Information.”</span> <em>British Journal of Disorders of Communication</em> 3 (1): 43–54. <a href="https://doi.org/10.3109/13682826809011440">https://doi.org/10.3109/13682826809011440</a>.
</div>
<div id="ref-levonFox2014" class="csl-entry" role="listitem">
Levon, E., and S. Fox. 2014. <span>“Social Salience and the Sociolinguistic Monitor: <span>A</span> Case Study of <span>ING</span> and <span>TH</span>-Fronting in Britain.”</span> <em>Journal of English Linguistics</em> 42 (3): 185–217. <a href="https://doi.org/10.1177/0075424214531487">https://doi.org/10.1177/0075424214531487</a>.
</div>
<div id="ref-lisker1986" class="csl-entry" role="listitem">
Lisker, Leigh. 1986. <span>“<span>‘Voicing’</span> in English: A Catalogue of Acoustic Features Signaling/b/Versus/p/in Trochees.”</span> <em>Language and Speech</em> 29 (1): 3–11.
</div>
<div id="ref-imagemagick" class="csl-entry" role="listitem">
LLC, ImageMagick Studio. 2023. <span>“ImageMagick.”</span> <a href="https://imagemagick.org">https://imagemagick.org</a>.
</div>
<div id="ref-ChicagoFaceDatabase" class="csl-entry" role="listitem">
Ma, D. S., J. Correll, and B. Wittenbrink. 2015. <span>“The Chicago Face Database: A Free Stimulus Set of Faces and Norming Data.”</span> <em>Behavior Research Methods</em> 47 (4): 1122–35. <a href="https://doi.org/10.3758/s13428-014-0532-5">https://doi.org/10.3758/s13428-014-0532-5</a>.
</div>
<div id="ref-mackMunson2012b" class="csl-entry" role="listitem">
Mack, Sara, and Benjamin Munson. 2012a. <span>“The Association Between/s/Quality and Perceived Sexual Orientation of Men’s Voices: Implicit and Explicit Measures.”</span> <em>Journal of Phonetics</em> 40 (1): 198–212.
</div>
<div id="ref-mackmunson2012" class="csl-entry" role="listitem">
———. 2012b. <span>“The Influence of /s/ Quality on Ratings of Men’s Sexual Orientation: Explicit and Implicit Measures of the <span>‘Gay Lisp’</span> Stereotype.”</span> <em>Journal of Phonetics</em> 40 (1): 198–212. https://doi.org/<a href="https://doi.org/10.1016/j.wocn.2011.10.002">https://doi.org/10.1016/j.wocn.2011.10.002</a>.
</div>
<div id="ref-MannRepp1980" class="csl-entry" role="listitem">
Mann, Virginia A, and Bruno H Repp. 1980. <span>“Influence of Vocalic Context on Perception of the [∫]-[s] Distinction.”</span> <em>Perception &amp; Psychophysics</em> 28 (3): 213–28.
</div>
<div id="ref-opensesame" class="csl-entry" role="listitem">
Mathôt, S., D. Schreij, and J. Theeuwes. 2012. <span>“Opensesame: An Open-Source, Graphical Experiment Builder for the Social Sciences.”</span> <em>Behavior Research Methods</em> 44 (2): 314–24.
</div>
<div id="ref-may1976" class="csl-entry" role="listitem">
May, Janet. 1976. <span>“Vocal Tract Normalization for /s/ and /š/.”</span> <em>Haskins Laboratories Status Report on Speech Research</em>, no. SR-48: 67–73.
</div>
<div id="ref-McGowan2011" class="csl-entry" role="listitem">
McGowan, Kevin B. 2011. <span>“The Role of Socioindexical Expectation in Speech Perception.”</span> PhD thesis, Ann Arbor, MI: University of Michigan.
</div>
<div id="ref-McGowan2015" class="csl-entry" role="listitem">
———. 2015. <span>“Social Expectation Improves Speech Perception in Noise.”</span> <em>Language and Speech</em> 58 (4): 502–21.
</div>
<div id="ref-mcgowan2016" class="csl-entry" role="listitem">
———. 2016. <span>“Sounding Chinese and Listening Chinese: Awareness and Knowledge in the Laboratory.”</span> In <em>Awareness and Control in Sociolinguistic Research</em>, edited by Anna M. Babel, 25–61. Cambridge University Press Cambridge.
</div>
<div id="ref-mcgowanBabel2020" class="csl-entry" role="listitem">
McGowan, Kevin B., and Anna M. Babel. 2020. <span>“Perceiving Isn’t Believing: Divergence in Levels of Sociolinguistic Awareness.”</span> <em>Language in Society</em> 49 (2): 231–56.
</div>
<div id="ref-McGurkMacDonald1976" class="csl-entry" role="listitem">
McGurk, Harry, and John MacDonald. 1976. <span>“Hearing Lips and Seeing Voices.”</span> <em>Nature</em> 264: 746–48.
</div>
<div id="ref-milroyMcClenaghan1977" class="csl-entry" role="listitem">
Milroy, Lesley, and Paul McClenaghan. 1977. <span>“Stereotyped Reactions to Four Educated Accents in Ulster.”</span> <em>Belfast Working Papers in Language and Linguistics</em> 2 (4): 1–11.
</div>
<div id="ref-munson2011" class="csl-entry" role="listitem">
Munson, Benjamin. 2011. <span>“The Influence of Actual and Imputed Talker Gender on Fricative Perception, Revisited (l).”</span> <em>The Journal of the Acoustical Society of America</em> 130 (5): 2631–34.
</div>
<div id="ref-Niedzielski1999" class="csl-entry" role="listitem">
Niedzielski, Nancy. 1999. <span>“The Effect of Social Information on the Perception of Sociolinguistic Variables.”</span> <em>Journal of Language and Social Psychology</em> 18 (1): 62–85.
</div>
<div id="ref-niedzielskiPreston2000" class="csl-entry" role="listitem">
Niedzielski, Nancy, and Dennis Richard Preston. 2000. <em>Folk Linguistics</em>. Vol. 122. Walter de Gruyter.
</div>
<div id="ref-nygaard1994" class="csl-entry" role="listitem">
Nygaard, Lynne C, Mitchell S Sommers, and David B Pisoni. 1994. <span>“Speech Perception as a Talker-Contingent Process.”</span> <em>Psychological Science</em> 5 (1): 42–46.
</div>
<div id="ref-ohala1984" class="csl-entry" role="listitem">
Ohala, John J. 1984. <span>“An Ethological Perspective on Common Cross-Language Utilization of F₀ of Voice.”</span> <em>Phonetica</em> 41 (1): 1–16.
</div>
<div id="ref-ohala1994" class="csl-entry" role="listitem">
———. 1994. <span>“The Frequency Code Underlies the Sound-Symbolic Use of Voice Pitch.”</span> <em>Sound Symbolism</em>, 325–47.
</div>
<div id="ref-perryOhdeAshmead2001" class="csl-entry" role="listitem">
Perry, Theodore L, Ralph N Ohde, and Daniel H Ashmead. 2001. <span>“The Acoustic Bases for Gender Identification from Children’s Voices.”</span> <em>The Journal of the Acoustical Society of America</em> 109 (6): 2988–98.
</div>
<div id="ref-pharaoKristiansen2019" class="csl-entry" role="listitem">
Pharao, Nicolai, and Tore Kristiansen. 2019. <span>“Reflections on the Relation Between Direct/Indirect Methods and Explicit/Implicit Attitudes.”</span> <em>Linguistics Vanguard</em> 5 (s1).
</div>
<div id="ref-pierrehumbert2003phonetic" class="csl-entry" role="listitem">
Pierrehumbert, Janet B. 2003. <span>“Phonetic Diversity, Statistical Learning, and Acquisition of Phonology.”</span> <em>Language and Speech</em> 46 (2-3): 115–54.
</div>
<div id="ref-podesvaKajino2014" class="csl-entry" role="listitem">
Podesva, Robert J, and Sakiko Kajino. 2014. <span>“Sociophonetics, Gender, and Sexuality.”</span> <em>The Handbook of Language, Gender, and Sexuality</em>, 103–22.
</div>
<div id="ref-preston1996" class="csl-entry" role="listitem">
Preston, Dennis R. 1996. <span>“Whaddayaknow?: The Modes of Folk Linguistic Awareness.”</span> <em>Language Awareness</em> 5 (1): 40–74.
</div>
<div id="ref-preston2016" class="csl-entry" role="listitem">
———. 2016. <span>“Whaddayaknow Now.”</span> <em>Awareness and Control in Sociolinguistic Research</em>, 177–99.
</div>
<div id="ref-prinz_unconscious_2015" class="csl-entry" role="listitem">
Prinz, Jesse J. 2015. <span>“Unconscious Perception.”</span> In <em>The <span>Oxford</span> Handbook of Philosophy of Perception</em>, 371–89. New York, NY, US: Oxford University Press. <a href="https://doi.org/10.1093/oxfordhb/9780199600472.001.0001">https://doi.org/10.1093/oxfordhb/9780199600472.001.0001</a>.
</div>
<div id="ref-repp1982" class="csl-entry" role="listitem">
Repp, Bruno H. 1982. <span>“Phonetic Trading Relations and Context Effects: New Experimental Evidence for a Speech Mode of Perception.”</span> <em>Psychological Bulletin</em> 92 (1): 81.
</div>
<div id="ref-rosseelGrondelaers2019" class="csl-entry" role="listitem">
Rosseel, Laura, and Stefan Grondelaers. 2019. <span>“Implicitness and Experimental Methods in Language Variation Research.”</span> <em>Linguistics Vanguard</em> 5 (s1).
</div>
<div id="ref-rubin1992" class="csl-entry" role="listitem">
Rubin, Donald L. 1992. <span>“Nonlanguage Factors Affecting Undergraduates’ Judgments of Nonnative English-Speaking Teaching Assistants.”</span> <em>Research in Higher Education</em> 33 (4): 511–31.
</div>
<div id="ref-samolinski2007" class="csl-entry" role="listitem">
Samoliński, Bolesław K, Antoni Grzanka, and Tomasz Gotlib. 2007. <span>“Changes in Nasal Cavity Dimensions in Children and Adults by Gender and Age.”</span> <em>The Laryngoscope</em> 117 (8): 1429–33.
</div>
<div id="ref-schellingerMunsonEdwards2017" class="csl-entry" role="listitem">
Schellinger, Sarah K, Benjamin Munson, and Jan Edwards. 2017. <span>“Gradient Perception of Children’s Productions of/s/and/<span class="math inline">\(\theta\)</span>: A Comparative Study of Rating Methods.”</span> <em>Clinical Linguistics &amp; Phonetics</em> 31 (1): 80–103.
</div>
<div id="ref-schulman1974" class="csl-entry" role="listitem">
Schulman, Arthur I. 1974. <span>“Memory for Words Recently Classified.”</span> <em>Memory &amp; Cognition</em> 2 (1): 47–52. <a href="https://doi.org/10.3758/BF03197491">https://doi.org/10.3758/BF03197491</a>.
</div>
<div id="ref-shadle1991" class="csl-entry" role="listitem">
Shadle, Christine H. 1991. <span>“The Effect of Geometry on Source Mechanisms of Fricative Consonants.”</span> <em>Journal of Phonetics</em> 19 (3-4): 409–24.
</div>
<div id="ref-steckerDOnofrioIssue" class="csl-entry" role="listitem">
Stecker, Amelia, and Annette D’Onofrio. This issue. <span>“Recognizing Uptalk: Memory and Metalinguistic Commentary for a Sociolinguistic Feature.”</span> <em>Journal of Sociolinguistics</em> 42 (1).
</div>
<div id="ref-strand1999" class="csl-entry" role="listitem">
Strand, Elizabeth A. 1999. <span>“Uncovering the Role of Gender Stereotypes in Speech Perception.”</span> <em>Journal of Language and Social Psychology</em> 18 (1): 86–100.
</div>
<div id="ref-strandJohnson1996" class="csl-entry" role="listitem">
Strand, Elizabeth A, and Keith Johnson. 1996. <span>“Gradient and Visual Speaker Normalization in the Perception of Fricatives.”</span> In <em>KONVENS</em>, 14–26.
</div>
<div id="ref-sumner2014" class="csl-entry" role="listitem">
Sumner, Meghan, Seung Kyung Kim, Ed King, and Kevin B. McGowan. 2014. <span>“The Socially Weighted Encoding of Spoken Words: A Dual-Route Approach to Speech Perception.”</span> <em>Frontiers in Psychology</em> 4: 1015.
</div>
<div id="ref-trippMunson2022" class="csl-entry" role="listitem">
Tripp, Alayo, and Benjamin Munson. 2022. <span>“Perceiving Gender While Perceiving Language: Integrating Psycholinguistics and Gender Theory.”</span> <em>Wiley Interdisciplinary Reviews: Cognitive Science</em> 13 (2): e1583.
</div>
<div id="ref-walkerHay2011" class="csl-entry" role="listitem">
Walker, Abby, and Jen Hay. 2011. <span>“Congruence Between ‘Word Age’and ‘Voice Age’facilitates Lexical Access.”</span> <em>Laboratory Phonology</em> 2 (1).
</div>
<div id="ref-whalen1981" class="csl-entry" role="listitem">
Whalen, Douglas H. 1981. <span>“Effects of Vocalic Formant Transitions and Vowel Quality on the English [s]–[<span>š</span>] Boundary.”</span> <em>The Journal of the Acoustical Society of America</em> 69 (1): 275–82.
</div>
<div id="ref-whalen1984" class="csl-entry" role="listitem">
———. 1984. <span>“Subcategorical Phonetic Mismatches Slow Phonetic Judgments.”</span> <em>Perception &amp; <span>Psychophysics</span></em> 35: 49–64.
</div>
<div id="ref-whalen1991" class="csl-entry" role="listitem">
———. 1991. <span>“Perception of the English/s/–//Distinction Relies on Fricative Noises and Transitions, Not on Brief Spectral Slices.”</span> <em>The Journal of the Acoustical Society of America</em> 90 (4): 1776–85.
</div>
<div id="ref-wilbanks2022" class="csl-entry" role="listitem">
Wilbanks, Eric. 2022. <span>“The Integration of Social and Acoustic Cues During Speech Perception.”</span> PhD thesis, University of California, Berkeley.
</div>
<div id="ref-wright2023" class="csl-entry" role="listitem">
Wright, Kelly Elizabeth. 2023. <span>“Housing Policy and Linguistic Profiling: An Audit Study of Three American Dialects.”</span> <em>Language</em>.
</div>
<div id="ref-zimman2017" class="csl-entry" role="listitem">
Zimman, Lal. 2017. <span>“Gender as Stylistic Bricolage: Transmasculine Voices and the Relationship Between Fundamental Frequency and/s.”</span> <em>Language in Society</em> 46 (3): 339–70.
</div>
<div id="ref-zimman2018" class="csl-entry" role="listitem">
———. 2018. <span>“Transgender Voices: Insights on Identity, Embodiment, and the Gender of the Voice.”</span> <em>Language and Linguistics Compass</em> 12 (8): e12284.
</div>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Although, in their response, <span class="citation" data-cites="levonFox2014">(<a href="#ref-levonFox2014" role="doc-biblioref">Levon and Fox 2014</a>)</span> are careful to refer exclusively to <em>evaluation</em> rather than perception.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>We are choosing the words ‘congruous’ and ‘incongruous’ <span class="citation" data-cites="schulman1974">(<a href="#ref-schulman1974" role="doc-biblioref">Schulman 1974</a>)</span> intentionally to suggest faces and voices may pattern together in particular ways in listeners’ experience and perception with no implied claim that voices may ‘match’ or ‘mismatch’ in some way that suggests either experimenters or participants have veridical access to an objective reality.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{laycock2024,
  author = {Laycock, Kyler and B McGowan, \&nbsp;Kevin},
  title = {Removing the Disguise: The Matched Guise Technique and
    Listener Awareness},
  date = {2024-10-26},
  langid = {en},
  abstract = {Sociophonetic perception is often studied using versions
    of the matched guise technique. Linguists using this technique
    appear united in the methodological assumptions that participants
    believe the manipulation and that this belief influences perception
    below the level of introspective awareness. We report an audiovisual
    matched guise experiment with a novel “unhidden” instruction
    condition. The basic task is a replication of the Strand effect
    {[}@strandJohnson1996; @strand1999{]}. Participants in the
    “unhidden” condition were instructed that the man or woman in the
    photo did not represent the voice they were listening to.
    Participants in both guises exhibited the Strand effect to nearly
    numerically identical extents. This result suggests that
    participants need not believe a link exists between a voice and a
    purported social category for visually-cued social information to
    influence segmental perception. We explore the implications of this
    result for the MGT and for theories of social awareness and speech
    perception more broadly.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-laycock2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Laycock, Kyler, and &amp;nbsp;Kevin B McGowan. 2024. <span>“Removing the
Disguise: The Matched Guise Technique and Listener Awareness.”</span>
Awareness and Control of Sociolinguistic Variation. October 26, 2024.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>