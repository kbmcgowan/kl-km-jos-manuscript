<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kyler Laycock">
<meta name="author" content="Kevin B McGowan">
<meta name="dcterms.date" content="2024-05-23">
<meta name="description" content="REMOVING THE DISGUISE: THE MATCHED GUISE TECHNIQUE AND LISTENER AWARENESS">

<title>Removing the disguise: the matched guise technique and listener awareness</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/critic/critic.min.js"></script>
<link href="site_libs/quarto-contrib/critic/critic.css" rel="stylesheet">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="_extensions/wjschne/apaquarto/apa.css">
<meta name="citation_title" content="Removing the disguise: the matched guise technique and listener awareness">
<meta name="citation_abstract" content="Sociophonetic perception is often studied using versions of the matched guise technique. Linguists using this technique appear united in the methodological assumptions that participants believe the manipulation and that this belief influences perception below the level of introspective awareness. We report an audiovisual matched guise experiment with a novel &amp;amp;#039;unhidden' instruction condition. The basic task is a replication of the Strand effect [@strandJohnson1996; @strand1999]. Participants in the 'unhidden' condition were instructed that the man or woman in the photo did not represent the voice they were listening to. Participants in both guises exhibited the Strand effect to nearly numerically identical extents. This result suggests that participants need not believe a link exists between a voice and a purported social category for visually-cued social information to influence segmental perception. We explore the implications of this result for the MGT and for theories of social awareness and speech perception more broadly.
">
<meta name="citation_keywords" content="">
<meta name="citation_author" content="Kyler Laycock">
<meta name="citation_author" content="Kevin B McGowan">
<meta name="citation_publication_date" content="2024-05-23">
<meta name="citation_cover_date" content="2024-05-23">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-05-23">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Awareness and Control of Sociolinguistic Variation">
<meta name="citation_reference" content="citation_title=Uncovering the role of gender stereotypes in speech perception;,citation_author=Elizabeth A Strand;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=18;,citation_journal_title=Journal of language and social psychology;,citation_publisher=Sage Publications Sage CA: Thousand Oaks, CA;">
<meta name="citation_reference" content="citation_title=Gradient and visual speaker normalization in the perception of fricatives.;,citation_author=Elizabeth A Strand;,citation_author=Keith Johnson;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=KONVENS;">
<meta name="citation_reference" content="citation_title=Acoustic theory of speech production;,citation_author=G. Fant;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;">
<meta name="citation_reference" content="citation_title=The effect of geometry on source mechanisms of fricative consonants;,citation_author=Christine H Shadle;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=3-4;,citation_volume=19;,citation_journal_title=Journal of Phonetics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Subcategorical phonetic mismatches slow phonetic judgments;,citation_author=Douglas H Whalen;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_volume=35;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Vocal tract normalization for /s/ and /š/;,citation_author=Janet May;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=SR-48;,citation_journal_title=Haskins Laboratories Status Report on Speech Research;">
<meta name="citation_reference" content="citation_title=The influence of actual and imputed talker gender on fricative perception, revisited (l);,citation_author=Benjamin Munson;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=5;,citation_volume=130;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Influence of vocalic context on perception of the [ʃ]-[s] distinction;,citation_author=Virginia A Mann;,citation_author=Bruno H Repp;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=3;,citation_volume=28;,citation_journal_title=Perception &amp;amp;amp; Psychophysics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=An ethological perspective on common cross-language utilization of F₀ of voice;,citation_author=John J Ohala;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=1;,citation_volume=41;,citation_journal_title=Phonetica;,citation_publisher=S. Karger AG Basel, Switzerland;">
<meta name="citation_reference" content="citation_title=On the influence of context upon perception of voiceless fricative consonants;,citation_author=Osamu Kunisaki;,citation_author=Hyroya Fujisaki;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_volume=11;,citation_journal_title=Annual Bulletin;,citation_publisher=Research Institute of Logopedics; Phoniatrics Tokyo;">
<meta name="citation_reference" content="citation_title=Effects of vocalic formant transitions and vowel quality on the english [s]–[š] boundary;,citation_author=Douglas H Whalen;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=1;,citation_volume=69;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=The time course of perception of coarticulation;,citation_author=Patrice Speeter Beddor;,citation_author=Kevin B McGowan;,citation_author=Julie E Boland;,citation_author=Andries W Coetzee;,citation_author=Anthony Brasher;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=133;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=The time course of individuals’ perception of coarticulatory information is linked to their production: Implications for sound change;,citation_author=Patrice Speeter Beddor;,citation_author=Andries W Coetzee;,citation_author=Will Styler;,citation_author=Kevin B McGowan;,citation_author=Julie E Boland;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=94;,citation_journal_title=Language;,citation_publisher=Linguistic Society of America;">
<meta name="citation_reference" content="citation_title=Hearing lips and seeing voices;,citation_author=Harry McGurk;,citation_author=John MacDonald;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_volume=264;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Perception of the english/s/–//distinction relies on fricative noises and transitions, not on brief spectral slices;,citation_author=Douglas H Whalen;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=4;,citation_volume=90;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Sociophonetics, gender, and sexuality;,citation_author=Robert J Podesva;,citation_author=Sakiko Kajino;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=The handbook of language, gender, and sexuality;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The association between/s/quality and perceived sexual orientation of men’s voices: Implicit and explicit measures;,citation_author=Sara Mack;,citation_author=Benjamin Munson;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=40;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=From “gay lisp” to “fierce queen”: The sociophonetics of sexuality’s most iconic variable;,citation_author=Jeremy Calder;,citation_editor=Kira Hall;,citation_editor=Rusty Barrett;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_inbook_title=The oxford handbook of language and sexuality;">
<meta name="citation_reference" content="citation_title=Pharyngeal dimensions in healthy men and women;,citation_author=Mauro Miguel Daniel;,citation_author=Maria Cecı́lia Lorenzi;,citation_author=Claudia Costa Leite;,citation_author=Geraldo Lorenzi-Filho;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=62;,citation_journal_title=Clinics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Changes in nasal cavity dimensions in children and adults by gender and age;,citation_author=Bolesław K Samoliński;,citation_author=Antoni Grzanka;,citation_author=Tomasz Gotlib;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=8;,citation_volume=117;,citation_journal_title=The Laryngoscope;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The acoustic bases for gender identification from children’s voices;,citation_author=Theodore L Perry;,citation_author=Ralph N Ohde;,citation_author=Daniel H Ashmead;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=6;,citation_volume=109;,citation_journal_title=The Journal of the Acoustical Society of America;,citation_publisher=Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Gradient perception of children’s productions of/s/and/$\theta$: A comparative study of rating methods;,citation_author=Sarah K Schellinger;,citation_author=Benjamin Munson;,citation_author=Jan Edwards;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=31;,citation_journal_title=Clinical Linguistics &amp;amp;amp; Phonetics;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Non-binary approaches to gender and sexuality;,citation_author=Penelope Eckert;,citation_author=Robert J Podesva;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The Routledge handbook of language, gender, and sexuality;,citation_publisher=Routledge;">
<meta name="citation_reference" content="citation_title=Speaker normalization in speech perception;,citation_author=K. Johnson;,citation_editor=D. B. Pisoni;,citation_editor=R. Remez;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_inbook_title=The handbook of speech perception;">
<meta name="citation_reference" content="citation_title=Resonance in an exemplar-based lexicon: The emergence of social identity and phonology.;,citation_author=Keith Johnson;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=34;,citation_journal_title=Journal of Phonetics;">
<meta name="citation_reference" content="citation_title=Variation and the indexical field 1;,citation_author=Penelope Eckert;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=4;,citation_volume=12;,citation_journal_title=Journal of sociolinguistics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Conceptualizing thai genderscapes: Transformation and continuity in the thai sex/gender system;,citation_author=Dredge Byung’chu Käng;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Contemporary socio-cultural and political perspectives in thailand;">
<meta name="citation_reference" content="citation_title=Language, gender, and ideology in japanese professional matchmaking.;,citation_author=Erika Renée Alpert;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_dissertation_institution=University of Michigan, Department of Anthropology;">
<meta name="citation_reference" content="citation_title=Crosslinguistic perceptions of /s/ among english, french, and german listeners;,citation_author=Zac Boyd;,citation_author=Josef Fruehwald;,citation_author=Lauren Hall-Lew;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_doi=10.1017/S0954394521000089;,citation_volume=33;,citation_journal_title=Language Variation and Change;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Listener perceptions of sociolinguistic variables: The case of (ING);,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=Accent,(ING), and the social logic of listener perceptions;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=1;,citation_volume=82;,citation_journal_title=American speech;,citation_publisher=Duke University Press;">
<meta name="citation_reference" content="citation_title=Gender as stylistic bricolage: Transmasculine voices and the relationship between fundamental frequency and/s;,citation_author=Lal Zimman;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=3;,citation_volume=46;,citation_journal_title=Language in Society;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Situating experience in social meaning: Ethnography, experiments and exemplars in the enregisterment of istanbul greek;,citation_author=Matthew Hadodo;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Verbal guise test: Problems and solutions;,citation_author=Ka Long Roy CHAN;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=Academia Letters;">
<meta name="citation_reference" content="citation_title=Evaluational reactions to spoken languages.;,citation_author=Wallace E Lambert;,citation_author=Richard C Hodgson;,citation_author=Robert C Gardner;,citation_author=Samuel Fillenbaum;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_issue=1;,citation_volume=60;,citation_journal_title=The journal of abnormal and social psychology;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=Nonlanguage factors affecting undergraduates’ judgments of nonnative english-speaking teaching assistants;,citation_author=Donald L Rubin;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_volume=33;,citation_journal_title=Research in Higher Education;">
<meta name="citation_reference" content="citation_title=Social expectation improves speech perception in noise;,citation_author=Kevin B McGowan;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=58;,citation_journal_title=Language and Speech;,citation_publisher=Sage Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=Toward a cognitively realistic model of meaningful sociolinguistic variation;,citation_author=Kathryn Campbell-Kibler;,citation_editor=Anna Babel;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_inbook_title=Awareness and control in sociolinguistic research;">
<meta name="citation_reference" content="citation_title=Within-speaker variation in passing for a native speaker;,citation_author=Ksenia Gnevsheva;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_volume=21;,citation_journal_title=International Journal of Bilingualism;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=Experimental methods in sociolinguistics;,citation_author=Katie Drager;,citation_editor=Janet Holmes;,citation_editor=Kirk Hazen;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Research methods in sociolinguistics: A practical guide;">
<meta name="citation_reference" content="citation_title=Implicitness and experimental methods in language variation research;,citation_author=Laura Rosseel;,citation_author=Stefan Grondelaers;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=s1;,citation_volume=5;,citation_journal_title=Linguistics Vanguard;,citation_publisher=De Gruyter Mouton;">
<meta name="citation_reference" content="citation_title=Reflections on the relation between direct/indirect methods and explicit/implicit attitudes;,citation_author=Nicolai Pharao;,citation_author=Tore Kristiansen;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=s1;,citation_volume=5;,citation_journal_title=Linguistics Vanguard;,citation_publisher=De Gruyter Mouton;">
<meta name="citation_reference" content="citation_title=How “deep” is dynamism? Revisiting the evaluation of moroccan-flavored netherlandic dutch;,citation_author=Stefan Grondelaers;,citation_author=Paul Gent;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=s1;,citation_volume=5;,citation_journal_title=Linguistics Vanguard;,citation_publisher=De Gruyter Mouton;">
<meta name="citation_reference" content="citation_title=Perceiving isn’t believing: Divergence in levels of sociolinguistic awareness;,citation_author=Kevin B McGowan;,citation_author=Anna M Babel;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_volume=49;,citation_journal_title=Language in Society;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=A semiotic approach to awareness and control;,citation_author=Anna Babel;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Perceiving gender while perceiving language: Integrating psycholinguistics and gender theory;,citation_author=Alayo Tripp;,citation_author=Benjamin Munson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=2;,citation_volume=13;,citation_journal_title=Wiley Interdisciplinary Reviews: Cognitive Science;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Recognizing uptalk: Memory and metalinguistic commentary for a sociolinguistic feature;,citation_author=Amelia Stecker;,citation_author=Annette D’Onofrio;,citation_issue=1;,citation_volume=42;,citation_journal_title=Journal of Sociolinguistics;">
<meta name="citation_reference" content="citation_title=Bidirectional effects of priming in speech perception: Social-to-lexical and lexical-to-social;,citation_author=Dominique A. Bouavichith;,citation_author=Ian C. Calloway;,citation_author=Justin T. Craft;,citation_author=Tamarae Hildebrandt;,citation_author=Stephen J. Tobin;,citation_author=Patrice S. Beddor;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1121/1.5101933;,citation_volume=145;,citation_journal_title=The Journal of the Acoustical Society of America;">
<meta name="citation_reference" content="citation_title=Deliberative control in audiovisual sociolinguistic perception;,citation_author=Kathryn Campbell-Kibler;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_volume=25;,citation_journal_title=Journal of Sociolinguistics;,citation_publisher=Wiley Online Library;">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro">Introduction</a>
  <ul class="collapse">
  <li><a href="#coarticulatory-and-social-information-influence-ʃ-s-perception" id="toc-coarticulatory-and-social-information-influence-ʃ-s-perception" class="nav-link" data-scroll-target="#coarticulatory-and-social-information-influence-ʃ-s-perception">Coarticulatory and Social Information Influence [ʃ]-[s] perception</a></li>
  <li><a href="#phonetics-speech-perception-and-the-social-construction-of-gender" id="toc-phonetics-speech-perception-and-the-social-construction-of-gender" class="nav-link" data-scroll-target="#phonetics-speech-perception-and-the-social-construction-of-gender">Phonetics, Speech Perception, and the Social-Construction of Gender</a></li>
  <li><a href="#sub-mgt" id="toc-sub-mgt" class="nav-link" data-scroll-target="#sub-mgt">Matched Guise</a></li>
  </ul></li>
  <li><a href="#method" id="toc-method" class="nav-link" data-scroll-target="#method">Method</a>
  <ul class="collapse">
  <li><a href="#participants" id="toc-participants" class="nav-link" data-scroll-target="#participants">Participants</a></li>
  <li><a href="#stimulus-materials" id="toc-stimulus-materials" class="nav-link" data-scroll-target="#stimulus-materials">Stimulus Materials</a>
  <ul class="collapse">
  <li><a href="#auditory-stimuli" id="toc-auditory-stimuli" class="nav-link" data-scroll-target="#auditory-stimuli">Auditory Stimuli</a></li>
  </ul></li>
  <li><a href="#sec-data-methods" id="toc-sec-data-methods" class="nav-link" data-scroll-target="#sec-data-methods">Data &amp; Methods</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word (apaquarto)</a></li></ul></div><div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="notebooks/explore-earthquakes.embed-preview.html"><i class="bi bi-journal-code"></i>Explore Earthquakes</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<br>

<br>

<section id="title" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">Removing the disguise: the matched guise technique and listener awareness</h1>
<div class="Author">
<br>

<p>Kyler Laycock<sup>1</sup> andKevin B McGowan<sup>2</sup></p>
<p><sup>1</sup>The Ohio State University</p>
<p><sup>2</sup>The University of Kentucky</p>
</div>
</section>
<section id="author-note" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Author Note</h1>
</section>
<section id="abstract" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Abstract</h1>
<p><em>Keywords</em>:</p>
</section>
<section id="firstheader" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">Removing the disguise: the matched guise technique and listener awareness</h1>
</section>
<section id="sec-intro" class="level1">
<h1>Introduction</h1>
<p>A great deal of attention has been paid in the phonetics and sociophonetics literatures to the perception of the voiceless fricatives [ʃ] and [s] in English. To a first approximation, these fricatives differ in the distance between the point of lingual articulation and the teeth, which give them their characteristic sibilance <span class="citation" data-cites="fant1960">Shadle (<a href="#ref-shadle1991" role="doc-biblioref">1991</a>)</span>. English [s] has a short resonating chamber behind the teeth; it is typically produced by holding the tongue blade near enough to the alveolar ridge to cause turbulent airflow. English [ʃ] has a comparatively larger resonating chamber; it is typically produced with a more posterior, palato-alveolar tongue position and lip rounding both of which serve to reinforce this posteriority. But listeners do not perceive via <ins>this type of</ins><span class="critic comment">KM</span> first approximation<ins>; we are sensitive to fine phonetic details far beyond these gross, categorical, differences</ins><span class="critic comment">KM</span>. Indeed, these two fricatives have been exciting to researchers precisely because of the sensitivity listeners bring to their perception and how that perception interacts with both linguistic and social knowledge.</p>
<section id="coarticulatory-and-social-information-influence-ʃ-s-perception" class="level2">
<h2 data-anchor-id="coarticulatory-and-social-information-influence-ʃ-s-perception">Coarticulatory and Social Information Influence [ʃ]-[s] perception</h2>
<p><span class="critic comment">KL: ok, this is the specific section the editors didn’t like I think vis-a-vis “rewriting the introduction to state more strongly why this study is important to sociolinguistics, and not mainly interesting to cognitive linguists”</span> Listeners are sensitive to articulatory mismatches between the fricatives [ʃ]-[s] and neighboring sounds. <span class="citation" data-cites="whalen1984">Whalen (<a href="#ref-whalen1984" role="doc-biblioref">1984</a>)</span> conducted a series of experiments to investigate listeners’ responses to articulatory mismatches in synthetic speech. Overall, the result of these investigations was that subcategorical phonetic mismatches slow phonetic judgments. In onset position, in isolation, or in coda position, misleading coarticulatory information inhibited reaction times. Listeners, Whalen cautions in the conclusion, are sensitive to articulatory patterns that are below the level of conscious awareness and not available to direct experimenter scrutiny. While listeners will readily fill-in missing or ambiguous information, the presence of actively <em>conflicting</em> articulatory information is inhibitory.</p>
<p>A commonly used methodology involves the creation of synthetic fricative continua. These continua have endpoints in prototypical examples of [ʃ] and [s] with some number of equal-sized acoustic steps generated, synthesized, or even mixed between these. Somewhere in the middle of such a continuum will be fricative-like noise that is ambiguous as to category membership: not clearly a [ʃ] and not clearly an [s]. <span class="citation" data-cites="May1976">May (<a href="#ref-May1976" role="doc-biblioref">1976</a>)</span> paired a continuum from [ʃ] (2.9 kHz) to [s] (4.4 kHz) with synthetic [æ] vowels to form CV pairs. May found that listeners perceived a higher proportion of the fricative continuum as [ʃ] when paired with vowel stimuli from a smaller vocal tract. The logic here is that smaller resonating chambers between the lingual articulation and teeth will have a higher mean frequency than larger resonating chambers. Listeners’ use of apparent vocal tract size in perception reflect their knowledge of this variation <span class="citation" data-cites="munson2011">(<a href="#ref-munson2011" role="doc-biblioref">Munson, 2011</a>)</span>.</p>
<p><span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> replicated this finding, extending it to natural productions of vowels spoken by a male or female-identified talker. Similar to May’s results with simulated vocal tract size, Mann &amp; Repp found a higher proportion of the fricative continuum was heard as [ʃ] when paired with the speech of the female talker. This early work, like others of the period <span class="citation" data-cites="ohala1984">(<a href="#ref-ohala1984" role="doc-biblioref">Ohala, 1984</a>)</span>, theorized size as being a relatively deterministic feature of talker sexual dimorphism. One consequence of this view is that gender-related variation in the speech signal is considered mechanistic, universal, and following from purely physical laws. Vocal tract size is presumably not available for individual performance and so listener knowledge of this variation can be correspondingly simple. Vocal tract size may influence perception, but it does so implicitly, automatically, and below the level of introspective awareness.</p>
<p><ins> <span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> also replicated and extended previous work <span class="citation" data-cites="kunisakifujisaki1977 whalen1981">(<a href="#ref-kunisakifujisaki1977" role="doc-biblioref">Kunisaki &amp; Fujisaki, 1977</a>; <a href="#ref-whalen1981" role="doc-biblioref">Whalen, 1981</a>)</span> demonstrating that listeners report hearing more of the synthetic fricative continuum as [s] when followed by a rounded vowel quality such as English [u] than when followed by an unrounded quality such as [i] or [a]. Listeners experience the fricative continuum differently in the presence of anticipatory coarticulation. The presence of nasal coarticulation on a vowel similarly allows listeners to make a lexical decision between words like <em>bend</em> and <em>bed</em> as soon as that information is present in the acoustic signal <span class="citation" data-cites="beddormcgowanbolandcoetzeebrasher2013 beddorcoetzeestylermcgowanboland2018">(<a href="#ref-beddormcgowanbolandcoetzeebrasher2013" role="doc-biblioref">Beddor et al., 2013</a>, <a href="#ref-beddorcoetzeestylermcgowanboland2018" role="doc-biblioref">2018</a>)</span>. Mann &amp; Repp’s participants in this study experienced auditory evidence of posteriority in the ambiguous portion of the fricative continuum as the presence of coarticulation with a following rounded vowel. As with vocal tract length, above, the behavioral result was a shift in the listeners’ fricative category boundary toward [s]. </ins><span class="critic comment">KM: clarifying and putting this back at least for now.</span></p>
<p><span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span> conducted a pair of experiments investigating the influence of purported gender of a talker on the perception of the [ʃ]-[s] boundary. In their experiment 1, listeners heard a [ʃ]-[s] continuum paired with voices previously normed as prototypical female, non-prototypical female, non-prototypical male, and prototypical male voices. The result replicates <span class="citation" data-cites="MannRepp1980">Mann and Repp (<a href="#ref-MannRepp1980" role="doc-biblioref">1980</a>)</span> and extends it to show that the influence of a gendered voice correlates with the protypicality of that voice (exp1). They then extend this research to show that presenting listeners with prototypically-gendered videos of their purported talker can, again, shift perceptions of the [ʃ]-[s] such that listeners report hearing a higher proportion of the continuum as [ʃ] when watching a female talker and a higher proportion of [s] when watching a male talker. The AV condition of their experiment 2 is reminiscent of <span class="citation" data-cites="McGurkMacDonald1976">McGurk and MacDonald (<a href="#ref-McGurkMacDonald1976" role="doc-biblioref">1976</a>)</span> and is presented in that context. A striking feature of the McGurk Effect is its automaticity; participants can not choose to perceive the two components of a fused percept independently. It is unclear from <span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span> and subsequent work whether the perceptual influence of visually-presented social information is implicit and automatic, like vocal tract size, the McGurk effect, etc., or whether the effect disappears when listeners are aware of the guise manipulation.</p>
<p>This is an incomplete sample of the literature on the perception of these fricatives. We hope, however, that the message is clear that even when arriving at a purely linguistic percept, listeners’ judgments depend on a rich constellation of evidence and expectation. Vocal tract size, formant transitions, following vowel quality <span class="citation" data-cites="MannRepp1980">(<a href="#ref-MannRepp1980" role="doc-biblioref">Mann &amp; Repp, 1980</a>)</span>, and coarticulatory cues, along with the acoustic properties of the fricative itself, can all shape how listeners report experiencing that fricative. Rather than relying on a single, invariant, phonetic cue, listeners take the entire fricative and context into account <span class="citation" data-cites="whalen1991">Whalen (<a href="#ref-whalen1991" role="doc-biblioref">1991</a>)</span>.</p>
<p><del>One imagines</del><ins> It is conceivable that</ins> <span class="critic comment">KM</span> such exquisite sensitivity to the phonetic cues conveying linguistic category membership might restrict language users’ freedom to communicate and perceive social information via the same phonetic signal. This would be the prediction of a phonetic theory in which linguistic information and social information battle for control of the air waves –where listeners must normalize away social variation to recover linguistic information. Instead, with these fricatives, at least, we can observe the opposite. The fricatives /ʃ/ and /s/ often carry social meaning <span class="citation" data-cites="podesvakajino2014 mackMunson2012b">(<a href="#ref-mackMunson2012b" role="doc-biblioref">Mack &amp; Munson, 2012</a>; <a href="#ref-podesvakajino2014" role="doc-biblioref">Podesva &amp; Kajino, 2014</a>)</span> with /s/ being “perhaps the most iconic phonetic variable in the field” <span class="citation" data-cites="calder2018">(<a href="#ref-calder2018" role="doc-biblioref">Calder, 2018</a>)</span>. The implication is that the social and linguistic meanings of particular phonetic cues are not in competition with one another.</p>
</section>
<section id="phonetics-speech-perception-and-the-social-construction-of-gender" class="level2">
<h2 data-anchor-id="phonetics-speech-perception-and-the-social-construction-of-gender">Phonetics, Speech Perception, and the Social-Construction of Gender</h2>
<p>It has long seemed normal in speech research to imagine that gender is a simple, binary projection from biological sex onto social identity <span class="citation" data-cites="daniel2007 samolinski2007">(<a href="#ref-daniel2007" role="doc-biblioref">Daniel et al., 2007</a>; <a href="#ref-samolinski2007" role="doc-biblioref">Samoliński et al., 2007</a>)</span>. However, if these biological tendencies were deterministic we would expect to see differentiation begin at puberty. It does not. In fact, prior to the onset of puberty, girls’ oral and nasal cavities tend to be larger than those of boys <span class="citation" data-cites="samolinski2007">(<a href="#ref-samolinski2007" role="doc-biblioref">Samoliński et al., 2007</a>)</span>. If anything, we should expect lower formants and lower center and peak frequencies for girls, inverting the adult pattern. Instead what we observe is that listeners can differentiate the voices of children as young as 4 years of age using vowel formant frequencies <span class="citation" data-cites="perryOhdeAshmead2001">(<a href="#ref-perryOhdeAshmead2001" role="doc-biblioref">Perry et al., 2001</a>)</span>. <span class="citation" data-cites="schellingerMunsonEdwards2017">Schellinger et al. (<a href="#ref-schellingerMunsonEdwards2017" role="doc-biblioref">2017</a>)</span>] report a pair of experiments in which participants heard words produced by children between the ages of 2 and 5, and provided continuous ratings identifying fricatives, vowels, and gender typicality. Children typically show gendered patterns in speech at age 4 and up despite vocal tract length being non-distinct for this cohort. It is critical to remember that formants and fricatives are the result of not purely vocal tract biology but also articulator coordination. Even without biologically-differentiated vocal tracts, people who identify as male or female can perform that identity through gestural style. Vowels, in both their linguistic and social aspects, are the acoustic consequence of gestural control.</p>
<p>Gender is more likely the product of, rather than an explanation for, linguistic variation <span class="citation" data-cites="eckertPodesva2021">(<a href="#ref-eckertPodesva2021" role="doc-biblioref">Eckert &amp; Podesva, 2021</a>)</span>. Just as with words, genders are arbitrary; both the category labels and their acoustic correlates are language specific <span class="citation" data-cites="johnson2005 Johnson2006">(<a href="#ref-johnson2005" role="doc-biblioref">Johnson, 2005</a>; <a href="#ref-Johnson2006" role="doc-biblioref">Johnson, 2006</a>)</span> and the constellation of meanings are socially-constructed in interaction <span class="citation" data-cites="eckert2008">(<a href="#ref-eckert2008" role="doc-biblioref">Eckert, 2008</a>)</span>. The formant ratios that distinguish <code>male' from</code>female’ in Norwegian are markedly different from the formant ratios that do this in Danish <span class="citation" data-cites="Johnson2006">(<a href="#ref-Johnson2006" role="doc-biblioref">Johnson, 2006</a>)</span>; what it means to be <code>male' versus</code>female’ is quite different in Thailand than in Japan <span class="citation" data-cites="kang2013 alpert2014">(<a href="#ref-alpert2014" role="doc-biblioref">Alpert, 2014</a>; <a href="#ref-kang2013" role="doc-biblioref">Käng, 2013</a>)</span>. Children don’t perform adult-like vowel formant patterns because they were born tiny men and women, children perform adult-like vowel formant patterns because they identify as a gender and are participating in the sylistic bricolage <span class="citation" data-cites="zimman2017">(<a href="#ref-zimman2017" role="doc-biblioref">Zimman, 2017</a>)</span> available to communicate that gender to others. Humans are meaning-making agents, not deterministically resonating meat tubes and expert listeners of a language know this.</p>
<p>The existence of this knowledge questions awareness XXX control. In the earliest sociophonetic perception research it was still possible to imagine that the kind of knowledge listeners drew on to perceive gender was knowledge of primary biological traits. We now understand that, instead, the influence of gender-based expectations in speech perception like that investigated here is evidence of the influence of cultural knowledge on what are traditionally understood to be purely linguistic decisions <span class="citation" data-cites="boydfruehwaldhall-lew_2021">(<a href="#ref-boydfruehwaldhall-lew_2021" role="doc-biblioref">Boyd et al., 2021</a>)</span>. Just as vowel height, lip rounding, and syllable affiliation influence the perception of fricative place, so too do socially-constructed gender categories.</p>
</section>
<section id="sub-mgt" class="level2">
<h2 data-anchor-id="sub-mgt">Matched Guise</h2>
<p>The Matched Guise technique (MGT) has been deployed in numerous configurations but, at its core, the technique pairs a single linguistic signal (identical recordings, an identical speaker, identical texts, etc.) with multiple purported social categories to elicit the influence of those cues on participants’ linguistic judgments <span class="citation" data-cites="campbell-kibler2005 campbell-kibler2007">(<a href="#ref-campbell-kibler2005" role="doc-biblioref">Campbell-Kibler, 2005</a>, <a href="#ref-campbell-kibler2007" role="doc-biblioref">2007</a>)</span> or language attitudes <span class="citation" data-cites="hadodoVolume chan2021">(<a href="#ref-chan2021" role="doc-biblioref">CHAN, 2021</a>; <a href="#ref-hadodoVolume" role="doc-biblioref">Hadodo, this volume</a>)</span>. In their foundational use of the technique, for example, <span class="citation" data-cites="lambertEtAl1960">Lambert et al. (<a href="#ref-lambertEtAl1960" role="doc-biblioref">1960</a>)</span> found that bilingual Montrealer’s voices evoked quite different social judgments in French vs English guises, providing evidence that listeners are able to perceive and connect social information in the voice to ideological framing of social types. In social speech perception research, cross-modal audio/visual matched guise studies are common in which visual information serves as a ‘guise’ for identical voice recordings; researchers sometimes disregard that even so-called standard voices carry social information <span class="citation" data-cites="rubin1992">Rubin (<a href="#ref-rubin1992" role="doc-biblioref">1992</a>)</span> and sometimes take the combination of voice and visual stimuli into account <span class="citation" data-cites="mcGowan2015 campbell-kibler2016 gnevsheva2017">(<a href="#ref-campbell-kibler2016" role="doc-biblioref">Campbell-Kibler, 2016</a>; <a href="#ref-gnevsheva2017" role="doc-biblioref">Gnevsheva, 2017</a>; <a href="#ref-mcGowan2015" role="doc-biblioref">McGowan, 2015</a>)</span>.</p>
<p>This latter type of guise manipulation has been called ‘inverted’ matched guise [<span class="citation" data-cites="mcGowan2015">McGowan (<a href="#ref-mcGowan2015" role="doc-biblioref">2015</a>)</span>} or, simply, ‘identification’ [<span class="citation" data-cites="drager2013">Drager (<a href="#ref-drager2013" role="doc-biblioref">2013</a>)</span>}. In this paper we intentionally conflate the two to focus on the guise manipulation itself rather than whether the goal is to elicit, primarily, a social judgment as in traditional matched guise or a linguistic behavior.</p>
<p>But uniting these linguistic researchers, and delineating them from colleagues in social psychology <span class="citation" data-cites="rosseelGrondelaers2019">(for discussion, see <a href="#ref-rosseelGrondelaers2019" role="doc-biblioref">Rosseel &amp; Grondelaers, 2019</a>)</span>, is the methodological assumption that the connection of voice to social type happens below the level of conscious awareness. Awareness here, though generally not explicitly acknowledged, appears to be construed narrowly as participants’ ability to identify and comment on the existence of a guise manipulation. Researchers attempt to deceive participants about the intentional use of guise to elicit evidence of social evaluation in language attitudes, segmental speech perception, memory, etc.</p>
<p>It may be assumed that the matched guise technique works because listeners are unaware of the guise manipulation. Researchers go to great lengths to ensure this lack of awareness <span class="citation" data-cites="pharaoKristiansen2019 grondelaersVanGent2019">(<a href="#ref-grondelaersVanGent2019" role="doc-biblioref">Grondelaers &amp; Gent, 2019</a>; e.g. <a href="#ref-pharaoKristiansen2019" role="doc-biblioref">Pharao &amp; Kristiansen, 2019</a>)</span>. However, the majority of studies cannot speak to this lack of awareness during phonetic perception because the data provided by the participants is relatively late in processing and involves layers of potential introspection and evaluation that block access to the initial online percept for listeners and researchers alike. <span class="citation" data-cites="mcgowanBabel2020">McGowan and Babel (<a href="#ref-mcgowanBabel2020" role="doc-biblioref">2020</a>)</span> performed an audio/visual MGT with both a task designed to get at phonetic perception of individual segments and a sociolinguistic interview intended to investigate listeners’ judgements about the purported speaker. Every participant was shown both guises and while segmental and social perceptions were aligned with the identity of the purported talker in the initial guise presentation, these perceptions diverged in the second guise – with phonetic perceptions remaining unchanged and social evaluations tracking the change of guise. Of particular relevance to the present study, despite the fact that the fricatives used in <span class="citation" data-cites="mcgowanBabel2020">McGowan and Babel (<a href="#ref-mcgowanBabel2020" role="doc-biblioref">2020</a>)</span> were not different across guises, participants often commented on how the fricatives participated in communicating the purported social identity. This work raises the likelihood of at least two levels of sociophonetic perception and suggests that further work is needed to understand the role of awareness, and the necessity of deception, for the ``complex, multi-layered process’’ of perception <span class="citation" data-cites="BabelVolume">(<a href="#ref-BabelVolume" role="doc-biblioref">Babel, this volume</a>)</span>.</p>
<p>This paper reports an audiovisual matched guise experiment with both standard ‘hidden’ and novel ‘unhidden’ instruction conditions. The basic task is a replication of <span class="citation" data-cites="strandJohnson1996">Strand and Johnson (<a href="#ref-strandJohnson1996" role="doc-biblioref">1996</a>)</span>. Listeners are asked to identify an ambiguous word as <em>sack</em> or <em>shack</em> on a [ʃ]-[s] continuum given manipulated beliefs about the gender identity of the talker <span class="citation" data-cites="trippMunson2022 steckerDOnofrioVolume">(<a href="#ref-steckerDOnofrioVolume" role="doc-biblioref">Stecker &amp; D’Onofrio, this volume</a>; <a href="#ref-trippMunson2022" role="doc-biblioref">Tripp &amp; Munson, 2022</a>)</span>. As described above, numerous previous replications have found that listeners perceive more of the ambiguous continuum as [ʃ] when they believe the speaker identifies as a woman and more as [s] when they believe the speaker identifies as a man and that, furthermore, this effect is bi-directional, with fricative type influencing perception of gender for an ambiguous voice <span class="citation" data-cites="bouavichithEtAl2019">(<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">Bouavichith et al., 2019</a>)</span>. Unusually, participants in the present study’s `unhidden’ instruction condition were briefed, in the instructions, about the guise manipulation. They were instructed that the man or woman in the photo was not associated with the voice they were listening to. <span class="citation" data-cites="campbell-kibler2020">(<a href="#ref-campbell-kibler2020" role="doc-biblioref">Campbell-Kibler, 2021</a>)</span>, using a similar manipulation, finds that listeners have some ability to disregard social information when making accentedness or attractiveness judgments but that influence of available social information, particularly from the voice, is difficult to disregard completely. In the present study, participants were asked to provide a <em>sack</em>/<em>shack</em> lexical decision either with, or without, explicit instructions to disregard the visual stimulus.</p>
</section>
</section>
<section id="method" class="level1">
<h1>Method</h1>
<section id="participants" class="level2">
<h2 data-anchor-id="participants">Participants</h2>
<p>120 participants (self-identified 59 female, 61 male; ages 20 to 75) were recruited to complete the online experiment online. These participants were recruited through prolific.com and had provided language history and demographic data as part of Prolific’s general pre-screening questionnaire. Participation was restricted to a standard sample of desktop computer users located in the USA, , who spent most of their childhoods in the US, , with no known language or hearing difficulties. Additionally, due to an audio playback restriction imposed by Apple Computer, the Safari web browser could not be used. Participants were urged only to accept the task if they could do so in a quiet space, free from distractions and wearing headphones for the 6 to 10 minute duration of the experiment (average time 6:51). Headphone usage was not verified within the instrument. No participants’ data were excluded from analysis. Participants were paid $3 for their time, pro-rated from a projected rate of $20/hour (actual rate: $26.29/hour). This same instrument was piloted in the Speech Perception lab of The Ohio State University and, while reaction times online were generally slower than in-person, results from the online administration were generally consistent with results collected under laboratory conditions. Four participants were excluded for low accuracy rates (below 85%).</p>
</section>
<section id="stimulus-materials" class="level2">
<h2 data-anchor-id="stimulus-materials">Stimulus Materials</h2>
<section id="auditory-stimuli" class="level3">
<h3 data-anchor-id="auditory-stimuli">Auditory Stimuli</h3>
<p>The auditory stimuli used in this study are the same wav-format files used in . The stimuli, which were generously shared with us, contain two parts, both of which are drawn from synthetic continua: a fricative onset and a VC rime. The fricative onsets comprise a synthetic six step /-/ continuum. These steps were generated with the Klatt Synthesizer in Praat using parameters identical to ranging between the values of Munson’s second and eighth continuum steps (which were, in turn, based on the parameters used in ). Centers of Gravity ranged from 3.2 kHz (-like) to 7 kHz ().</p>
<p>For the VC rime, two additional continua were modified from natural productions of spoken by one male-identifying and one female-identifying talker in the carrier phrase ``Say sack again’’. These five-step continua were created by evenly spacing mean F0 across consecutive steps such that the male /k/ continuum increased F0 frequency and formant spacing from their unmodified values while the female talker’s /k/ continuum decreased both parameters from unmodified. each synthesized fricative token was concatenated with each CV rime of /k/ resulting in a total of 60 unique auditory stimuli. These manipulations are described in greater detail in Bouavichith et al’s section 2.1 and summarized visually in Figure <a href="#fig-stimuli" class="quarto-xref" aria-expanded="false">Figure&nbsp;1</a>. Unlike MGT studies that ask a talented, multi-dialectal talker to consciously change their speech style , these stimuli were asked to . As these talkers were advanced doctoral students in a linguistics PhD program, some of the elements of such an identity are likely available to conscious reflection, but many of these indexical features are likely implicit even for them.</p>
<p>La Palma is one of the west most islands in the Volcanic Archipelago of the Canary Islands (<a href="#fig-stimuli" class="quarto-xref" aria-expanded="false">Figure&nbsp;1</a>).</p>
<p><a href="#fig-spatial-plot" class="quarto-xref" aria-expanded="false">Figure&nbsp;2</a> shows the location of recent Earthquakes on La Palma.</p>
</section>
</section>
<section id="sec-data-methods" class="level2">
<h2 data-anchor-id="sec-data-methods">Data &amp; Methods</h2>
</section>
<section id="conclusion" class="level2">
<h2 data-anchor-id="conclusion">Conclusion</h2>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-alpert2014" class="csl-entry" role="listitem">
Alpert, E. R. (2014). <em>Language, gender, and ideology in japanese professional matchmaking.</em> [PhD thesis]. University of Michigan, Department of Anthropology.
</div>
<div id="ref-BabelVolume" class="csl-entry" role="listitem">
Babel, A. (this volume). A semiotic approach to awareness and control. <em>Journal of Sociolinguistics</em>, <em>42</em>(1).
</div>
<div id="ref-beddorcoetzeestylermcgowanboland2018" class="csl-entry" role="listitem">
Beddor, P. S., Coetzee, A. W., Styler, W., McGowan, K. B., &amp; Boland, J. E. (2018). The time course of individuals’ perception of coarticulatory information is linked to their production: Implications for sound change. <em>Language</em>, <em>94</em>(4), 931–968.
</div>
<div id="ref-beddormcgowanbolandcoetzeebrasher2013" class="csl-entry" role="listitem">
Beddor, P. S., McGowan, K. B., Boland, J. E., Coetzee, A. W., &amp; Brasher, A. (2013). The time course of perception of coarticulation. <em>The Journal of the Acoustical Society of America</em>, <em>133</em>(4), 2350–2366.
</div>
<div id="ref-bouavichithEtAl2019" class="csl-entry" role="listitem">
Bouavichith, D. A., Calloway, I. C., Craft, J. T., Hildebrandt, T., Tobin, S. J., &amp; Beddor, P. S. (2019). Bidirectional effects of priming in speech perception: Social-to-lexical and lexical-to-social. <em>The Journal of the Acoustical Society of America</em>, <em>145</em>. <a href="https://doi.org/10.1121/1.5101933">https://doi.org/10.1121/1.5101933</a>
</div>
<div id="ref-boydfruehwaldhall-lew_2021" class="csl-entry" role="listitem">
Boyd, Z., Fruehwald, J., &amp; Hall-Lew, L. (2021). Crosslinguistic perceptions of /s/ among english, french, and german listeners. <em>Language Variation and Change</em>, <em>33</em>(2), 165–191. <a href="https://doi.org/10.1017/S0954394521000089">https://doi.org/10.1017/S0954394521000089</a>
</div>
<div id="ref-calder2018" class="csl-entry" role="listitem">
Calder, J. (2018). From <span>“gay lisp”</span> to <span>“fierce queen”</span>: The sociophonetics of sexuality’s most iconic variable. In K. Hall &amp; R. Barrett (Eds.), <em>The oxford handbook of language and sexuality</em> (pp. 1–23).
</div>
<div id="ref-campbell-kibler2005" class="csl-entry" role="listitem">
Campbell-Kibler, K. (2005). <em>Listener perceptions of sociolinguistic variables: The case of (ING)</em> [PhD thesis]. Stanford University.
</div>
<div id="ref-campbell-kibler2007" class="csl-entry" role="listitem">
Campbell-Kibler, K. (2007). Accent,(ING), and the social logic of listener perceptions. <em>American Speech</em>, <em>82</em>(1), 32–64.
</div>
<div id="ref-campbell-kibler2016" class="csl-entry" role="listitem">
Campbell-Kibler, K. (2016). Toward a cognitively realistic model of meaningful sociolinguistic variation. In A. Babel (Ed.), <em>Awareness and control in sociolinguistic research</em> (pp. 123–151).
</div>
<div id="ref-campbell-kibler2020" class="csl-entry" role="listitem">
Campbell-Kibler, K. (2021). Deliberative control in audiovisual sociolinguistic perception. <em>Journal of Sociolinguistics</em>, <em>25</em>(2), 253–271.
</div>
<div id="ref-chan2021" class="csl-entry" role="listitem">
CHAN, K. L. R. (2021). Verbal guise test: Problems and solutions. <em>Academia Letters</em>.
</div>
<div id="ref-daniel2007" class="csl-entry" role="listitem">
Daniel, M. M., Lorenzi, M. C., Costa Leite, C. da, &amp; Lorenzi-Filho, G. (2007). Pharyngeal dimensions in healthy men and women. <em>Clinics</em>, <em>62</em>(1), 5–10.
</div>
<div id="ref-drager2013" class="csl-entry" role="listitem">
Drager, K. (2013). Experimental methods in sociolinguistics. In J. Holmes &amp; K. Hazen (Eds.), <em>Research methods in sociolinguistics: A practical guide</em> (pp. 58–73). Wiley Blackwell.
</div>
<div id="ref-eckert2008" class="csl-entry" role="listitem">
Eckert, P. (2008). Variation and the indexical field 1. <em>Journal of Sociolinguistics</em>, <em>12</em>(4), 453–476.
</div>
<div id="ref-eckertPodesva2021" class="csl-entry" role="listitem">
Eckert, P., &amp; Podesva, R. J. (2021). Non-binary approaches to gender and sexuality. <em>The Routledge Handbook of Language, Gender, and Sexuality</em>, 25–36.
</div>
<div id="ref-fant1960" class="csl-entry" role="listitem">
Fant, G. (1960). <em>Acoustic theory of speech production</em>. Mouton.
</div>
<div id="ref-gnevsheva2017" class="csl-entry" role="listitem">
Gnevsheva, K. (2017). Within-speaker variation in passing for a native speaker. <em>International Journal of Bilingualism</em>, <em>21</em>(2), 213–227.
</div>
<div id="ref-grondelaersVanGent2019" class="csl-entry" role="listitem">
Grondelaers, S., &amp; Gent, P. van. (2019). How <span>“deep”</span> is dynamism? Revisiting the evaluation of moroccan-flavored netherlandic dutch. <em>Linguistics Vanguard</em>, <em>5</em>(s1).
</div>
<div id="ref-hadodoVolume" class="csl-entry" role="listitem">
Hadodo, M. (this volume). Situating experience in social meaning: Ethnography, experiments and exemplars in the enregisterment of istanbul greek. <em>Journal of Sociolinguistics</em>, <em>42</em>(1).
</div>
<div id="ref-johnson2005" class="csl-entry" role="listitem">
Johnson, K. (2005). Speaker normalization in speech perception. In D. B. Pisoni &amp; R. Remez (Eds.), <em>The handbook of speech perception</em> (pp. 363–389).
</div>
<div id="ref-Johnson2006" class="csl-entry" role="listitem">
Johnson, K. (2006). Resonance in an exemplar-based lexicon: The emergence of social identity and phonology. <em>Journal of Phonetics</em>, <em>34</em>, 485–499.
</div>
<div id="ref-kang2013" class="csl-entry" role="listitem">
Käng, D. B. (2013). Conceptualizing thai genderscapes: Transformation and continuity in the thai sex/gender system. In <em>Contemporary socio-cultural and political perspectives in thailand</em> (pp. 409–429). Springer.
</div>
<div id="ref-kunisakifujisaki1977" class="csl-entry" role="listitem">
Kunisaki, O., &amp; Fujisaki, H. (1977). On the influence of context upon perception of voiceless fricative consonants. <em>Annual Bulletin</em>, <em>11</em>, 85–91.
</div>
<div id="ref-lambertEtAl1960" class="csl-entry" role="listitem">
Lambert, W. E., Hodgson, R. C., Gardner, R. C., &amp; Fillenbaum, S. (1960). Evaluational reactions to spoken languages. <em>The Journal of Abnormal and Social Psychology</em>, <em>60</em>(1), 44.
</div>
<div id="ref-mackMunson2012b" class="csl-entry" role="listitem">
Mack, S., &amp; Munson, B. (2012). The association between/s/quality and perceived sexual orientation of men’s voices: Implicit and explicit measures. <em>Journal of Phonetics</em>, <em>40</em>(1), 198–212.
</div>
<div id="ref-MannRepp1980" class="csl-entry" role="listitem">
Mann, V. A., &amp; Repp, B. H. (1980). Influence of vocalic context on perception of the [ʃ]-[s] distinction. <em>Perception &amp; Psychophysics</em>, <em>28</em>(3), 213–228.
</div>
<div id="ref-May1976" class="csl-entry" role="listitem">
May, J. (1976). Vocal tract normalization for /s/ and /š/. <em>Haskins Laboratories Status Report on Speech Research</em>, <em>SR-48</em>, 67–73.
</div>
<div id="ref-mcGowan2015" class="csl-entry" role="listitem">
McGowan, K. B. (2015). Social expectation improves speech perception in noise. <em>Language and Speech</em>, <em>58</em>(4), 502–521.
</div>
<div id="ref-mcgowanBabel2020" class="csl-entry" role="listitem">
McGowan, K. B., &amp; Babel, A. M. (2020). Perceiving isn’t believing: Divergence in levels of sociolinguistic awareness. <em>Language in Society</em>, <em>49</em>(2), 231–256.
</div>
<div id="ref-McGurkMacDonald1976" class="csl-entry" role="listitem">
McGurk, H., &amp; MacDonald, J. (1976). Hearing lips and seeing voices. <em>Nature</em>, <em>264</em>, 746–748.
</div>
<div id="ref-munson2011" class="csl-entry" role="listitem">
Munson, B. (2011). The influence of actual and imputed talker gender on fricative perception, revisited (l). <em>The Journal of the Acoustical Society of America</em>, <em>130</em>(5), 2631–2634.
</div>
<div id="ref-ohala1984" class="csl-entry" role="listitem">
Ohala, J. J. (1984). An ethological perspective on common cross-language utilization of F₀ of voice. <em>Phonetica</em>, <em>41</em>(1), 1–16.
</div>
<div id="ref-perryOhdeAshmead2001" class="csl-entry" role="listitem">
Perry, T. L., Ohde, R. N., &amp; Ashmead, D. H. (2001). The acoustic bases for gender identification from children’s voices. <em>The Journal of the Acoustical Society of America</em>, <em>109</em>(6), 2988–2998.
</div>
<div id="ref-pharaoKristiansen2019" class="csl-entry" role="listitem">
Pharao, N., &amp; Kristiansen, T. (2019). Reflections on the relation between direct/indirect methods and explicit/implicit attitudes. <em>Linguistics Vanguard</em>, <em>5</em>(s1).
</div>
<div id="ref-podesvakajino2014" class="csl-entry" role="listitem">
Podesva, R. J., &amp; Kajino, S. (2014). Sociophonetics, gender, and sexuality. <em>The Handbook of Language, Gender, and Sexuality</em>, 103–122.
</div>
<div id="ref-rosseelGrondelaers2019" class="csl-entry" role="listitem">
Rosseel, L., &amp; Grondelaers, S. (2019). Implicitness and experimental methods in language variation research. <em>Linguistics Vanguard</em>, <em>5</em>(s1).
</div>
<div id="ref-rubin1992" class="csl-entry" role="listitem">
Rubin, D. L. (1992). Nonlanguage factors affecting undergraduates’ judgments of nonnative english-speaking teaching assistants. <em>Research in Higher Education</em>, <em>33</em>(4), 511–531.
</div>
<div id="ref-samolinski2007" class="csl-entry" role="listitem">
Samoliński, B. K., Grzanka, A., &amp; Gotlib, T. (2007). Changes in nasal cavity dimensions in children and adults by gender and age. <em>The Laryngoscope</em>, <em>117</em>(8), 1429–1433.
</div>
<div id="ref-schellingerMunsonEdwards2017" class="csl-entry" role="listitem">
Schellinger, S. K., Munson, B., &amp; Edwards, J. (2017). Gradient perception of children’s productions of/s/and/<span class="math inline">\theta</span>: A comparative study of rating methods. <em>Clinical Linguistics &amp; Phonetics</em>, <em>31</em>(1), 80–103.
</div>
<div id="ref-shadle1991" class="csl-entry" role="listitem">
Shadle, C. H. (1991). The effect of geometry on source mechanisms of fricative consonants. <em>Journal of Phonetics</em>, <em>19</em>(3-4), 409–424.
</div>
<div id="ref-steckerDOnofrioVolume" class="csl-entry" role="listitem">
Stecker, A., &amp; D’Onofrio, A. (this volume). Recognizing uptalk: Memory and metalinguistic commentary for a sociolinguistic feature. <em>Journal of Sociolinguistics</em>, <em>42</em>(1).
</div>
<div id="ref-strand1999" class="csl-entry" role="listitem">
Strand, E. A. (1999). Uncovering the role of gender stereotypes in speech perception. <em>Journal of Language and Social Psychology</em>, <em>18</em>(1), 86–100.
</div>
<div id="ref-strandJohnson1996" class="csl-entry" role="listitem">
Strand, E. A., &amp; Johnson, K. (1996). Gradient and visual speaker normalization in the perception of fricatives. <em>KONVENS</em>, 14–26.
</div>
<div id="ref-trippMunson2022" class="csl-entry" role="listitem">
Tripp, A., &amp; Munson, B. (2022). Perceiving gender while perceiving language: Integrating psycholinguistics and gender theory. <em>Wiley Interdisciplinary Reviews: Cognitive Science</em>, <em>13</em>(2), e1583.
</div>
<div id="ref-whalen1981" class="csl-entry" role="listitem">
Whalen, D. H. (1981). Effects of vocalic formant transitions and vowel quality on the english [s]–[<span>š</span>] boundary. <em>The Journal of the Acoustical Society of America</em>, <em>69</em>(1), 275–282.
</div>
<div id="ref-whalen1984" class="csl-entry" role="listitem">
Whalen, D. H. (1984). Subcategorical phonetic mismatches slow phonetic judgments. <em>Perception &amp; <span>Psychophysics</span></em>, <em>35</em>, 49–64.
</div>
<div id="ref-whalen1991" class="csl-entry" role="listitem">
Whalen, D. H. (1991). Perception of the english/s/–//distinction relies on fricative noises and transitions, not on brief spectral slices. <em>The Journal of the Acoustical Society of America</em>, <em>90</em>(4), 1776–1785.
</div>
<div id="ref-zimman2017" class="csl-entry" role="listitem">
Zimman, L. (2017). Gender as stylistic bricolage: Transmasculine voices and the relationship between fundamental frequency and/s. <em>Language in Society</em>, <em>46</em>(3), 339–370.
</div>
</div>
<div id="fig-stimuli" class="quarto-float quarto-figure quarto-figure-center FigureWithoutNote" data-fignum="1" prefix="" data-custom-style="FigureWithoutNote">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-stimuli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;1</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p><span class="citation" data-cites="bouavichithEtAl2019">Bouavichith et al. (<a href="#ref-bouavichithEtAl2019" role="doc-biblioref">2019</a>)</span> auditory stimulus continua. S1, S2, S3, S4, and S5 represent continuum steps from most <em>sack</em>-like to most <em>shack</em>-like fricatives. F0 and F1:F2 Ratio plots show the manipulations to the Male and Female voiced vowels.</p>
</div>
</figcaption>
<div aria-describedby="fig-stimuli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/figure1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: @bouavichithEtAl2019 auditory stimulus continua. S1, S2, S3, S4, and S5 represent continuum steps from most sack-like to most shack-like fricatives. F0 and F1:F2 Ratio plots show the manipulations to the Male and Female voiced vowels."><img src="images/figure1.png" class="img-fluid figure-img"></a>
</div>
</figure>
</div>
<div class="quarto-embed-nb-cell FigureWithoutNote" data-custom-style="FigureWithoutNote">
<div id="cell-fig-spatial-plot" class="cell">
<div class="cell-output cell-output-display">
<div id="fig-spatial-plot" class="quarto-float quarto-figure quarto-figure-center" alt="A scatterplot of earthquake locations plotting latitude against longitude." prefix="" data-fignum="2">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-spatial-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;2</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Locations of earthquakes on La Palma since 2017</p>
</div>
</figcaption>
<div aria-describedby="fig-spatial-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-explore-earthquakes-fig-spatial-plot-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Locations of earthquakes on La Palma since 2017"><img src="index_files/figure-html/notebooks-explore-earthquakes-fig-spatial-plot-output-1.png" class="img-fluid figure-img" alt="A scatterplot of earthquake locations plotting latitude against longitude."></a>
</div>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{laycock2024,
  author = {Laycock, Kyler and B McGowan, Kevin},
  title = {Removing the Disguise: The Matched Guise Technique and
    Listener Awareness},
  date = {2024-05-23},
  langid = {en},
  abstract = {Sociophonetic perception is often studied using versions
    of the matched guise technique. Linguists using this technique
    appear united in the methodological assumptions that participants
    believe the manipulation and that this belief influences perception
    below the level of introspective awareness. We report an audiovisual
    matched guise experiment with a novel “unhidden” instruction
    condition. The basic task is a replication of the Strand effect
    {[}@strandJohnson1996; @strand1999{]}. Participants in the
    “unhidden” condition were instructed that the man or woman in the
    photo did not represent the voice they were listening to.
    Participants in both guises exhibited the Strand effect to nearly
    numerically identical extents. This result suggests that
    participants need not believe a link exists between a voice and a
    purported social category for visually-cued social information to
    influence segmental perception. We explore the implications of this
    result for the MGT and for theories of social awareness and speech
    perception more broadly.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-laycock2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Laycock, K., &amp; B McGowan, K. (2024, May 23). <em>Removing the
disguise: the matched guise technique and listener awareness</em>.
Awareness and Control of Sociolinguistic Variation.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="kbmcgowan/play-manuscript" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->

<div id="criticnav">
<ul>
<li id="markup-button">Markup</li>
<li id="original-button">Original</li>
<li id="edited-button">Edited</li>
</ul>
</div>

<script type="text/javascript">
  function critic() {

      $('.content').addClass('markup');
      $('#markup-button').addClass('active');
      $('ins.break').unwrap();
      $('span.critic.comment').wrap('<span class="popoverc" /></span>');
      $('span.critic.comment').before('&#8225;');
  }

  function original() {
      $('#original-button').addClass('active');
      $('#edited-button').removeClass('active');
      $('#markup-button').removeClass('active');

      $('.content').addClass('original');
      $('.content').removeClass('edited');
      $('.content').removeClass('markup');
  }

  function edited() {
      $('#original-button').removeClass('active');
      $('#edited-button').addClass('active');
      $('#markup-button').removeClass('active');

      $('.content').removeClass('original');
      $('.content').addClass('edited');
      $('.content').removeClass('markup');
  } 

  function markup() {
      $('#original-button').removeClass('active');
      $('#edited-button').removeClass('active');
      $('#markup-button').addClass('active');

      $('.content').removeClass('original');
      $('.content').removeClass('edited');
      $('.content').addClass('markup');
  }

  var o = document.getElementById("original-button");
  var e = document.getElementById("edited-button");
  var m = document.getElementById("markup-button");

  window.onload = critic();
  o.onclick = original;
  e.onclick = edited;
  m.onclick = markup;
</script>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","openEffect":"zoom","selector":".lightbox","loop":false,"descPosition":"bottom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>