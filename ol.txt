\subsubsection{Visual Stimuli}

The visual stimuli used in this study, again identical to the images used in \citep{bouavichithEtAl2019}, are shown in Figure ~\ref{fig:stim}. These included two face images, used for the guise manipulation, which were retrieved from the Chicago Face Database \citep{ChicagoFaceDatabase}, a resource containing high-resolution, normed images of faces indexed by gender and ethnicity.added[id=KL]{The faces selected were normalized for both physical attributes (i.e., measurements of particular facial dimensions), subjective ratings such as attractiveness, and for gender and gender prototypicality.} As in Bouavichith et al., CFD-WF-015-006-N was selected as the representation of the gender-protypical female talker and CFD-WM-029-023-N was selected as the representation of the gender-prototypical male talker. Both images were converted to greyscale at the command line using ImageMagick \citep{imagemagick}.

Additionally, two gray-scale line drawings were used as visual representations of \textit{shack} and \textit{sack}. These images were used in place of orthographic targets both to maintain consistency with Bouavichith et al's design and to facilitate future eye tracking investigation of this phenomenon.

\begin{center}
\captionsetup{justification=centering}
\begin{minipage}{0.6\linewidth}
    \includegraphics[width=\linewidth]{facesanddrawings.jpg}
captionof{figure}{Visual Stimuli comprised \textit{shack} and \textit{sack} targets (top) and a gender-protypical `male' and `female' face (bottom)}
    \label{fig:stim}
\end{minipage}
\end{center}

\subsection{Procedure}

\par The experiment was created in OpenSesame v3.3 \citep{opensesame} and exported for the web using OSWeb v1.4.14.0. Modifications to the experiment included translating portions of the python code into JavaScript and adding code to collect Prolific IDs and provide proof of completion to Prolific at the end of the experiment. This experiment was hosted on a JATOS \citep{JATOS} instance hosted on an Ohio State University Linguistics Department server. Participants received a link to the experiment via Prolific and used their own computers, keyboards, and headphones to complete the experiment.  

\par In a between-subjects design, participants were randomly assigned to one of two awareness conditions. These conditions differed only in the initial information provided as to the nature of the experiment. Participants in the \textit{hidden} condition experienced a standard Matched Guise task. They were given no information about the task or the stimulus materials beyond the general instructions for completing the experiment: listen to the voice, press `z' if you heard the word on the left, press `m' for the word on the right. Participants in the \textit{unhidden} condition also received this instruction and were given a partial debriefing regarding the task. They were informed that-- while they would see faces onscreen while hearing words-- the voices in a given trial were not produced by the person shown in the images, the images had been downloaded from a database of photographs created at the University of Chicago for experimental use, and that the auditory and visual stimuli were in no way related to each other. Participants were divided equally among these two conditions. Neither awareness condition was informed about the synthetic nature of the auditory stimuli. 

\par Additionally, participants were assigned to one of two gender congruity conditions. Although the manipulated rimes sounded gender ambiguous to us, and had been rated as ambiguous by \cite{bouavichithEtAl2019}'s pilot participants, the possibility remained that the voices, particularly at the end-points, might be perceived incongruously with the faces as in, for example, \cite{McGowan2015}\footnote{We are choosing the words `congruous' and `incongruous' intentionally to suggest faces and voices may pattern together in particular ways in listeners' experience and perception with no implied claim that voices may `match' or `mismatch' in some way that suggests either experimenters or participants have veridical access to an objective reality}.

In congruous trials, the faces and voices were paired such that participants were only presented with auditory stimuli from the female talker's continuum alongside the female face and tokens from the male talker were only presented alongside the male face.  In incongruous trials, by contrast, auditory stimuli from the female talker's continuum were only ever presented alongside the male face and tokens from the male talker's continuum were only ever presented alongside the female face. Half of participants were randomly assigned to each congruity condition, resulting in a 4-way between-subjects design across instruction and congruity conditions. Each participant heard all 60 auditory stimuli; 30 paired with the male face and 30 paired with the female face.

In each trial, participants were shown one of the two faces for 1500ms. Following this initial presentation, the face remained onscreen and was flanked by the \textit{shack} and \textit{sack} images. Simultaneously, one of the auditory stimuli was played over the headphones. The trial ended when the participant pressed an appropriate key on their physical keyboard and their response and reaction time data were uploaded to the JATOS instance.  In both congruous and incongruous conditions, all 60 unique trials (30 per face) were presented twice to each participant for a total of 120 trials.

\section{Predicted Results}

\subsection{Face: male or female} Consistent with previous results, we expect to replicate the Strand effect; in general, we anticipate that more of the [ʃ]-[s] continuum will be heard as [ʃ] when participants are shown the female face and more to be heard as [s] when participants are shown the male face. However, these general predictions about the Face presentation when the congruence of auditory and visual components of the guise are taken as a whole.

\subsection{Congruence: pairing of face and voice} To our knowledge, the influence of congruence has not been directly investigated for listeners' joint perception of gender and fricative place. \cite{johnsonstranddimperio1999} tested AV integration of Male and Female faces with prototypical and non-prototypical gendered voices in a vowel quality perception task. They find what appears to be an incongruence effect with the prototypical male voice; listeners reported no difference in perceived vowel quality with this voice in either Face condition \citep[][p. 376, Table 4]{johnsonstranddimperio1999}. For this reason, we anticipate a replication of the Strand effect on fricative identification in our congruous trials (when Face and Voice do not conflict) but a failure to replicate for the incongruous trials (when Face and Voice provide conflicting social information). This difference may be stronger with the male voice, given both Johnson, Strand, and D'Imperio's finding but also \cite{king2021}.

We make a similar prediction for reaction times. \cite{johnsonstranddimperio1999} did not collect reaction time data, but \cite{McGowan2011} reports longer reaction times for incongruous trials, albeit in a very different task, and \cite{whalen1984} would seem to suggest that this should hold for listeners' identification of fricatives on a [ʃ]-[s] continuum. Specifically, we predict longer reaction times, in general, for the Incongruous conditions. Furthermore, when gender information is most clear, at gender continuum steps 1 and 2 for the Male talker and at gender steps 4 \& 5 for the Female talker, and in conflict with the presented Face, listeners' response times should be slower.

Since strong phonetic correlates of gender, F0 and F3, have been manipulated over the course of the VC rime continua in our auditory stimuli, we anticipate that the effect of incongruous face and voice should be strongest for the natural end points of the continua where the difference is most salient and weaker as phonetically-cued gender information becomes more ambiguous. These stimuli have been independently normed for ambiguity \citep[][p. 1040, Table 1]{bouavichithEtAl2019} in the 2nd and 3rd levels of the rime continua.  This means we anticipate an interaction between Face and Rime step but only in the incongruous trials and only at the extremes of the rime continuum.

\subsection{Guise: Hidden or Unhidden} The primary goal of this experiment was to explore the role of listener awareness and control in the matched guise technique. The tremendous care researchers take to ensure that the guise manipulation is hidden from participants suggests a kind of imagined fragility added[id=KL]{of the effects of social information on language perception}. From this view: listeners who become aware of the guise manipulation will have introspective access to and deliberative control over the influence of visual social information on perception. If this is true, explaining the guise manipulation, in the unhidden condition, should have a strongly negative effect on the Strand effect. Alternatively, if the influence of social information is not available to introspection or deliberative control, we should see no change between the (traditional) hidden matched guise and the unhidden guise.

Additionally, we speculate that there may be a response time difference between the Hidden and Unhidden guises even if there is no apparent difference in percept between the conditions. It can certainly be the case that participants will arrive at the same behavioral responses via different cognitive processing paths, perhaps drawing on different levels of knowledge and awareness, and that these differences may be visible in response times between the Instruction conditions.


\section{Results}
\par Participants provided a total of 14,400 trials (120 trials from each of 120 online participants added[id=KL]{; 3600 trials in each instruction x congruity condition}). It is not clear what it means to be `accurate' when asked to perceive fricatives from a continuum so accuracy was calculated only for responses to the [ʃ] and [s] endpoints. Overall, participants were highly accurate (96.8\%) but four participants were excluded from further analysis for accuracy below the pre-determined 85\% threshold reducing the total number of trials to 13,920. Trials were coded as correct if the participant responded `shack' to onset step 1 or `sack' to onset step 6. The four excluded participants all scored 67.5\% accuracy or lower.
\par An additional 50 trials were excluded due to response times that were either too fast or too slow. To reduce the effects of response time outliers on subsequent analyses, all response times shorter than 50 ms (N=0) and longer than 5000ms (N=50) were excluded. The 5000ms response time cutoff was used instead of imposing an in-experiment time limit on responses to a trial to ensure that participants were required to respond to each trial. added[id=KL]{Altogether, 530 trials were excluded, leaving} data from 13,870 trials for analysis (approximately 96.3\% of the initial data set). The majority (96.8\%) of the remaining response times were within a range between 200 and 2000ms. To increase normality of the distribution of response times across participants, the remaining response times were log-transformed.

\subsection{[ʃ]-[s] Percepts}

\begin{center}
\captionsetup{justification=centering}
\begin{minipage}{1.0\linewidth}
    \includegraphics[width=\linewidth]{Scurve.png}
captionof{figure}{Proportion `sack' responses plotted as a function of [ʃ]-[s] fricative (Onset) continuum steps and purported gender presented by the face.}
    \label{fig:scurve}
\end{minipage}
\end{center}

Figure \ref{fig:scurve} presents listeners' percepts on this 2AFC task. The horizontal axis in each of these four plots is the fricative (syllable Onset) continuum step. Step 1 of the continuum is most [ʃ]-like, step 6 is the most [s]-like, steps 3 \& 4 are the most ambiguous. Darker lines in Figure \ref{fig:scurve} present trials using the female Face; lighter lines present trials using the male Face. The Hidden and Unhidden instruction conditions are represented by the left and right columns of figures, respectively. The rows present the Congruous blocks where Face and Coda speaker voice shared a gender identity (top) and Incongruous trials where Face and Coda speaker voice mismatched in gender identity (bottom).

A successful replication of the Strand effect would mean that a higher proportion of the ambiguous stimuli would be heard as [s] when the purported gender suggested by the face is male than when the face is female. This pattern appears to hold in both the Hidden and Unhidden conditions, but only when gender identity of the talker who produced the CV rime stimuli was congruous with the gender presented in the visual portion of the guise. From Figure \ref{fig:scurve} it would appear that listeners' reported percepts more closely track the voice of the talker than the face in the picture when these sources of information are incongruous.

\begin{center}
\captionsetup{justification=centering}
\begin{minipage}{1.0\linewidth}
    \includegraphics[width=\linewidth]{ambiguous-by-rime-step.png}
captionof{figure}{Proportion `sack' responses on ambiguous fricative trials plotted as a function of CV rime continuum steps and gender identity of stimulus talker.}
    \label{fig:rimes}
\end{minipage}
\end{center}

We predicted that, since strong phonetic correlates of gender have been manipulated over the course of the VC rime continua, the effect of incongruence should be strongest for the end points of the continua where the social information presented by the voice is, presumably, most salient and weaker as phonetically-cued gender information becomes more ambiguous. Figure \ref{fig:rimes} suggests that this prediction is at least partially borne out. Figure \ref{fig:rimes} plots proportion `sack' responses  to the ambiguous portion of the [ʃ]-[s] continuum (steps 3 \& 4) as a function of rime continuum step. The meaning of line color has changed in this figure. Dark lines represent the male talker and lighter lines represent the female talker. Step 1 on this continuum includes the most natural token for the male talker and the most manipulated token for the female talker while step 5 includes the most natural token for the male talker and the most manipulated token for the female talker. As before, columns present the Hidden and Unhidden conditions while rows present the Congruous and Incongruous blocks.

In a 2AFC task with unbiased stimuli, chance is 50\%. Responses at the .5 line in figure \ref{fig:rimes} suggest that the ambiguous fricatives remained ambiguous while responses that tend to be above this line reflect a tendency toward [s] percepts and responses that tend to be below this line reflect a tendency toward [ʃ]. Across all 4 conditions we observe a declination from highest-proportion [s] responses in step 1 of the F0 continua to lowest in step 5. When face and voice were congruous, virtually all male-voice (and male face) responses are above or at 50\% `sack' and virtually all female-voiced (and female face) responses are at or \emph{below} 50\% `sack'. This is the same pattern that can be observed at Onset continuum steps 3 \& 4 in figure \ref{fig:scurve}. It is not clear from Figure \ref{fig:rimes} alone if there is any difference at all between the Congruous and Incongruous conditions. However, it is important to recall about the bottom row of this figure that male talker responses in the incongruous trials were presented with a female face while female talker trials were presented with a male face. Even a weakly-significant Strand effect would predict that the female talker, particularly on the more ambiguous continuum steps, should show more `sack' responses consistent with having been shown a male face and no such effect is evident in this plot.

Indeed, a striking feature of figures \ref{fig:scurve} and \ref{fig:rimes} is how the apparent influence of gender information flips between congruous and incongruous conditions in the former but remains essentially constant in the latter. Taken together, these plots suggest that cues to gender in F0 is a stronger predictor of listeners' reported percept in this matched guise task than just the purported gender of the face. 

Finally, the main objective of this experiment was to explore the role of listener awareness in the matched guise technique. Here again there may be differences between the congruous and incongruous conditions that will be better understood through quantitative analysis, but the overall trend is clear. If there is an effect of explaining to participants that the voice and face in the matched guise task are unrelated to each other, that effect is so weak as to be essentially invisible in these  visual interrogations of the data. Categorical responses in the Hidden and Unhidden instruction conditions appear to be identical.

\subsection{Logistic Regression and Quantitative Analysis}

These qualitative assessments of listener responses can be examined further through quantitative analysis. Through model comparison we initially arrived at a logistic mixed model to predict percept with Congruity condition, instruction condition, Onset step, Face, and Rime step with interactions for all but Rime step. This model was justified by model selection but given the notorious difficulty of interpreting a 4-way interaction and the preceding visual interrogation of the data, we opted to separate Congruence into a pair of 3-way models. Using \verb|glmer()| \citep{lme4}, we divided the data into congruous and incongruous subsets and fitted a pair of logistic mixed models (estimated using ML and BOBYQA optimizer) to predict percept with Instruction condition, Onset.step, Face and Rime step (\lstinline[breaklines=true]|percept ~ Instruction * Onset.step * Face + Rime.step|). The models included random intercepts for subject. All categorical predictors were coded using contrast coding.

\begin{center}
\captionsetup{justification=centering}
\begin{minipage}{1.0\linewidth}
    \includegraphics[width=\linewidth]{coefs_instruction.png}
captionof{figure}{Estimated Beta coefficients for listener responses in the Congruous (black) and Incongruous (gray) logistic regression models plotted with 95\% confidence intervals.}
    \label{fig:coefs}
\end{minipage}
\end{center}

Beta coefficients for the two separate logistic mixed models are plotted together in Figure \ref{fig:coefs}. Terms plotted to the left of the dashed zero line have a negative influence on `sack' percepts in the model while terms plotted to the right have a positive influence. As a consistency check we can observe that the levels of the Onset continuum behave in precisely the expected ways and all levels are statistically significant predictors of percept in both models. Onset step 1 ([ʃ]) is negatively associated with `sack' responses and significant in both the Congruous ($β=-5.00, SE=0.28, p < 0.001$) and Incongruous ($β=-4.84, SE=0.24, p < 0.001$) models. Onset step 5 ([s]) is positively associated with `sack' responses and significant in both the Congruous ($β=4.35, SE=, p < 0.001$) and Incongruous ($β=4.12, SE=0.19, p < 0.001$) models.

As visual inspection of the data suggests, this study includes a replication of the Strand effect in the Congruous condition. There is a main effect of Face in the model ($β=-0.22, SE=0.09, p<0.05$). Face is negatively associated with `sack' responses suggesting that, with these stimuli, at least, it is more appropriate to understand the effect of Face as an increase of `shack' responses given the female Face. The inclusion of the interaction term for Onset and Face allows us to see that the effect of Face is greatest on the ambiguous Onset steps 3 ($β=-0.43, SE=0.11, p < 0.001$) and, to a lesser extent, 4 ($β=-0.23, SE=0.11, p < 0.05$).

However, the Strand effect observed in the Congruous condition is not attributable entirely to the main effect of Face. Rime F0 is also significant; Rime level 1, the male end of the continuum, is positively associated with `sack' responses ($β=0.61, SE=0.10, p < 0.001$) as is Rime level 2 ($β=0.52, SE=0.10, p < 0.001$). Rime level 3, where the  continuum is most gender ambiguous, is not statistically significant. Rime level 4, on the female end of the continuum, is negatively associated with `sack' responses and significant ($β=-0.49, SE=0.10, p < 0.001$).

Unsurprisingly, the Strand effect has not been replicated in the incongruous condition. As is visible in the bottom row of Figure \ref{fig:scurve}, the effect of Face on `sack' responses is not significant. The interaction of Onset and Face also behaves quite differently in the Incongruous model. Onset x Face is negatively associated with `sack' responses at Onset step 1 ($β=-0.66, SE=0.24, p < 0.001$) but positively associated with `sack' responses and significant at Onset step 3 ($β=0.27, SE=0.11, p < 0.05$).

Interestingly, the significant effect of Rime observed in the Congruous model also holds, nearly identically, in the Incongruous model. Rime level 1, the male end of the continuum, is again positively associated with `sack' responses ($β=0.77, SE=0.10, p < 0.001$) as is Rime level 2 ($β=0.41, SE=0.10, p < 0.001$). Rime level 3 is also not statistically significant in the Incongruous model. Rime level 4, on the female end of the continuum, is negatively associated with `sack' responses and significant ($β=-0.36, SE=0.10, p < 0.001$).

Finally, the quantitative analysis of the primary objective of this experiment, exploring the effect of unhiding the matched guise manipulation from participants, largely supports the qualitative analysis. As can be observed in Figure \ref{fig:coefs}, there is no significant main effect of Instruction condition in either model. Still, a somewhat more nuanced picture emerges from the interactions of Instruction condition with Onset and the 3 way interaction of Instruction, Onset, and Face in the Congruous trials. The interaction of Instruction with Onset is significant, or nearly so, at every step of the fricative continuum other than the most significant. In the [ʃ]-like portion of the continuum, the interaction with face is positively associated with `sack' responses at step 1 ($β=0.65, SE=0.28, p < 0.05$) and 2 ($β=0.44, SE=0.18, p < 0.05$). The interaction of guise with the most ambiguous onset step is not significant ($β=0.011, SE=0.12$). The interaction of Instruction with Onset step 4, on the [s] end of the continuum is negatively associated with `sack' responses and statistically significant ($β=-0.43, SE=0.12, p < 0.001$). Instruction x Onset step4 is also negatively associated with `sack' responses but does not reach significance at the standard alpha level ($β=-0.40, SE=0.22, p = 0.067$). The 3-way interaction of Instruction x Onset x Face is positively associated with `sack' responses at step 2 ($β=0.41, SE=0.17, p < 0.05$) and weakly, but not significantly, negatively associated with `sack' responses at step 5 ($β=-0.38, SE=0.21, p = 0.080$).

There is also no main effect of Instruction in the Incongruous trials. The 3-way interaction of Instruction x Onset x Face, while justified by model selection for inclusion in this model, also does not reach statistical significance. However the 2-way interaction of Instruction with Onset step is positively associated with `sack' responses at Onset step 2 ($β=0.53, SE=0.21, p < 0.05$) and approaches significance at step 3, where it is weakly positively associated ($β=0.18, SE=0.11, p = 0.095$) and step 5 where it is weakly negatively associated ($β=-0.32, SE=0.19, p = 0.086$).

\subsection{Response Times}

As with the logistic regression models, we again opted to separate Congruence into a pair of 3-way models for linear mixed model analysis of our log-transformed response time data. Using \verb|lmer()| \citep{lme4}, we reused the congruous and incongruous subsets created for the logistic regression models and We fitted a linear mixed model (estimated using REML and nloptwrap optimizer) to predict logRT with Guise, Onset, Face and Rime
(\lstinline|logRT ~ Instruction * Onset * Face + Rime|).
The models included random intercepts for subject. All categorical predictors were coded using contrast coding. Beta coefficients for both models are plotted in Figure \ref{fig:coefs:logRT}. Terms plotted to the left of the zero line are associated with a decrease in log response time while terms plotted to the right of the zero line are associated with an increase in log response time. Notably, the longest response times are associated with the most ambiguous steps of the [ʃ]-[s] onset continuum. Onset step 3 is positively associated with response time and significant in both the congruous ($β=0.08, SE=0.007, p < 0.001$) and incongruous ($β=0.07, SE=0.007, p < 0.001$ ) models. The same is true of step 4 in the congruous ($β=0.07, SE=0.007, p < 0.001$) and incongruous ($β=0.07, SE=0.007, p < 0.001$) models as well. On the other hand, steps 1, 2, and 5 are all negatively associated with response time and also significant in both models (see Figure \ref{fig:coefs:logRT}).
\begin{center}
\captionsetup{justification=centering}
\begin{minipage}{1.0\linewidth}
    \includegraphics[width=\linewidth]{coefs-logRT_instructions.png}
captionof{figure}{Estimated Beta coefficients for log-transformed response times in the Congruous (black) and Incongruous (gray) linear regression models plotted with 95\% confidence intervals.}
    \label{fig:coefs:logRT}
\end{minipage}
\end{center}

We predicted overall slower response times in the Incongruous than Congruous conditions and this prediction is not borne out by the data. Apart from generally higher variability in the incongruous conditions, there is no positive or negative trend in response times between the two Congruity models. For example, within the Incongruous model response times given the interaction of Onset step 3 * Face are longer  ($β=-0.009, SE=0.007, p = 0.17$), which would seem to support our prediction, but response times for Onset step 4 * Face are shorter ($β-0.02, SE=0.007, p < 0.01$), the opposite of what we predicted. The exact opposite pattern appears within the Congruous model where response times are shorter given Onset 3 * Face ($β=-0.02, SE=0.007, p < 0.01$) but longer given Onset step 4 * Face ($β=0.04, SE=0.007, p < 0.001$). These crossing patterns can be seen in Figure \ref{fig:coefs:logRT}.

Given the replication of the Strand effect in the Congruous, but not the Incongruous conditions described in the previous section, it may be notable that there is a significant main effect of Face in the Congruous model where it is negatively associated with response time ($β=0.22, SE=0.08, p < 0.05$) and not significant in the Incongruous model.


\section{Discussion}

The question that motivated this study was a desire to understand the role of listener awareness and control in the matched guise technique. We believe that the careful measures researchers generally employ to obscure the nature of the guise manipulation from participants is attributable to a long-held assumption in the sociolinguistics literature that social knowledge is high-level knowledge, available to introspective control, and that this differs from linguistic knowledge which is low-level knowledge, unavailable to control \citep{campbell-kibler2016}. The results of the present study are inconsistent with this imagined fragility of the influence of social knowledge. Revealing the nature of the guise manipulation did not significantly influence listener responses in either the congruous or incongruous conditions. Nor did this revelation have a significant influence on response times in either condition.

The finding that the Matched Guise effect holds for speech perception both when hidden from the participant and when unhidden is inconsistent with a model of processing in which social knowledge simply acts as a filter on linguistic knowledge. Social knowledge influences perception even when listeners are aware that it is, or may be, false.  This result parallels previous results for accentedness and attractiveness judgments \citep{campbell-kibler2020}. A similar result may be present, for social information, in the within-participants guise manipulation of \cite{mcgowanBabel2020}. In that study, the authors use participants' metalinguistic commentaries to assess the extent to which the guise manipulations were or were not `believed'. The results of the present study suggests that that belief may be irrelevant. The present result also gives additional context to studies demonstrating influence of social knowledge even when listeners have no reason to believe the guise manipulation \citep{Niedzielski1999, haynolandrager2006, HayDrager2010}. It is unclear whether social knowledge will prove to be as resilient to awareness as the obligatory McGurk effect \citep{McGurkMacDonald1976} which persists even when participants actively identify that the face and voice in the experiment are mismatched \citep{GreenEtAl1991}, but the suggestion is that it will.

The gender identity of the talker who produced the VC Rime supplemented Face in the Congruous conditions to make the Strand effect even stronger; the mechanism may prove similar to the way lip-rounding accentuates the backness of back vowels.  In the Incongruous conditions, though, listeners' perception of the [ʃ]-[s] continuum tracked the VC Rimes, rather than the purported gender of the Face. This pattern was strongest in the least-ambiguous portions of the Rime continuum and weakest in the most-ambiguous. In a sense, by separating trials by congruity of face and voice we have replicated \cite{strandJohnson1996}'s exp1 and exp2 simultaneously. One wonders, looking back at their exp2, whether this classic result was \emph{also} a congruous condition in which listeners had sufficient gender information from the voice to supplement the purported information from the Face. Even the non-prototypical voices used in that study did pattern, in exp1, in weakly gendered ways. This finding may provide some insight into recent failures to replicate the original Strand effect \citep{schellingerMunsonEdwards2017, wilbanks2022}.

The phonetic correlates of gender manipulated in the VC rimes for this study are F0 and formant ratios. However, these may not be the only cues listeners are drawing upon with their knowledge of US English. Surely, F0 and vowel formant ratios \emph{can be} important to listeners, just as voice onset time and vocal fold vibration can be important cues to the voicing of /t/ and /d/. But as \cite{lisker1986} catalogs, there are 16 cues to this apparently simple feature in English, any of which might be sufficient to communicate voicing, but none of which is required. In this study we have used manipulated stimuli that obscure, over the course of two gender continua, the gender identity of the talker who produced the basis token for that continuum. At an explicit level, these continua \emph{sound ambiguous} to the experimenters in much the way that \cite{whalen1984}'s stimuli do not sound obviously mismatched. But our perception results suggest that listeners are still aware, albeit implicitly, of the gender identity we have attempted to obscure by altering the phonetic correlates of gender.

\section{Conclusion}

\begin{comment}
There are likely three levels of awareness (or indexical order) relevant in this experiment. The highest level (corresponding to the Labovian idea of stereotype) being indicative of something like Southern vowel shift-- speakers are fully aware of the feature, what it indexes, how to imitate it generally, and are able to discuss it metalinguistically.
    Below this are features which are probably less available for some of these things (maybe crucially metalinguistic discourse, but crucially Silverstein 2003 makes a point that even things available for this kind of discourse need not be accurately described/perceived/in any way in line with reality). An example of this maybe is Chinese accented English? Speakers have beliefs about it (ostensibly \textit{knowledge} about it) but couldn't identify the actual hallmark features of a Chinese accent, nor could they produce it in any realistic way (or perceive it as different from a mock accent if you believe that McGowan guy). 
        The level my comment was about would be below that as well. Something which doesn't require conscious awareness, which isn't available for metalinguistic discussion, and which probably isn't even salient enough for individuals to describe internally, \emph{BUT} which listeners are able to attend to on some level in perception, and which demonstrably characterizes responses/behavior in an indexical way despite the lack of awareness. This is anecdotal, but an example might be how southern speakers perceive unmerged pen-pin vowels. I expect the difference still exists, and is noticeable, and would produce clear results in an experiment (both "which word is this" and "is this speaker from the south" kind of judgments). But I don't believe (unless the hypothetical southerners knew about the merger in a metalinguistic way) that they could tell you what they were using in these judgements, or have the ability to discuss them outright as a thing that marks non-southerners. (the cot-caught merger may be a better more general example? There are no doubt tons of others like this that may be more identity-specific as opposed to regional. 
        Maybe something about voice quality? Creaky voice in frat boys? Creaky voice from old male academics (Chomsky)?
        Breathy voice in performances of male+stupid/incompetence (typically cartoon characters but probably mocking quotes too? Cowardly lion?)
        Breathy voice used by drag queens of the Divine/Lady Chablis/Latrice Royale stock?(potentially to offset limited ability to raise f0 without employing falsetto? Doesn't matter other than not a thing people can directly identify and discuss I guess, but would put money on people judging male+breathy as different from male+modal in a hundred socially meaningful ways-- Chablis was trans also i think? so maybe not the best of three examples). Tough to find examples of "people "know" about this indexical variable implicitly, but that knowledge is only available for perception, not for metalinguistic discourse (yet)". ]]   

\subsection{Language is fundamentally social}
\end{comment}

Decades of research since \cite{strandJohnson1996}'s original finding have demonstrated that a visual cue can shift fricative perceptions when paired with an ambiguously-gendered voice (although cf Munson 2017 and Wilbanks 2022). \cite{bouavichithEtAl2019} even demonstrated with eye-tracking that this effect is fast and bi-directional. One could come away from Strand \& Johnson's exp1 and exp2 and subsequent replications with a theoretical model in which visually-cued social information and phonetically-cued social information exert equivalent influence on speech perception. Prototypically-gendered voices can shift perception of a [ʃ]-[s] continuum and prototypically-gendered visual information can as well. However, listeners' behavior in our Congruous and Incongruous conditions is inconsistent with such a model and suggests, instead, that when visually-cued and phonetically-cued social information are in congruence, they can enhance one another. When, on the other hand, these information sources conflict, it is the phonetically-cued social information that will dominate \citep{campbell-kibler2020}.

It is unlikely that fricatives are unique in this respect. For example, the incongruous results seen in this study are, perhaps, predicted by lack of Face effect for \cite{johnsonstranddimperio1999}'s vowel perception results in exp2 given a stereotypical face (particularly, in that study, for the male voice). As listeners, we do not have veridical access to the speech sounds intended by a talker. Instead, we must combine the speech signal with our phonological knowledge, lexical knowledge, social expectations, visual input, expectations of the social world \citep{BabelVolume}  and other sensory information to arrive at a percept. The implication is that perception is more holistic than is dreamt of in our phonologies. Category boundaries, whether for speech sounds or social categories, are fuzzy and perception needs to be fast. We retain knowledge of, and use, detailed social and linguistic knowledge at both high and low levels of processing. Enumerating the phonetic correlates of gender may not be the wrong question, but it is certainly premature given the limitations of current theory to account for what listeners actually do. A better question is  something like ``what kinds of knowledge do listeners draw on during perception and when?''

%Because Bouavichith et al. saw social information influence  the onset fricative, even before listeners had had time to hear the nucleus or coda. result is inconsistent with word-level segmentation (e.g. Johnson 2006) and also inconsistent with a model that requires social categories to be activated after lexical access \citep{munson2010}. The present results appear to require a hybrid episodic model (Pierrehumbert 2006; Cutler et al. 2010; Docherty and Mendoza-Denton 2012) in which social and linguistic knowledge interact with the signal during processing. We need a model that can account for \cite{whalen1984}'s subcategorical mismatches, \citep{beddormcgowanbolandcoetzeebrasher2013}'s real-time sensitivity to coarticulation, \cite{bouavichithEtAl2019}'s bidirectional influence of social information on segmental classification and fricative quality on gender classification, and the present results. 

%The results in the incongruent condition shed some light on an existing mild conundrum in the literature. Why does the Strand effect demonstrate the influence of social knowledge on segmental speech perception while Green et al. (1991) finds the opposite. Why do listeners in a cross-gender McGurk task still McGurk despite having introspective awareness of the mismatch and the ability to participate in meta-linguistic commentary about that mismatch?  We submit that the McGurk effect “doesn’t break” for Green et al. not, as they claim, because social information is irrelevant to listeners or normalized away prior to speech perception but because social information from the face and the voice combine to form a complete percept of the talker’s identity. Green et al. is necessarily an incongruous pairing of face and voice and, as our results suggest, when purported gender from a visual cue and purported gender from a voice conflict, at least for gender, the face wins. This interpretation predicts that a replication of Green et al. with non-prototypically gendered voices may prove more interesting. However, it should also be noted that another key problem with Green et al.’s design is that, unlike fricative place, the integration of visual lips with auditory velar consonants does not participate in the creation and perception of gender in American English. There is no reason, therefore, that Green et al.’s study should have turned out any other way; there is no conundrum.

\cite[p. 205]{barrett2014} writes, ``any assumption of essentialism will ultimately marginalize those individuals who do not fit the essentialist understandings of human behavior''. It may not feel brutal or reductive to read \cite{May1976}'s findings about large and small vocal tracts as if they refer to male and female vocal tracts, respectively, but it does necessarily imply that tall, long-necked women and short, squat-necked men need to find some other way of labeling themselves. The idea that male voices come from large bodies and female voices come from small bodies need not be literally true for the phonetic and perceptual correlates of size to become enregistered alongside other features in the creation of gendered personae (D'Onofrio 2020). Our prediction that incongruity in face and voice would slow listener judgments was not supported. It is tempting to interpret this as evidence that, unlike misleading coarticulatory information, listeners are aware of the diversity of gender expression, but this is not a question the current study can resolve.

What the current study can resolve is that listeners' social knowledge of speech is not delicate. The present result is equally inconsistent with a model that disregards social knowledge entirely and with any model of speech perception that presumes \emph{all} social knowledge to be late, high-level, and available to introspective control. Part of what listeners know when they know a language includes the simultaneous patterning of `linguistic' and `social' information in a shared phonetic signal. Social knowledge is not a weakly-associated prime; Social knowledge and linguistic knowledge are deeply intertwined in speech perception and it is perverse to assume that the language subsystem underlying this ability would necessarily distinguish them.



